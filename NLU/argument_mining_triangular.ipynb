{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: ../github/allennlp/ is not a valid editable requirement. It should either be a path to a local project or a VCS URL (beginning with svn+, git+, hg+, or bzr+).\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ../github/allennlp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3fae1fad90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 18 13:18:18 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 70%   68C    P2   267W / 260W |  10682MiB / 11019MiB |     94%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 67%   67C    P2   211W / 260W |   8646MiB / 11019MiB |     91%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 28%   43C    P8     5W / 260W |   7174MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   37C    P8    10W / 260W |     11MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 77%   67C    P2   239W / 260W |   5826MiB / 11019MiB |     90%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 82%   77C    P2   226W / 260W |   5834MiB / 11019MiB |     91%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 27%   37C    P8    11W / 260W |    966MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 37%   48C    P2    62W / 260W |   1046MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.0.1\n",
      "Summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Sam Shleifer, Patrick von Platen, Sylvain Gugger, Google AI Language Team Authors, Open AI team Authors, Facebook AI Authors, Carnegie Mellon University Authors\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache\n",
      "Location: /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages\n",
      "Requires: numpy, packaging, tokenizers, regex, requests, sacremoses, filelock, tqdm\n",
      "Required-by: flair, allennlp\n"
     ]
    }
   ],
   "source": [
    "!pip3 show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2080 Ti\n",
      "GeForce RTX 2080 Ti\n",
      "GeForce RTX 2080 Ti\n",
      "GeForce RTX 2080 Ti\n",
      "GeForce RTX 2080 Ti\n",
      "GeForce RTX 2080 Ti\n",
      "GeForce RTX 2080 Ti\n",
      "GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "cuda_device = torch.device('cuda:3')\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "for i in range(n_gpu):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.token_indexers import PretrainedTransformerMismatchedIndexer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "\n",
    "\n",
    "#BERT_MODEL = 'bert-base-cased'\n",
    "BERT_MODEL = 'google/electra-base-discriminator'\n",
    "indexer = PretrainedTransformerMismatchedIndexer(model_name=BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Sequence, Iterable\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.dataset_readers.dataset_utils import to_bioul\n",
    "from allennlp.data.fields import TextField, SequenceLabelField, Field, MetadataField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def _is_divider(line: str) -> bool:\n",
    "    empty_line = line.strip() == \"\"\n",
    "    if empty_line:\n",
    "        return True\n",
    "    else:\n",
    "        first_token = line.split()[0]\n",
    "        if first_token == \"-DOCSTART-\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "class ConllUniversalReader(DatasetReader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_indexers: Dict[str, TokenIndexer] = None,\n",
    "        tag_index: int = 0,\n",
    "        coding_scheme: str = \"IOB1\",\n",
    "        label_namespace: str = \"labels\",\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self._token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        \n",
    "        if coding_scheme not in (\"IOB1\", \"BIOUL\"):\n",
    "            raise ConfigurationError(\"unknown coding_scheme: {}\".format(coding_scheme))\n",
    "\n",
    "        self.tag_index = tag_index\n",
    "        self.coding_scheme = coding_scheme\n",
    "        self.label_namespace = label_namespace\n",
    "        self._original_coding_scheme = \"IOB1\"\n",
    "\n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterable[Instance]:\n",
    "        # if `file_path` is a URL, redirect to the cache\n",
    "        file_path = cached_path(file_path)\n",
    "\n",
    "        with open(file_path, \"r\") as data_file:\n",
    "            logger.info(\"Reading instances from lines in file at: %s\", file_path)\n",
    "\n",
    "            # Group into alternative divider / sentence chunks.\n",
    "            for is_divider, lines in itertools.groupby(data_file, _is_divider):\n",
    "                # Ignore the divider chunks, so that `lines` corresponds to the words\n",
    "                # of a single sentence.\n",
    "                if not is_divider:\n",
    "                    fields = [line.strip().split() for line in lines]\n",
    "                    # unzipping trick returns tuples, but our Fields need lists\n",
    "                    fields = [list(field) for field in zip(*fields)]\n",
    "                    tokens_ = fields[0]\n",
    "                    if self.tag_index >= 0:\n",
    "                        ner_tags = fields[1:][self.tag_index]\n",
    "                    else:\n",
    "                        ner_tags = None\n",
    "                    # TextField requires `Token` objects\n",
    "                    tokens = [Token(token) for token in tokens_]\n",
    "\n",
    "                    yield self.text_to_instance(tokens, ner_tags)\n",
    "\n",
    "    def text_to_instance(  # type: ignore\n",
    "        self,\n",
    "        tokens: List[Token],\n",
    "        ner_tags: List[str] = None,\n",
    "    ) -> Instance:\n",
    "        \"\"\"\n",
    "        We take `pre-tokenized` input here, because we don't have a tokenizer in this class.\n",
    "        \"\"\"\n",
    "\n",
    "        sequence = TextField(tokens, self._token_indexers)\n",
    "        instance_fields: Dict[str, Field] = {\"tokens\": sequence}\n",
    "        instance_fields[\"metadata\"] = MetadataField({\"words\": [x.text for x in tokens]})\n",
    "\n",
    "        # Recode the labels if necessary.\n",
    "        if self.coding_scheme == \"BIOUL\":\n",
    "            coded_ner = (\n",
    "                to_bioul(ner_tags, encoding=self._original_coding_scheme)\n",
    "                if ner_tags is not None\n",
    "                else None\n",
    "            )\n",
    "        else:\n",
    "            # the default IOB1\n",
    "            coded_ner = ner_tags\n",
    "\n",
    "        \n",
    "        # Add \"tag label\" to instance\n",
    "        if coded_ner:\n",
    "            instance_fields[\"tags\"] = SequenceLabelField(coded_ner, sequence, self.label_namespace)\n",
    "        \n",
    "        return Instance(instance_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598b51514ee649aba651c3cf45640f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='reading instances'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e67b9826514c5fb4ca4d9e410d326e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='reading instances'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#from allennlp.data.dataset_readers import Conll2003DatasetReader\n",
    "from allennlp.data.dataset_readers import SequenceTaggingDatasetReader\n",
    "\n",
    "#reader = Conll2003DatasetReader(token_indexers={'tokens': indexer})\n",
    "reader = ConllUniversalReader(token_indexers={'tokens': indexer})\n",
    "train_dataset = reader.read('train.tsv')\n",
    "dev_dataset = reader.read('dev.tsv')\n",
    "#test_dataset = reader.read('data_1/test_no_answers.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b831e821004578bf6634b88b18e1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='building vocab'), FloatProgress(value=0.0, max=2334.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset.instances)\n",
    "train_dataset.index_with(vocab)\n",
    "dev_dataset.index_with(vocab)\n",
    "#test_dataset.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.token_embedders import PretrainedTransformerMismatchedEmbedder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.seq2seq_encoders import PassThroughEncoder\n",
    "\n",
    "\n",
    "embedder = PretrainedTransformerMismatchedEmbedder(model_name=BERT_MODEL)\n",
    "text_field_embedder = BasicTextFieldEmbedder({'tokens': embedder})\n",
    "seq2seq_encoder = PassThroughEncoder(input_dim=embedder.get_output_dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'crf_tagger' from 'allennlp.models' (/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/allennlp/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2e3ce57e1b16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrf_tagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'crf_tagger' from 'allennlp.models' (/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/allennlp/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "from allennlp.models import crf_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e4896ca9d36d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m model = crf_tagger(vocab=vocab, \n\u001b[0m\u001b[1;32m      6\u001b[0m                       \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq2seq_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0mcalculate_span_f1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "from allennlp.models import SimpleTagger\n",
    "from allennlp.models import crf_tagger\n",
    "\n",
    "\n",
    "model = SimpleTagger(vocab=vocab, \n",
    "                      encoder=seq2seq_encoder,\n",
    "                      calculate_span_f1=True,\n",
    "                      label_encoding='IOB1').cuda(device=cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-71cacc06bb91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'steps_per_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f796906406f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'steps_per_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "(steps_per_epoch*num_epochs)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from transformers import AdamW\n",
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "from allennlp.training.learning_rate_schedulers import LinearWithWarmup\n",
    "from torch.utils.data import DataLoader\n",
    "from allennlp.training import GradientDescentTrainer\n",
    "from allennlp.training.learning_rate_schedulers import SlantedTriangular\n",
    "from allennlp.data import allennlp_collate\n",
    "\n",
    "import math\n",
    "\n",
    "def train_roberta_triangular(lr, batch_size):\n",
    "    num_epochs = 3\n",
    "    #batch_size = 16\n",
    "    #batch_size = 2\n",
    "    #accum = 4\n",
    "    accum = 1\n",
    "    steps_per_epoch = math.ceil(len(train_dataset) / batch_size)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    train_data_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, \n",
    "                                   collate_fn=allennlp_collate, shuffle=True)\n",
    "    val_data_loader = DataLoader(dataset=dev_dataset, batch_size=batch_size, collate_fn=allennlp_collate)\n",
    "    lr_scheduler = SlantedTriangular(optimizer, \n",
    "                                    num_epochs=num_epochs, \n",
    "                                    #warmup_steps=(steps_per_epoch*num_epochs)*0.1, \n",
    "                                    num_steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "    date_time = datetime.now()\n",
    "    date_str = date_time.strftime('%m/%d/%Y')\n",
    "    time_str = date_time.strftime('%H:%M:%S')\n",
    "\n",
    "\n",
    "    trainer = GradientDescentTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        patience = 1,\n",
    "        data_loader=train_data_loader,\n",
    "        validation_data_loader=val_data_loader,\n",
    "        #validation_data_loader=None,\n",
    "        num_epochs=num_epochs,\n",
    "        cuda_device=cuda_device,\n",
    "        learning_rate_scheduler=lr_scheduler,\n",
    "        num_gradient_accumulation_steps=accum,\n",
    "        serialization_dir=f'./workdir/{date_str}/{time_str}',\n",
    "        grad_clipping=1.\n",
    "    )\n",
    "    parameter_tuple = (lr, batch_size, (steps_per_epoch*num_epochs)*0.1)\n",
    "    try:\n",
    "        metrics = trainer.train()\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    return metrics, parameter_tuple\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ef76a6b50c493789592a125e012b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=146.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf9eee039a94308918089a12b898c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962f5e8d72624896b45e235dffc7eed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=146.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbb3072f6e644e7a7aa9ce26e3df247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from transformers import AdamW\n",
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "from allennlp.training.learning_rate_schedulers import LinearWithWarmup\n",
    "from torch.utils.data import DataLoader\n",
    "from allennlp.training import GradientDescentTrainer\n",
    "from allennlp.training.learning_rate_schedulers import SlantedTriangular\n",
    "from allennlp.data import allennlp_collate\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 16\n",
    "#batch_size = 2\n",
    "#accum = 4\n",
    "accum = 1\n",
    "steps_per_epoch = math.ceil(len(train_dataset) / batch_size)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n",
    "train_data_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, \n",
    "                               collate_fn=allennlp_collate, shuffle=True)\n",
    "val_data_loader = DataLoader(dataset=dev_dataset, batch_size=100, collate_fn=allennlp_collate)\n",
    "lr_scheduler = SlantedTriangular(optimizer, \n",
    "                                    num_epochs=num_epochs, \n",
    "                                    #warmup_steps=(steps_per_epoch*num_epochs)*0.1, \n",
    "                                    num_steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "date_time = datetime.now()\n",
    "date_str = date_time.strftime('%m/%d/%Y')\n",
    "time_str = date_time.strftime('%H:%M:%S')\n",
    "\n",
    "\n",
    "trainer = GradientDescentTrainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    patience = 1,\n",
    "    data_loader=train_data_loader,\n",
    "    validation_data_loader=val_data_loader,\n",
    "    #validation_data_loader=None,\n",
    "    num_epochs=num_epochs,\n",
    "    cuda_device=cuda_device,\n",
    "    learning_rate_scheduler=lr_scheduler,\n",
    "    num_gradient_accumulation_steps=accum,\n",
    "    serialization_dir=f'./workdir/{date_str}/{time_str}',\n",
    "    grad_clipping=1.\n",
    ")\n",
    "\n",
    "try:\n",
    "    metrics = trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6d2ebc8632490482cac6ee0c1d342c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9179720196101877,\n",
       " 'accuracy3': 0.9900753318187253,\n",
       " 'precision-overall': 0.7098479841374752,\n",
       " 'recall-overall': 0.7542134831460674,\n",
       " 'f1-measure-overall': 0.7313585291112882,\n",
       " 'loss': 0.26040369272232056}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.training.util import evaluate\n",
    "\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=100, collate_fn=allennlp_collate)\n",
    "evaluate(model, dev_dataloader, cuda_device=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebook/NLU_last_version\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"/notebook/NLU_last_version/models/model_triang.th\", 'wb') as f:\n",
    "#    torch.save(model.state_dict(), f)\n",
    "\n",
    "#vocab.save_to_files(\"/notebook/NLU_last_version/models/vocabulary_triang\")\n",
    "\n",
    "#vocab2 = Vocabulary.from_files(\"/tmp/vocabulary\")\n",
    "\n",
    "#model2 = LstmTagger(word_embeddings, lstm, vocab2)\n",
    "#with open(\"/tmp/model.th\", 'rb') as f:\n",
    "#    model2.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors import SentenceTaggerPredictor\n",
    "\n",
    "class CustomSentenceTaggerPredictor(SentenceTaggerPredictor):\n",
    "    @overrides\n",
    "    def _json_to_instance(self, json_dict):\n",
    "        tokens = [Token(e) for e in json_dict[\"sentence\"]]\n",
    "        return self._dataset_reader.text_to_instance(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'B-Object'),\n",
       " ('is', 'O'),\n",
       " ('better', 'B-Predicate'),\n",
       " ('than', 'O'),\n",
       " ('C++', 'B-Object')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = CustomSentenceTaggerPredictor(model, reader)\n",
    "preds = predictor.predict(['Python', 'is', 'better', 'than', 'C++'])\n",
    "list(zip(preds['words'], preds['tags'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'B-Object'),\n",
       " ('is', 'O'),\n",
       " ('better', 'B-Predicate'),\n",
       " ('than', 'O'),\n",
       " ('C++', 'B-Object')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.predictors import SentenceTaggerPredictor\n",
    "\n",
    "predictor = SentenceTaggerPredictor(model, reader)\n",
    "preds = predictor.predict('Python is better than C++')\n",
    "list(zip(preds['words'], preds['tags']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval on the dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_labels = [list(e['tags']) for e in dev_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encountered the loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n"
     ]
    }
   ],
   "source": [
    "predictor = CustomSentenceTaggerPredictor(model, reader)\n",
    "\n",
    "dev_eval_loader = DataLoader(dataset=dev_dataset, batch_size=100, \n",
    "                             shuffle=False, collate_fn=lambda a: a)\n",
    "\n",
    "all_preds = []\n",
    "for batch in dev_eval_loader:\n",
    "    all_preds += predictor.predict_batch_instance(batch)\n",
    "    \n",
    "pred_tags = [pred['tags'][:len(pred['words'])] for pred in all_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731358529111338\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "Predicate       0.87      0.93      0.90       386\n",
      "   Object       0.67      0.73      0.70       781\n",
      "   Aspect       0.58      0.57      0.58       257\n",
      "\n",
      "micro avg       0.71      0.75      0.73      1424\n",
      "macro avg       0.71      0.75      0.73      1424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report, f1_score\n",
    "\n",
    "print(f1_score(dev_labels, pred_tags))\n",
    "print(classification_report(dev_labels, pred_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('georgia', 'B-Object'),\n",
       " ('has', 'O'),\n",
       " ('a', 'O'),\n",
       " ('higher', 'B-Predicate'),\n",
       " ('percentage', 'O'),\n",
       " ('of', 'O'),\n",
       " ('blacks', 'B-Aspect'),\n",
       " ('(', 'O'),\n",
       " ('30', 'O'),\n",
       " ('.', 'O'),\n",
       " ('5', 'O'),\n",
       " (')', 'O'),\n",
       " ('than', 'O'),\n",
       " ('new', 'B-Object'),\n",
       " ('york', 'B-Object'),\n",
       " ('(', 'O'),\n",
       " ('15', 'O'),\n",
       " ('.', 'O'),\n",
       " ('9', 'O'),\n",
       " (')', 'O'),\n",
       " ('or', 'O'),\n",
       " ('california', 'B-Object'),\n",
       " ('(', 'O'),\n",
       " ('6', 'O'),\n",
       " ('.', 'O'),\n",
       " ('2', 'O'),\n",
       " (').', 'O')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_num = 47\n",
    "list(zip(all_preds[sent_num]['words'], all_preds[sent_num]['tags']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a9601a3cd342f7a5b2f90e675086fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='reading instances'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reader = ConllUniversalReader(token_indexers={'tokens': indexer}, tag_index=-1)\n",
    "test_dataset_no_answers = reader.read('test_no_answers.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = CustomSentenceTaggerPredictor(model, reader) \n",
    "\n",
    "predict_data_loader = DataLoader(dataset=test_dataset_no_answers, batch_size=100, \n",
    "                                 shuffle=False, collate_fn=lambda a: a)\n",
    "\n",
    "all_preds = []\n",
    "for batch in predict_data_loader:\n",
    "    all_preds += predictor.predict_batch_instance(batch)\n",
    "    \n",
    "pred_tags = [pred['tags'][:len(pred['words'])] for pred in all_preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_test_triangular.tsv', 'w') as f:\n",
    "    for pred in all_preds:\n",
    "        f.write('\\n'.join([f'{w}\\t{t}' for w, t in zip(pred['words'], pred['tags'])]))\n",
    "        \n",
    "        if i < len(all_preds) - 1:\n",
    "            f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_test.tsv', 'w') as f:\n",
    "    for i, pred in enumerate(all_preds):\n",
    "        f.write('\\n'.join([f'{w}\\t{t}' for w, t in zip(pred['words'], pred['tags'])]))\n",
    "        \n",
    "        if i < len(all_preds) - 1:\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
