{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative question answering demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project by:  \n",
    "Nikita Borovkov  \n",
    "Filipp Furaev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External resourses required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 -m nltk.downloader stopwords\n",
    "!python3 -m nltk.downloader universal_tagset\n",
    "!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.\n",
      "Warning:  apex was installed without --cuda_ext. Fused syncbn kernels will be unavailable.  Python fallbacks will be used instead.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedAdam will be unavailable.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedLayerNorm will be unavailable.\n"
     ]
    }
   ],
   "source": [
    "from utils.sentence_clearer import clear_sentences, remove_questions\n",
    "from ml_approach.sentence_preparation_ML import prepare_sentence_DF\n",
    "from ml_approach.classify import classify_sentences\n",
    "from utils.es_requester import extract_sentences\n",
    "from utils.objects import Argument\n",
    "\n",
    "#import pke\n",
    "#from pke.unsupervised import MultipartiteRank\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from bert_comp_pred import get_BERT_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input two objects to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_a = \"python\"\n",
    "obj_b = \"java\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_a = Argument(obj_a.lower().strip())\n",
    "obj_b = Argument(obj_b.lower().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for sentences, containing the requested objects in Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in user and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_elasticsearch(obj_a, obj_b, user, password):\n",
    "    url = 'http://ltdemos.informatik.uni-hamburg.de/depcc-index/_search?q='\n",
    "    url += 'text:\\\"{}\\\"%20AND%20\\\"{}\\\"'.format(obj_a.name, obj_b.name)\n",
    "    proxies = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "    size = 10000\n",
    "    \n",
    "    url += '&from=0&size={}'.format(size)\n",
    "    response = requests.get(url, auth=HTTPBasicAuth(user, password), proxies=proxies)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "proxies = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "params = {\n",
    "            'objectA': 'Moscow',\n",
    "            'objectB': 'London',\n",
    "            'fs': str(True).lower()}\n",
    "response = requests.get(url=URL, params=params, proxies=proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write down the name and password for elasticSearch\n",
    "name = \"\"\n",
    "password = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_compl = request_elasticsearch(obj_a, obj_b, name, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing sentences for classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = extract_sentences(json_compl)\n",
    "remove_questions(all_sentences)\n",
    "prepared_sentences = prepare_sentence_DF(all_sentences, obj_a, obj_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_a</th>\n",
       "      <th>object_b</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [object_a, object_b, sentence]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using classificator of comparative sentences\n",
    "The classificator is used in CAM system:  \n",
    "Paper: https://arxiv.org/abs/1901.05041  \n",
    "Github: https://github.com/uhh-lt/cam/  \n",
    "\n",
    "The classifier takes 2 compared objects and a sentence as an input.\n",
    "The output is one of 3 classes:\n",
    "- NONE - the sentence does not have comparison in it\n",
    "- BETTER - the first object in a sentence is better than the second\n",
    "- WORSE - the first object in a sentence is worse than the second  \n",
    "\n",
    "Paper: https://arxiv.org/abs/1809.06152\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second option is to use pretrained BERT (BERT training is in another notebook (BERT_classifier.ipynb). It's preffered to run it in google colab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run BERT you should download it from https://drive.google.com/file/d/1Hu4XC-N_pt4f10-2Nk8k15jN1HyZK8DX/view?usp=sharing and put it into the \"model\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"BERT\"\n",
    "model = \"bow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to convert 5457 examples..\n",
      "Spawning 11 processes..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bde3fa1c342414a82ba37d91ba17270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5457), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1341ef062d294a1d9e0752ef5226b3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Prediction', max=171, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if model == \"BERT\":\n",
    "    classification_results = get_BERT_prediction(prepared_sentences)\n",
    "if model == \"bow\":\n",
    "    classification_results = classify_sentences(prepared_sentences, 'bow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the sentences without comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         max\n",
       "464   BETTER\n",
       "481   BETTER\n",
       "537   BETTER\n",
       "538   BETTER\n",
       "550   BETTER\n",
       "...      ...\n",
       "5274  BETTER\n",
       "5309  BETTER\n",
       "5330  BETTER\n",
       "5399  BETTER\n",
       "5452  BETTER\n",
       "\n",
       "[113 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_results[classification_results['max'] != 'NONE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_a</th>\n",
       "      <th>object_b</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java 8X Faster than Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java 5.3X Faster than Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>When I use Python, I write Python, not Java.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>I write Python code in Python not Java code us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java 8X Faster than Python .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>throw a Python RuntimeError instead of a Java ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>I'm writing this project in Java instead of Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java is a whole lot more predictible than Python.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>Python has classical OOP, kinda like C++ or Java.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>- the python font size matches the java font s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     object_a object_b                                           sentence\n",
       "464      java   python                         Java 8X Faster than Python\n",
       "481      java   python                       Java 5.3X Faster than Python\n",
       "537    python     java       When I use Python, I write Python, not Java.\n",
       "538    python     java  I write Python code in Python not Java code us...\n",
       "550      java   python                       Java 8X Faster than Python .\n",
       "...       ...      ...                                                ...\n",
       "5274   python     java  throw a Python RuntimeError instead of a Java ...\n",
       "5309     java   python  I'm writing this project in Java instead of Py...\n",
       "5330     java   python  Java is a whole lot more predictible than Python.\n",
       "5399   python     java  Python has classical OOP, kinda like C++ or Java.\n",
       "5452   python     java  - the python font size matches the java font s...\n",
       "\n",
       "[113 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_sentences[classification_results['max'] != 'NONE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniting the comparative sentences and results of classification into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_sentences = prepared_sentences[classification_results['max'] != 'NONE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "comparative_sentences['max'] = classification_results[classification_results['max'] != 'NONE']['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_a</th>\n",
       "      <th>object_b</th>\n",
       "      <th>sentence</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java 8X Faster than Python</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java 5.3X Faster than Python</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>When I use Python, I write Python, not Java.</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>I write Python code in Python not Java code us...</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java 8X Faster than Python .</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>throw a Python RuntimeError instead of a Java ...</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>I'm writing this project in Java instead of Py...</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java is a whole lot more predictible than Python.</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>Python has classical OOP, kinda like C++ or Java.</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>- the python font size matches the java font s...</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     object_a object_b                                           sentence  \\\n",
       "464      java   python                         Java 8X Faster than Python   \n",
       "481      java   python                       Java 5.3X Faster than Python   \n",
       "537    python     java       When I use Python, I write Python, not Java.   \n",
       "538    python     java  I write Python code in Python not Java code us...   \n",
       "550      java   python                       Java 8X Faster than Python .   \n",
       "...       ...      ...                                                ...   \n",
       "5274   python     java  throw a Python RuntimeError instead of a Java ...   \n",
       "5309     java   python  I'm writing this project in Java instead of Py...   \n",
       "5330     java   python  Java is a whole lot more predictible than Python.   \n",
       "5399   python     java  Python has classical OOP, kinda like C++ or Java.   \n",
       "5452   python     java  - the python font size matches the java font s...   \n",
       "\n",
       "         max  \n",
       "464   BETTER  \n",
       "481   BETTER  \n",
       "537   BETTER  \n",
       "538   BETTER  \n",
       "550   BETTER  \n",
       "...      ...  \n",
       "5274  BETTER  \n",
       "5309  BETTER  \n",
       "5330  BETTER  \n",
       "5399  BETTER  \n",
       "5452  BETTER  \n",
       "\n",
       "[113 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting aspects from gathered sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords approach\n",
    "We unite the sentences into a single document and look for keywords in that document using PKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = prepared_sentences[classification_results['max'] != 'NONE']['sentence'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = MultipartiteRank()\n",
    "extractor.load_document(input=text, language=\"en\", normalization='stemming')\n",
    "\n",
    "extractor.candidate_selection(pos={'NOUN', 'PROPN', 'ADJ'})\n",
    "\n",
    "extractor.candidate_weighting()\n",
    "\n",
    "keyphrases = extractor.get_n_best(n=-1, stemming=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('java 8x', 0.24749249572409165),\n",
       " ('python', 0.19022007379986342),\n",
       " ('java', 0.07702735192956407),\n",
       " ('python syntax', 0.034760281504254295),\n",
       " ('python code', 0.03403017697337611),\n",
       " ('java code', 0.01556818580647329),\n",
       " ('faster', 0.008886322455805515),\n",
       " ('slower', 0.008357065934817541),\n",
       " ('easier', 0.0068932419619071985),\n",
       " ('java programs', 0.006539830762890901),\n",
       " ('startup time', 0.006483490826817549),\n",
       " ('better programmers', 0.006381821755624784),\n",
       " ('popular', 0.005426591557860954),\n",
       " ('strict indentation rules', 0.0053477982634904855),\n",
       " ('javascript', 0.0046697540033665596),\n",
       " ('intro programming classes', 0.004669132067498419),\n",
       " ('language', 0.004635580728139692),\n",
       " ('bytecode vm', 0.004605635466155685),\n",
       " ('ruby', 0.0042366545050094165),\n",
       " ('times', 0.003844499948726177),\n",
       " ('simple', 0.0035921294615379124),\n",
       " ('duck typing', 0.003586835262880295),\n",
       " ('java first', 0.003558688689640822),\n",
       " ('much', 0.003500010064004049),\n",
       " ('optimizations', 0.0034299613598155363),\n",
       " ('general language preference', 0.0033740913300847088),\n",
       " ('little endian', 0.0033354616810161867),\n",
       " ('platform', 0.0033130583555133243),\n",
       " ('bytecodes', 0.0032902606192304435),\n",
       " ('rapid application development', 0.0032378677639856666),\n",
       " ('expressions', 0.0032274674654491865),\n",
       " ('result', 0.00320141499225353),\n",
       " ('syntax', 0.0031504443231881825),\n",
       " ('byte', 0.003091130400274215),\n",
       " ('python programs', 0.0030654421456474904),\n",
       " ('lot', 0.0030577610416606974),\n",
       " ('better', 0.00301622045941972),\n",
       " ('fact', 0.002995943135722199),\n",
       " ('-the', 0.002988415116470632),\n",
       " ('market share', 0.0029636053841587545),\n",
       " ('semantic meaning', 0.002928401894027546),\n",
       " ('jython', 0.0028946584020741184),\n",
       " ('seamless way', 0.0028448410900106602),\n",
       " ('indentation', 0.002787882669513218),\n",
       " ('correct', 0.0027707779402789227),\n",
       " ('crap', 0.0027019821471695755),\n",
       " ('python ones', 0.0026621016451070095),\n",
       " ('single value', 0.00264990978324232),\n",
       " ('python implementation', 0.0026294759043169113),\n",
       " ('php', 0.0024321556923986134),\n",
       " ('better language', 0.002414229034217629),\n",
       " ('longer', 0.0023672304048265595),\n",
       " ('inferior', 0.0023613968930580303),\n",
       " ('technically', 0.0023570103623984156),\n",
       " ('common', 0.0023427633315056214),\n",
       " ('hands', 0.002336070556220091),\n",
       " ('impressed', 0.0023349305696681675),\n",
       " ('lambdas', 0.0023276827884106503),\n",
       " ('python interpreter', 0.0023014873354231143),\n",
       " ('surprise', 0.0022687490578298442),\n",
       " ('half', 0.002241612675327989),\n",
       " ('scripting', 0.0022414270011540515),\n",
       " ('significant advantages', 0.0022253587153603155),\n",
       " ('versa', 0.0022060020406094115),\n",
       " ('typical java apps', 0.0021935094811028127),\n",
       " ('code samples', 0.0021903600493028775),\n",
       " ('nokia', 0.002186454649146195),\n",
       " ('guy', 0.002184918989216568),\n",
       " ('native', 0.002179433093562554),\n",
       " ('preferable', 0.0021662751673609806),\n",
       " ('like', 0.0021658644826220578),\n",
       " ('compiles', 0.0021650425519715347),\n",
       " ('vice', 0.0021558394173847384),\n",
       " ('python renderers', 0.002149377394809283),\n",
       " ('compact', 0.002145099025854684),\n",
       " ('first', 0.0021413103679690905),\n",
       " ('python module', 0.0021382262904018155),\n",
       " ('dynamic python', 0.0021274582513245563),\n",
       " ('weak', 0.0021243611466108822),\n",
       " ('backing', 0.002122203764680351),\n",
       " ('typed', 0.0021184794394586834),\n",
       " ('quicker', 0.0021161804292487785),\n",
       " ('contrast', 0.0021120378155829725),\n",
       " ('code', 0.002109488933278187),\n",
       " ('simpler', 0.002108950902161917),\n",
       " ('verbose', 0.002107125305261336),\n",
       " ('python font size', 0.002103864220422298),\n",
       " ('short', 0.002102987905232427),\n",
       " ('capable', 0.0020950104318448216),\n",
       " ('optimized version', 0.002092215679746605),\n",
       " ('acceptance', 0.0020903809400909037),\n",
       " ('cloudstack', 0.0020899049587001957),\n",
       " ('packages', 0.0020887357202432127),\n",
       " ('boeing', 0.0020778685900324613),\n",
       " ('productive', 0.0020681436831165283),\n",
       " ('example', 0.0020665567892589184),\n",
       " ('java memory management', 0.00206140381921247),\n",
       " ('classes', 0.0020548149448097),\n",
       " ('openstack', 0.0020537518143190965),\n",
       " ('lost', 0.0020521790599571585),\n",
       " ('none', 0.0020506918922444098),\n",
       " ('source', 0.0020491588051356723),\n",
       " ('notable differences', 0.0020438876072769495),\n",
       " ('easy', 0.002042658200965969),\n",
       " ('null', 0.0020389878859188616),\n",
       " ('unsigned', 0.0020387224510746904),\n",
       " ('mixed blessing', 0.0020383160638542445),\n",
       " ('concurrency', 0.0020370655428779824),\n",
       " ('hells', 0.002034247160799225),\n",
       " ('little', 0.002029204492537423),\n",
       " ('java classes', 0.002027600320496285),\n",
       " ('statements', 0.0020096004167619573),\n",
       " ('good orm framework', 0.002008516211465061),\n",
       " ('closer', 0.0020080221017011487),\n",
       " ('instincts', 0.0020036189287207956),\n",
       " ('benefit', 0.0020014696280539037),\n",
       " ('expressive language', 0.0019949904057134952),\n",
       " ('scala', 0.0019926698403692662),\n",
       " ('assignment', 0.0019869539268253717),\n",
       " ('perl', 0.001986506462122265),\n",
       " ('predictible', 0.0019841970246607943),\n",
       " ('developers', 0.0019835822690035033),\n",
       " ('equivalent java program', 0.001975539040504815),\n",
       " ('complex one', 0.0019747027595449027),\n",
       " ('rodge paroissiaux', 0.001973608107583162),\n",
       " ('j2me', 0.001966904534422523),\n",
       " ('java xml libraries', 0.001966274818992646),\n",
       " ('stronger', 0.001963106280965402),\n",
       " ('whole lot', 0.001962236407123807),\n",
       " ('fast', 0.0019599780023885167),\n",
       " ('10x shorter', 0.0019588668496090846),\n",
       " ('unicode', 0.0019387730203934263),\n",
       " ('pdftk', 0.0019302402775591755),\n",
       " ('things', 0.0019284868585160181),\n",
       " ('higher', 0.0019187442295315166),\n",
       " ('late binding', 0.0019130841162035641),\n",
       " ('propel', 0.0019120918753626132),\n",
       " ('stuff', 0.0018873907200252292),\n",
       " ('operators', 0.0018831823278525818),\n",
       " ('project', 0.0018779381110774257),\n",
       " ('matlab', 0.0018758239246711686),\n",
       " ('stapler', 0.001866901545653184),\n",
       " ('equivalent python programs', 0.0018647806465317174),\n",
       " ('true', 0.0018537726238615957),\n",
       " ('classical oop', 0.0018458466783629374),\n",
       " ('python ide tools', 0.0018443792791374568),\n",
       " ('encapsulation', 0.0018343120099342139),\n",
       " ('box', 0.0018256960715408803),\n",
       " ('wrong', 0.0018050878872457187),\n",
       " ('python alternative', 0.0017847893109419156),\n",
       " ('support', 0.0017788333656865818),\n",
       " ('python version', 0.0017470826917086186),\n",
       " ('java renderers', 0.0017257081676795964),\n",
       " ('python runtimeerror', 0.0017020040257448217),\n",
       " ('java programmers', 0.0016869275856027123),\n",
       " ('python beginner', 0.0016784290751741381),\n",
       " ('java interpretter', 0.001663517096574317),\n",
       " ('way java', 0.001648185619885432),\n",
       " ('java kind', 0.001601364951132358),\n",
       " ('java guis', 0.0015925461379000952),\n",
       " ('java stackoverflowerror', 0.0015746919719116163),\n",
       " ('python java', 0.0014866687774264548)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyphrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the keyphrases don't look like aspects we need. To extract the needed aspects we use a classifier which is trained to find good aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and preprocessing sentences for training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"OBJECT A\", \"OBJECT B\", \"ASPECT\", \"MOST FREQUENT RATING\", \"SENTENCE\"]\n",
    "df_train = pd.read_csv(\"classification_fine_grained/train_clf_fine_grained.csv\", header=None, names=names)\n",
    "df_test = pd.read_csv(\"classification_fine_grained/test_clf_fine_grained.csv\", header=None, names=names)\n",
    "df_dev = pd.read_csv(\"classification_fine_grained/dev_clf_fine_grained.csv\", header=None, names=names)\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def get_list_of_tokens(df_texts):\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    tokens = []\n",
    "    texts = df_texts[\"SENTENCE\"].values\n",
    "    for i in range(len(texts)):\n",
    "        row = texts[i]\n",
    "        # remove punctuation\n",
    "        for ch in string.punctuation:\n",
    "            row = row.replace(ch, \" \")\n",
    "        row = row.replace(\"   \", \" \")\n",
    "        row = row.replace(\"  \", \" \")\n",
    "        temp_line = []\n",
    "        # remove stop words\n",
    "        for word in row.split():\n",
    "            if word not in stop_words:\n",
    "                temp_line.append(word)\n",
    "        row = ' '.join(temp_line)\n",
    "        # lemmatization\n",
    "        temp_line = []\n",
    "        for word in row.split():\n",
    "            temp_line.append(wordnet_lemmatizer.lemmatize(word))\n",
    "        tokens.append(temp_line)\n",
    "    return tokens\n",
    "\n",
    "tokens_test = get_list_of_tokens(df_test)\n",
    "tokens_train = get_list_of_tokens(df_train)\n",
    "tokens_dev = get_list_of_tokens(df_dev)\n",
    "\n",
    "df_train['TOKENS'] = pd.Series(tokens_train)\n",
    "df_dev['TOKENS'] = pd.Series(tokens_dev)\n",
    "df_test['TOKENS'] = pd.Series(tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To vectorise the sentences we use Word2Vec:  \n",
    "Input of the classifier is a concatenation of 4 embeddings:\n",
    "- object a embedding\n",
    "- object b embedding\n",
    "- aspect embedding\n",
    "- sentence embedding  \n",
    "\n",
    "For sentence embedding we use mean of embeddings of its words.  \n",
    "So, considering w2v dimensionality, we have vecctors of size 1200 as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_embeddings(model, words_list):\n",
    "    sentence_embedding = []\n",
    "    for word in words_list:\n",
    "        try:\n",
    "            sentence_embedding.append(model[word])\n",
    "        except KeyError:\n",
    "            continue\n",
    "#             print(word + \" is not in the vocabulary, skipping...\")\n",
    "    if len(sentence_embedding) == 0:\n",
    "        sentence_embedding.append(np.zeros(300))\n",
    "    return np.array(sentence_embedding)\n",
    "\n",
    "def to_w2v_matrix(df_data, model):\n",
    "    sent_embs = np.zeros([df_data.shape[0], 300 * 4], dtype='float32')\n",
    "    for i in range(df_data.shape[0]):\n",
    "        object_a_embedding = create_sentence_embeddings(model, df_data[\"OBJECT A\"][i].split()).mean(axis=0)\n",
    "        object_b_embedding = create_sentence_embeddings(model, df_data[\"OBJECT B\"][i].split()).mean(axis=0)\n",
    "        aspect_embedding = create_sentence_embeddings(model, df_data[\"ASPECT\"][i].split()).mean(axis=0)\n",
    "        sentence_embedding = create_sentence_embeddings(model, df_data[\"TOKENS\"][i]).mean(axis=0)\n",
    "        sent_embs[i, :] = np.concatenate((object_a_embedding, object_b_embedding, aspect_embedding, sentence_embedding), axis=0)\n",
    "    return sent_embs\n",
    "\n",
    "X_train = to_w2v_matrix(df_train, w2v_model)\n",
    "X_dev = to_w2v_matrix(df_dev, w2v_model)\n",
    "X_test = to_w2v_matrix(df_test, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_for_binary(data):\n",
    "    return (data['MOST FREQUENT RATING'] != 'BAD').astype('float32').to_numpy()\n",
    "\n",
    "y_train = get_output_for_binary(df_train)\n",
    "y_dev = get_output_for_binary(df_dev)\n",
    "y_test = get_output_for_binary(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def report_scores(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    pr = precision_score(y, y_pred, average='weighted')\n",
    "    re = recall_score(y, y_pred, average='weighted')\n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    f1_bad, f1_good = f1_score(y, y_pred, average=None)\n",
    "    print(\"Accuracy: {:.2f}\".format(acc * 100))\n",
    "    print(\"Precision: {:.2f}\".format(pr * 100))\n",
    "    print(\"Recall: {:.2f}\".format(re * 100))\n",
    "    print(\"F1: {:.2f}\".format(f1 * 100))\n",
    "    print(\"F1 GOOD: {:.2f}\".format(f1_good * 100))\n",
    "    print(\"F1 BAD: {:.2f}\".format(f1_bad * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the classifier: Support Vector Classifier with a linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of fit\n",
      "Train\n",
      "Accuracy: 96.41\n",
      "Precision: 96.44\n",
      "Recall: 96.41\n",
      "F1: 96.41\n",
      "F1 GOOD: 96.21\n",
      "F1 BAD: 96.59\n",
      "Dev\n",
      "Accuracy: 78.74\n",
      "Precision: 78.72\n",
      "Recall: 78.74\n",
      "F1: 78.72\n",
      "F1 GOOD: 80.48\n",
      "F1 BAD: 76.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='linear', gamma='auto')\n",
    "\n",
    "print(\"start of fit\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Train\")\n",
    "report_scores(model, X_train, y_train)\n",
    "\n",
    "print(\"Dev\")\n",
    "report_scores(model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Accuracy: 81.91\n",
      "Precision: 81.99\n",
      "Recall: 81.91\n",
      "F1: 81.89\n",
      "F1 GOOD: 82.43\n",
      "F1 BAD: 81.36\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(\"Test\")\n",
    "report_scores(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "filename = 'asp_clf.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Accuracy: 81.91\n",
      "Precision: 81.99\n",
      "Recall: 81.91\n",
      "F1: 81.89\n",
      "F1 GOOD: 82.43\n",
      "F1 BAD: 81.36\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(\"Test\")\n",
    "report_scores(loaded_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have trained a classifier and are going to process our keyphrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process the keyphrases we need a separate dataframe with sentences for each aspect (keyphrase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp_df = pd.DataFrame(columns=['OBJECT A', 'OBJECT B', 'ASPECT', 'SENTENCE', 'max'])\n",
    "forbidden_phrases = [obj_a.name, obj_b.name, 'better', 'worse']\n",
    "\n",
    "for index, row in comparative_sentences.iterrows():\n",
    "    sentence = row['sentence']\n",
    "    for (keyphrase, score) in keyphrases:\n",
    "        skip_keyphrase = False\n",
    "        for phrase in forbidden_phrases:\n",
    "            if keyphrase == phrase:\n",
    "                skip_keyphrase = True\n",
    "                break\n",
    "        if not skip_keyphrase:\n",
    "            if keyphrase in sentence:\n",
    "                asp_df = asp_df.append(\n",
    "                    {'OBJECT A': row['object_a'],\n",
    "                     'OBJECT B': row['object_b'],\n",
    "                     'ASPECT': keyphrase,\n",
    "                     'SENTENCE': row['sentence'],\n",
    "                     'max': row['max'],\n",
    "                    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp_df['TOKENS'] = pd.Series(get_list_of_tokens(asp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_asp = to_w2v_matrix(asp_df, w2v_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aspects left after classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = asp_df.iloc[np.nonzero(y_pred)[0].tolist()]['ASPECT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['syntax', 'faster', 'indentation', 'better language', 'quicker',\n",
       "       'easier', 'instincts', 'simpler'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 keyphrases for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('java 8x', 0.24749249572409165),\n",
       " ('python', 0.19022007379986342),\n",
       " ('java', 0.07702735192956407),\n",
       " ('python syntax', 0.034760281504254295),\n",
       " ('python code', 0.03403017697337611),\n",
       " ('java code', 0.01556818580647329),\n",
       " ('faster', 0.008886322455805515),\n",
       " ('slower', 0.008357065934817541),\n",
       " ('easier', 0.0068932419619071985),\n",
       " ('java programs', 0.006539830762890901)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyphrases[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to specify which aspects belong to which object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_a_aspects = []\n",
    "obj_b_aspects = []\n",
    "for aspect in aspects:\n",
    "    rows = asp_df[asp_df['ASPECT']==aspect]\n",
    "    if obj_a.name == rows.iloc[0]['OBJECT A']:\n",
    "        obj_a_aspects.append(aspect)\n",
    "    else:\n",
    "        obj_b_aspects.append(aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['syntax', 'better language', 'quicker', 'easier', 'simpler']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_a_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['faster', 'indentation', 'instincts']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_b_aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winner of comparison is the object which has more aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_pair = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(obj_a_aspects) > len(obj_b_aspects):\n",
    "    comparing_pair['winner_aspects'] = obj_a_aspects\n",
    "    comparing_pair['loser_aspects'] = obj_b_aspects\n",
    "    comparing_pair['winner'] = obj_a.name\n",
    "    comparing_pair['loser'] = obj_b.name\n",
    "else:\n",
    "    comparing_pair['winner_aspects'] = obj_b_aspects\n",
    "    comparing_pair['loser_aspects'] = obj_a_aspects\n",
    "    comparing_pair['winner'] = obj_b.name\n",
    "    comparing_pair['loser'] = obj_a.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_generation.template_generation import generate_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I would prefer to use python because it is: first, syntax, second, better language, third, quicker, fourth, easier, fifth, simpler, but java is: first, faster, second, indentation, third, instincts'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_template(comparing_pair, mode=\"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a brief summary using text rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.textcleaner import split_sentences\n",
    "from gensim.summarization.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = asp_df[asp_df.ASPECT.isin(aspects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"\"\n",
    "for row in range (rows.shape[0]):\n",
    "    sentence = asp_df.iloc[row]['SENTENCE'] + \" \"\n",
    "    if sentence not in sentences:\n",
    "        sentences += sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(split_sentences(sentences)) > 10:\n",
    "    summary = str(summarize(sentences, split=False, word_count=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is Java so popular than Python.\n",
      "Simple: Java is faster than Python.\n",
      "Python grew six times faster than Java, but Java still has twice the market share of Python.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Demo import one_liner\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test what the demo by using the oneliner below (it only requires the w2v model)  \n",
    "response - sentence containing aspects of products generated using templates  \n",
    "summary - brief summary of sentences gathered from Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting Elasticsearch\n",
      "Preparing sentences\n",
      "Classifying comparative sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/philipp/anaconda3/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/philipp/anaconda3/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/philipp/Документы/NLG/demo/Demo.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comparative_sentences['max'] = classification_results[classification_results['max'] != 'NONE']['max']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for keyphrases\n",
      "Preparing keyphrases for classification\n",
      "Classifying keyphrases\n",
      "Determining the winner\n",
      "Generating response\n",
      "Generating summary\n"
     ]
    }
   ],
   "source": [
    "obj_a = \"play station\"\n",
    "obj_b = \"xbox\"\n",
    "user = \"\" # username in Elasticsearch\n",
    "password = \"\" # password in Elasticsearch\n",
    "\n",
    "response, summary = one_liner(obj_a, obj_b, user, password, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i came to the conclusion that play station is better, because: much, ill, fun abilities, useful, fun, smart design, better target, free, reliable, much video games, bumpers, rubbish, price tag, price, investors, current market dominance, apprehension, order, powerful consoles, candy, stocking, solder toys, bit bigger, x2 inches, numbers, works, cheaper, free games, better deal, better graphics, touch screen, coarse flipping, resistance bs, liberation, bad system, overall. But it will be useful for you to know that xbox is: play, control, graphics, comparison, better situation, greater sales, form, sale, last, bluray drive, disk, trading games, powerful, console sales, size, cheap, best, hard, secure'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One great feature on this then, is the free play station network, which is also much more reliable than Xbox LIVE.\\nPersonally I prefer the Xbox controller and I've heard that live is a more complete online experience than what play station offers.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A demo version of a comparative question answering system was developed\n",
    "- Using machine learning techniques it allows to get aspects of the compared objects and receive an answer containing them\n",
    "- Among tested comparative sentences classifier (BETTER, WORSE, NONE) the classifier using bow + xgboost seems to be the most suitable for the system because it is a lot faster than others (infersent and BERT) and its accuracy is not much lower\n",
    "- As for the aspect classifiers, w2v + SVC was chosen due to the same reasons (the full table with comparison of aspect classifiers is available)\n",
    "- The aspects received from the system are not always reasonable, so for some pairs of objects the system may return strange results, but in these cases the summary generated with the help of TextRank gives an understanding of the answer\n",
    "- One of the future work directions is improving aspect extraction (trying sequence labelling and other methods)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
