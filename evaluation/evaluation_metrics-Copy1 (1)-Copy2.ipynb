{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "max_len = 0\n",
    "df = pd.DataFrame(columns=['Object 1', 'Object 2', 'Question', 'Best Answer',  'Answers'])\n",
    "\n",
    "with open('yahoo_answers_positive_questions.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for ind, row in enumerate(reader):\n",
    "        d = {'Object 1': row[0], 'Object 2': row[1], 'Question': row[2], 'Best Answer': row[3],  'Answers': [elem for elem in row[3:]]}\n",
    "        if (ind > 0):\n",
    "            df = df.append(d, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebook/cqas/evaluation\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Question'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from gen import generate_one_answer\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "sys.path.insert(0, \"/notebook/cqas\")\n",
    "sys.path.insert(0, \"/notebook/cqas/generation/gpt-2-Pytorch\")\n",
    "sys.path.insert(0, \"/notebook/cqas/generation/Student\")\n",
    "sys.path.insert(0, \"/notebook/cqas/generation/pytorch_transformers\")\n",
    "\n",
    "from generation.generation import diviner\n",
    "from my_functions import extractor\n",
    "from my_functions import responser\n",
    "\n",
    "from cam_summarize import load_cam_model\n",
    "from text_gen_big import load_big_model\n",
    "from text_gen import load_small_model\n",
    "\n",
    "from ctrl_generation import initialize_model\n",
    "model_type = \"ctrl\" #PUT NAME OF NEEDED MODEL\n",
    "length = 200 #MODEL LENGTH\n",
    "\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, tokenizer, length = initialize_model(model_type, length, device = device)\n",
    "\n",
    "CTRL = diviner(tp = 'ctrl', model = model, device = device, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  9 11:45:29 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 30%   43C    P2    62W / 260W |   8249MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8     7W / 260W |    163MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 36%   47C    P2    56W / 260W |   5728MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   36C    P8    26W / 260W |   7199MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 27%   34C    P8    19W / 260W |  11001MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 27%   35C    P8    30W / 260W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8    10W / 260W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 29%   43C    P2    59W / 260W |   1421MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will be loaded\n",
      "loading gpu 4\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Init extractor: can't map to gpu. Maybe it is OOM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/notebook/cqas/my_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, my_device, model_name, model_path)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaggerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/cqas/src/factories/factory_tagger.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(checkpoint_fn, gpu)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_embeddings_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_seq_indexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu\u001b[0m \u001b[0;31m# hotfix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_ensure_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/cqas/src/models/tagger_base.py\u001b[0m in \u001b[0;36mself_ensure_gpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 4; 10.76 GiB total capacity; 6.30 GiB already allocated; 17.56 MiB free; 91.28 MiB cached)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ea777826ee23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_one_answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmy_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/notebook/cqas/my_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, my_device, model_name, model_path)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"extract_objects_predicates gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Init extractor: can't map to gpu. Maybe it is OOM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspan_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Init extractor: can't map to gpu. Maybe it is OOM"
     ]
    }
   ],
   "source": [
    "#from generation.generation import diviner\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(0, \"/notebook/cqas\")\n",
    "from my_functions import extractor\n",
    "from my_functions import responser\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from gen import generate_one_answer\n",
    "\n",
    "my_extractor = extractor(my_device = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n",
      "\n",
      "in extractor get params 0\n",
      "in batch_to_ids\n",
      "torch.cuda.device_of -1\n",
      "torch.cuda.device_of -1\n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['which', 'next-gen', 'console', 'is', 'the', 'best', 'nitendo', 'sonys', 'ps3', '-', 'microsoft', 'xbox', '360?']\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "We try to use spacy\n",
      "We can't recognize objects for comparision\n",
      "1 \n",
      "\n",
      "\n",
      "in extractor get params 0\n",
      "in batch_to_ids\n",
      "torch.cuda.device_of -1\n",
      "torch.cuda.device_of -1\n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-OBJ', 'O', 'O', 'O', 'O', 'B-OBJ', 'O']\n",
      "extract_objects_predicates words ['wich', 'is', 'better,', 'the', 'sony', 'play', 'station', 'or', 'the', 'microsoft', 'xbox?']\n",
      "['sony', 'microsoft']\n",
      "[]\n",
      "len(objects) 2\n",
      "aspects []\n",
      "weights []\n",
      "get url\n",
      "params {'objectA': 'sony', 'objectB': 'microsoft', 'fs': 'true'}\n",
      "1\n",
      "create fro json predicates []\n",
      "create fro json self.predicates \n",
      "aspects  ['smarter', 'potential', 'stupider'] ['faster', 'quicker', 'easier', 'quicker to its missteps']\n",
      "2\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "type  ctrl\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "self predicate  better\n",
      "answer_begin The sony is better than microsoft. \n",
      "answer_begin_ vs sony vs. microsoft \n",
      "answer_begin_vs sent sony vs. microsoft Sony is a superior hardware manufacturer, much better than both Nintendo and Microsoft.Microsoft is better & 2 times faster than Sony.\n",
      "answer begin:  The sony is better than microsoft. \n",
      "self type ctrl\n",
      "ctrl answer begin1  Links What is better: sony or microsoft?\n",
      "smth wrong in answer generation, please try again\n",
      "2 \n",
      "\n",
      "\n",
      "in extractor get params 0\n",
      "in batch_to_ids\n",
      "torch.cuda.device_of -1\n",
      "torch.cuda.device_of -1\n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['who', 'do', 'you', 'think', 'will', 'win', 'the', 'next-gen', 'war', 'sony(ps3)', 'or', 'microsoft(xbox', '360)', 'or', 'nintendo(revolution)?']\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "We try to use spacy\n",
      "comp_elem or\n",
      "tokens ['Who', 'do', 'you', 'think', 'will', 'win', 'the', 'next', '-', 'gen', 'war', 'Sony(PS3', ')', 'or', 'Microsoft(Xbox', '360', ')', 'or', 'Nintendo(revolution', ')', '?']\n",
      "comp elem in tokens\n",
      "We can't recognize objects for comparision\n",
      "3 \n",
      "\n",
      "\n",
      "in extractor get params 0\n",
      "in batch_to_ids\n",
      "torch.cuda.device_of -1\n",
      "torch.cuda.device_of -1\n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['which', 'do', 'you', 'prefer', \"sony's\", 'ps3', 'or', \"microsoft's\", 'xbox', '360?']\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "We try to use spacy\n",
      "comp_elem or\n",
      "tokens ['Which', 'do', 'you', 'prefer', 'Sony', \"'s\", 'PS3', 'or', 'Microsoft', \"'s\", 'Xbox', '360', '?']\n",
      "comp elem in tokens\n",
      "len(obj2) > 0 and len(obj1) == 0\n",
      "aspects []\n",
      "weights []\n",
      "get url\n",
      "params {'objectA': 'Microsoft', 'objectB': 'and', 'fs': 'true'}\n",
      "create fro json predicates []\n",
      "create fro json self.predicates \n",
      "aspects  ['easier to use', 'friendlier', 'simpler', 'easier'] ['greater', 'older', 'lighter', 'netscape']\n",
      "winnder: and  other: microsoft\n",
      "acpect winner  easier to use, friendlier and simpler\n",
      "acpect other  older, lighter and greater\n",
      "type  ctrl\n",
      "Microsoft has undeniable advantages. They are easier to use, friendlier and simpler.\n",
      "4 \n",
      "\n",
      "\n",
      "in extractor get params 0\n",
      "in batch_to_ids\n",
      "torch.cuda.device_of -1\n",
      "torch.cuda.device_of -1\n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OBJ', 'O', 'B-OBJ', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['ps3', 'or', 'x-box', '360?', 'we', 'all', 'know', 'that', 'these', 'are', 'the', 'latest', 'platforms', 'by', 'sony', 'and', 'microsoft.', 'but', 'which', 'is', 'better?']\n",
      "['sony', 'microsoft.']\n",
      "[]\n",
      "len(objects) 2\n",
      "aspects []\n",
      "weights []\n",
      "get url\n",
      "params {'objectA': 'sony', 'objectB': 'microsoft', 'fs': 'true'}\n",
      "1\n",
      "create fro json predicates []\n",
      "create fro json self.predicates \n",
      "aspects  ['smarter', 'potential', 'stupider'] ['faster', 'quicker', 'easier', 'quicker to its missteps']\n",
      "2\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "type  ctrl\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "self predicate  better\n",
      "answer_begin The sony is better than microsoft. \n",
      "answer_begin_ vs sony vs. microsoft \n",
      "answer_begin_vs sent sony vs. microsoft Sony is a superior hardware manufacturer, much better than both Nintendo and Microsoft.Microsoft is better & 2 times faster than Sony.\n",
      "answer begin:  The sony is better than microsoft. \n",
      "self type ctrl\n",
      "ctrl answer begin1  Links What is better: sony or microsoft?\n",
      "smth wrong in answer generation, please try again\n",
      "5 \n",
      "\n",
      "\n",
      "in extractor get params 0\n",
      "in batch_to_ids\n",
      "torch.cuda.device_of -1\n",
      "torch.cuda.device_of -1\n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['which', 'has', 'the', 'best', 'video', 'games?', 'nintendo?', 'microsoft', 'or', 'sony?']\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "We try to use spacy\n",
      "comp_elem or\n",
      "tokens ['which', 'has', 'the', 'best', 'video', 'games', '?', 'NINTENDO', '?', 'MICROSOFT', 'or', 'SONY', '?']\n",
      "comp elem in tokens\n",
      "aspects []\n",
      "weights []\n",
      "get url\n",
      "params {'objectA': 'MICROSOFT', 'objectB': 'SONY', 'fs': 'true'}\n",
      "1\n",
      "create fro json predicates []\n",
      "create fro json self.predicates \n",
      "aspects  ['smarter', 'greater', 'lither', 'stupider'] ['quicker', 'faster', 'easier', 'quicker to its missteps']\n",
      "2\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter and greater\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "type  ctrl\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter and greater\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "self predicate  better\n",
      "answer_begin The sony is better than microsoft. \n",
      "answer_begin_ vs sony vs. microsoft \n",
      "answer_begin_vs sent sony vs. microsoft Microsoft is better & 2 times faster than Sony.Sony is a superior hardware manufacturer, much better than both Nintendo and Microsoft.\n",
      "answer begin:  The sony is better than microsoft. \n",
      "self type ctrl\n",
      "ctrl answer begin1  Links What is better: microsoft or sony?\n",
      "smth wrong in answer generation, please try again\n",
      "6 \n",
      "\n",
      "\n",
      "in extractor get params 0\n",
      "in batch_to_ids\n",
      "torch.cuda.device_of -1\n",
      "torch.cuda.device_of -1\n",
      "extract_objects_predicates tags ['B-OBJ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['sony', 'ps3', 'vs', 'microsoft', 'xbox', '360', 'vs', 'nintendo', 'wii?']\n",
      "['sony']\n",
      "[]\n",
      "len(objects) 1\n",
      "We try to use spacy\n",
      "comp_elem vs\n",
      "tokens ['Sony', 'Ps3', 'vs', 'Microsoft', 'Xbox', '360', 'vs', 'Nintendo', 'wii', '?']\n",
      "comp elem in tokens\n",
      "aspects []\n",
      "weights []\n",
      "get url\n",
      "params {'objectA': 'sony', 'objectB': 'Microsoft', 'fs': 'true'}\n",
      "1\n",
      "create fro json predicates []\n",
      "create fro json self.predicates \n",
      "aspects  ['smarter', 'potential', 'stupider'] ['faster', 'quicker', 'easier', 'quicker to its missteps']\n",
      "2\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "type  ctrl\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "self predicate  better\n",
      "answer_begin The sony is better than microsoft. \n",
      "answer_begin_ vs sony vs. microsoft \n",
      "answer_begin_vs sent sony vs. microsoft Sony is a superior hardware manufacturer, much better than both Nintendo and Microsoft.Microsoft is better & 2 times faster than Sony.\n",
      "answer begin:  The sony is better than microsoft. \n",
      "self type ctrl\n",
      "ctrl answer begin1  Links What is better: sony or microsoft?\n",
      "smth wrong in answer generation, please try again\n",
      "7 \n",
      "\n",
      "\n",
      "in extractor get params 0\n",
      "in batch_to_ids\n",
      "torch.cuda.device_of -1\n",
      "torch.cuda.device_of -1\n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'B-OBJ', 'O', 'O', 'O', 'B-OBJ', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'is', 'worth', 'buying', 'the', 'sony', 'ps3', 'or', 'the', 'microsoft', 'xbox', '360?????????']\n",
      "['sony', 'microsoft']\n",
      "[]\n",
      "len(objects) 2\n",
      "aspects []\n",
      "weights []\n",
      "get url\n",
      "params {'objectA': 'sony', 'objectB': 'microsoft', 'fs': 'true'}\n",
      "1\n",
      "create fro json predicates []\n",
      "create fro json self.predicates \n",
      "aspects  ['smarter', 'potential', 'stupider'] ['faster', 'quicker', 'easier', 'quicker to its missteps']\n",
      "2\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "type  ctrl\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "self predicate  better\n",
      "answer_begin The sony is better than microsoft. \n",
      "answer_begin_ vs sony vs. microsoft \n",
      "answer_begin_vs sent sony vs. microsoft Sony is a superior hardware manufacturer, much better than both Nintendo and Microsoft.Microsoft is better & 2 times faster than Sony.\n",
      "answer begin:  The sony is better than microsoft. \n",
      "self type ctrl\n",
      "ctrl answer begin1  Links What is better: sony or microsoft?\n",
      "smth wrong in answer generation, please try again\n",
      "8 \n",
      "\n",
      "\n",
      "in extractor get params 0\n",
      "in batch_to_ids\n",
      "torch.cuda.device_of -1\n",
      "torch.cuda.device_of -1\n",
      "extract_objects_predicates tags ['O', 'B-OBJ', 'O', 'B-OBJ', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['if', 'sony', 'vs', 'microsoft,', 'who', 'will', 'win?', 'thanks.?']\n",
      "['sony', 'microsoft,']\n",
      "[]\n",
      "len(objects) 2\n",
      "aspects []\n",
      "weights []\n",
      "get url\n",
      "params {'objectA': 'sony', 'objectB': 'microsoft', 'fs': 'true'}\n",
      "1\n",
      "create fro json predicates []\n",
      "create fro json self.predicates \n",
      "aspects  ['smarter', 'potential', 'stupider'] ['faster', 'quicker', 'easier', 'quicker to its missteps']\n",
      "2\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "type  ctrl\n",
      "winnder: sony  other: microsoft\n",
      "acpect winner  smarter\n",
      "acpect other  quicker, faster and quicker to its missteps\n",
      "self predicate  better\n",
      "answer_begin The sony is better than microsoft. \n",
      "answer_begin_ vs sony vs. microsoft \n",
      "answer_begin_vs sent sony vs. microsoft Sony is a superior hardware manufacturer, much better than both Nintendo and Microsoft.Microsoft is better & 2 times faster than Sony.\n",
      "answer begin:  The sony is better than microsoft. \n",
      "self type ctrl\n",
      "ctrl answer begin1  Links What is better: sony or microsoft?\n",
      "smth wrong in answer generation, please try again\n",
      "9 \n",
      "\n",
      "\n",
      "in extractor get params 0\n",
      "in batch_to_ids\n",
      "torch.cuda.device_of -1\n",
      "torch.cuda.device_of -1\n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['whats', 'the', 'difference', 'between', 'rat', 'and', 'mouse?']\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "We try to use spacy\n",
      "We can't recognize objects for comparision\n",
      "10 \n",
      "\n",
      "\n",
      "in extractor get params 0\n",
      "in batch_to_ids\n",
      "torch.cuda.device_of -1\n",
      "torch.cuda.device_of -1\n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'B-OBJ', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'is', 'the', 'difference', 'between', 'a', 'rat', 'and', 'a', 'mouse?']\n",
      "['rat']\n",
      "[]\n",
      "len(objects) 1\n",
      "We try to use spacy\n",
      "len(obj1) > 0 and len(obj2) == 0\n",
      "aspects []\n",
      "weights []\n",
      "get url\n",
      "params {'objectA': 'rat', 'objectB': 'and', 'fs': 'true'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ee088a4e73c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mansw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_one_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_extractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCTRL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mansw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mgpt_answ_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mansw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/cqas/evaluation/gen.py\u001b[0m in \u001b[0;36mgenerate_one_answer\u001b[0;34m(input_string, my_extractor, my_diviner)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"len(obj1) > 0 and len(obj2) == 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmy_responser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'and'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpredicate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredicates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mresponse_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/cqas/my_functions.py\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(self, first_object, second_object, fast_search, aspects, weights)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"get url\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Object 1', 'Object 2', 'Question', 'Best Answer',  'Answers'])\n",
    "\n",
    "with open('yahoo_answers_positive_questions.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for ind, row in enumerate(reader):\n",
    "        d = {'Object 1': row[0], 'Object 2': row[1], 'Question': row[2], 'Best Answer': row[3],  'Answers': [elem for elem in row[3:]]}\n",
    "        if (ind > 0):\n",
    "            df = df.append(d, ignore_index=True)\n",
    "\n",
    "\n",
    "gpt_answ_list = []\n",
    "for ind, qw in enumerate(df['Question'].values[:10]):\n",
    "    print (ind, '\\n\\n')\n",
    "    answ = generate_one_answer(qw, my_extractor, CTRL)\n",
    "    print (answ)\n",
    "    gpt_answ_list.append(answ)\n",
    "\n",
    "with open('ctrl.pkl', 'wb') as f:\n",
    "    pickle.dump(templ_answ_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  8 12:43:58 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 29%   43C    P2    62W / 260W |   8249MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8     8W / 260W |    163MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 30%   43C    P8     4W / 260W |   5453MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   35C    P8    25W / 260W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8    17W / 260W |   2181MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 27%   34C    P8    30W / 260W |   1065MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8     9W / 260W |    959MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 28%   42C    P2    59W / 260W |   1421MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    2      1662      C   python3                                      861MiB |\n",
      "|    5      1662      C   python3                                     1055MiB |\n",
      "|    6      1662      C   python3                                      949MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"We can't recognize objects for comparision\",\n",
       " \"We can't recognize objects for comparision\",\n",
       " \"We can't recognize objects for comparision\",\n",
       " 'microsoft has undeniable advantages. They are simpler, friendlier and easier to use.',\n",
       " \"We can't recognize objects for comparision\",\n",
       " 'The sony is better than microsoft. The reason are greater and smarter. \\xa0The kudu is smarter than microsoft. The reason are the kudu is bigger and better. \\xa0The kudu is better for its price.A good game. \\xa0A good game made with people who understand the game. \\xa0A good game made with people who understand the game. \\xa0A good game made with people who understand the game. \\xa0A good game made with people who understand the game. \\xa0A good game made with people who understand the game. \\xa0A good game made with people who understand the game.If you\\'re a big fan of a game - do you know how many people are trying to get it? \\xa0You can find out with the numbers below. \\xa0You might be thinking, \"What if I\\'m playing a lot of games in the space of a month? \\xa0What if I\\'m playing a lot of games in the space of a year?\" \\xa0Well, that\\'s',\n",
       " \"The microsoft is better than wii. The reason are greater, faster and simpler. \\xa0The controller is made from a 1.2mm thick foam, which is much thicker and more flexible than wii ball. \\xa0This is a good thing for the user because it means that the microsoft will give you a better experience with the controller. \\xa0This is the reason that the microsoft has been running its own 3D controller. \\xa0The 3D controller is so much more powerful than the wii controller that it is so much better. \\xa0There are three main ways to achieve this. \\xa01) If you don't have a wii. 2) If you want to play wii. \\xa03) If you want to play wii. \\xa0The only way to play wii is to buy a wii ball.1. \\xa0The wii ball.If you don't have a wii ball, you can buy wii ball as a freebie or you can buy a wii ball (or you\",\n",
       " 'ps3 has undeniable advantages. They are easier, easier to use and lighter.',\n",
       " \"We can't recognize objects for comparision\",\n",
       " \"The rat is better than mouse. The reason are greater and easier. \\xa0But the rat is much more dangerous than the mouse. \\xa0The rats need to be trained to see. \\xa0The rat needs to be trained to eat. \\xa0The rat needs to be trained to eat. \\xa0It's not a good fit. \\xa0The rat has to be trained to think. \\xa0It has to be trained to make decisions. \\xa0The rat has to be trained to think. \\xa0It has to be trained to make choices. \\xa0It has to be trained to be creative. \\xa0The rat has to be trained to be creative. \\xa0It has to be trained to be innovative. \\xa0To be innovative, the rat needs to be creative. \\xa0To be innovative, the rat needs to be creative. \\xa0The rat needs to be creative. \\xa0The rat needs to be creative. \\xa0But the rat will grow even more creative.<|endoftext|>The New York Police Department will conduct a criminal investigation of a\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_answers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"We can't recognize objects for comparision\",\n",
       " \"We can't recognize objects for comparision\",\n",
       " \"We can't recognize objects for comparision\",\n",
       " 'microsoft has undeniable advantages. They are simpler, friendlier and easier to use.',\n",
       " \"We can't recognize objects for comparision\",\n",
       " 'The sony is better than microsoft. The reason are greater and smarter. Which is one of the areas that Sony is better than Microsoft. Apparently, talks with Sony are going better than those with Microsoft. In my opinion, Sony has had better customer support than Microsoft. As well, the catalog of Sony \"Only\" games is far better than Microsoft. I don\\'t think the point here is to say Microsoft is worse than Sony or Nintendo cause Microsoft is not.\\nMicrosoft also has a better Day One lineup than Sony does. Microsoft: Our first party games are superior to Sony and Nintendo\\'s . Worse even than Microsoft WMA (Napster et al), in fact: . The fact is Microsoft has a much better (easier to use) SDK for games than Sony does. Suddenly I find myself liking Microsoft much better than Sony!',\n",
       " 'The microsoft is better than wii. The reason are greater, faster and simpler. Microsoft said consumers spent a greater amount of money on Xbox 360 than the PS3 and Wii combined. Microsoft is doing a better job selling Wii U than Nintendo is. Yes it was a flop in terms of Core games but was better than Move and Wii Mote for games like this. Killer Instinct is shaping up to have better motion controls than Guilty Gear Accent Core on the Wii! Much better than the Netflix interface on the Xbox 360 or the wii.\\nI will be laughing so hard when Xbox One bombs and does even worse than Wii U . So yeah, mark my words, Microsoft, nor Sony are going to do that much better if any than Nintendo Wii U. . Wii U is virtually guaranteed to be easier to develop for than forthcoming Sony and Microsoft machines! Nintendo president Satoru Iwata has promised that the Wii U will be much better equipped to keep pace with Microsoft and Sony\\'s next consoles. It might even be worse than \"Wii U,\" though I doubt there will be the same level of confusion around this.',\n",
       " 'ps3 has undeniable advantages. They are easier, easier to use and lighter.',\n",
       " \"We can't recognize objects for comparision\",\n",
       " 'The rat is better than mouse. The reason are greater and easier. Fewer total small-diameter neurons from rat responded to CINN, but the responsive neurons in rat had greater response amplitudes than those from mouse ( Figs. 5A, B ). Fewer total small-diameter neurons from rat responded to CINN, but the responsive neurons in rat had greater response amplitudes than those from mouse (Figs. 5A, B). However, under nonreducing and reducing conditions, mouse perforin had a slower mobility than human and rat perforin expressed in both cells. Th e rat is highly suitable for seeking a better understanding of human genetics and biology because the rat in many ways better resembles human pathology, physiology, neurology, and cancer biology than other popular animal models, such as the mouse. Recombinant rat CYP2E1 exhibited greater affinity and catalytic efficiency for DCE metabolism than did recombinant human CYP2E1, mouse CYP2F2, goat CYP2F3 or rat CYP2F4.\\nAt the year point it stopped working completely and I went back to my Logitech MX518 which I believe works better than the RAT did. These results indicate that the sandwich-cultured primary mouse hepatocyte system is robust and seems to maintain its metabolic competence better than that of the rat hepatocyte system... . Feature: Eco-Friendly Place of Origin: Fujian China (Mainland) Brand Name: TNL Color: Black Material: ABS mouse trap \\xa0mechanical trap 1)A state-of-the-art mechanical trap that offers superior rat capture.2)Interlocking teeth make rat escap...... A combination of mouse and guinea pig transcriptomes was used because the annotation of the mouse genome is better than that of the guinea pig while the guinea pig genome is more similar to that of the naked mole-rat. Finally, the mouse appeared to be a better animal model than the rat for exploring the intestinal absorption and pharmacokinetics of peptides and peptide-like drugs in human... .']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_answers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gpt_arr = np.array([elem[0] for elem in gpt_score['rouge1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6423829141580153"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cam_answers1.pkl', 'rb') as f:\n",
    "    cam_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object 1</th>\n",
       "      <th>Object 2</th>\n",
       "      <th>Question</th>\n",
       "      <th>Best Answer</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>sony</td>\n",
       "      <td>which next-gen console is the best NITENDO SON...</td>\n",
       "      <td>How can you even ask this question yet? Only t...</td>\n",
       "      <td>[How can you even ask this question yet? Only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>sony</td>\n",
       "      <td>wich is better, the Sony play station or the M...</td>\n",
       "      <td>For a wide selection, choose PS2. However, XBO...</td>\n",
       "      <td>[For a wide selection, choose PS2. However, XB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>sony</td>\n",
       "      <td>Who do you think will win the next-gen war Son...</td>\n",
       "      <td>PS3 hands down</td>\n",
       "      <td>[PS3 hands down, PS3 hands down, I think Sony ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>sony</td>\n",
       "      <td>Which do you prefer Sony's PS3 or Microsoft's ...</td>\n",
       "      <td>I'll comment on PS3 when it's out but I am loo...</td>\n",
       "      <td>[I'll comment on PS3 when it's out but I am lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>sony</td>\n",
       "      <td>PS3 or X-BOX 360? We all know that these are t...</td>\n",
       "      <td>I'm sure you knew when you posted this that we...</td>\n",
       "      <td>[I'm sure you knew when you posted this that w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Object 1 Object 2                                           Question  \\\n",
       "0  microsoft     sony  which next-gen console is the best NITENDO SON...   \n",
       "1  microsoft     sony  wich is better, the Sony play station or the M...   \n",
       "2  microsoft     sony  Who do you think will win the next-gen war Son...   \n",
       "3  microsoft     sony  Which do you prefer Sony's PS3 or Microsoft's ...   \n",
       "4  microsoft     sony  PS3 or X-BOX 360? We all know that these are t...   \n",
       "\n",
       "                                         Best Answer  \\\n",
       "0  How can you even ask this question yet? Only t...   \n",
       "1  For a wide selection, choose PS2. However, XBO...   \n",
       "2                                     PS3 hands down   \n",
       "3  I'll comment on PS3 when it's out but I am loo...   \n",
       "4  I'm sure you knew when you posted this that we...   \n",
       "\n",
       "                                             Answers  \n",
       "0  [How can you even ask this question yet? Only ...  \n",
       "1  [For a wide selection, choose PS2. However, XB...  \n",
       "2  [PS3 hands down, PS3 hands down, I think Sony ...  \n",
       "3  [I'll comment on PS3 when it's out but I am lo...  \n",
       "4  [I'm sure you knew when you posted this that w...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'templates_answers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9dea60166542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemplates_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Answers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'templates_answers' is not defined"
     ]
    }
   ],
   "source": [
    "templates_answers[ind]\n",
    "df['Answers'].values[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from count_rouge import simple_rouge, rouge_cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_embedding import BertEmbedding\n",
    "bert_embedding = BertEmbedding()\n",
    "\n",
    "\n",
    "def rouge_cos(gen_answers, possible_answers):\n",
    "    list_of_n1 = []\n",
    "    list_of_n2 = []\n",
    "    for ind, elem in enumerate(gen_answers):\n",
    "        print (ind)\n",
    "        if (elem != \"We can't recognize objects for comparision\"):\n",
    "            ngrams1 = create_ngrams(tokenizer.tokenize(elem), 1)\n",
    "            answ_token_list = [tokenizer.tokenize(elemt) for elemt in possible_answers[0]]\n",
    "            scores_list_1 = [score_ngrams(ngrams1, create_ngrams(possible_answ, 1)) for possible_answ in answ_token_list]\n",
    "            sorted_scores_1 = sorted(scores_list_1, key=lambda x: x[0], reverse = True)\n",
    "            #print (\"target1\", sorted_scores_1[0])\n",
    "            list_of_n1.append(sorted_scores_1[0])\n",
    "            #print (ind, \"n2\")\n",
    "            ngrams01 = create_ngrams(tokenizer.tokenize(elem), 2)\n",
    "            scores_list_2 = [score_ngrams(ngrams01, create_ngrams(possible_answ, 2)) for possible_answ in answ_token_list]\n",
    "            sorted_scores_2 = sorted(scores_list_2, key=lambda x: x[0], reverse = True)\n",
    "            #print (\"target2\", sorted_scores_2[0])\n",
    "            list_of_n2.append(sorted_scores_2[0])\n",
    "    return {'rouge1':list_of_n1, 'rouge2':list_of_n2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "cam_answ = rouge_cos(cam_answers, df['Answers'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-93733aa6225f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cam_answers.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open('cam_answers.pkl', 'rb') as f:\n",
    "    ll = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cam_score.pkl', 'wb') as f:\n",
    "    pickle.dump(cam_answ, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gpt_score.pkl', 'wb') as f:\n",
    "    pickle.dump(gpt_answ, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_answ = rouge_cos(gpt_answers, df['Answers'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "templ_array = np.array([elem.fmeasure for elem in templ_answ['rouge1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(templ_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-e231a59ec562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmeasure\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtempl_answ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-e231a59ec562>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmeasure\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtempl_answ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([elem['rouge1'].fmeasure for elem in templ_answ['rouge1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores_1 = sorted(scores, key=lambda x: x['rouge1'].fmeasure, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge1': Score(precision=0.04081632653061224, recall=0.2857142857142857, fmeasure=0.07142857142857142),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0)},\n",
       " {'rouge1': Score(precision=0.04081632653061224, recall=0.2857142857142857, fmeasure=0.07142857142857142),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0)},\n",
       " {'rouge1': Score(precision=0.022727272727272728, recall=0.5714285714285714, fmeasure=0.04371584699453552),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0)},\n",
       " {'rouge1': Score(precision=0.01694915254237288, recall=0.14285714285714285, fmeasure=0.030303030303030297),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0)},\n",
       " {'rouge1': Score(precision=0.012269938650306749, recall=0.5714285714285714, fmeasure=0.024024024024024024),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0)}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_scores_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "for ind, elem in enumerate(answer_big):\n",
    "    print (ind, \"target1\")\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(elem, list_of_target1[ind])\n",
    "    print (scores)\n",
    "    print (ind, \"target2\")\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(elem, list_of_target2[ind])\n",
    "    print (scores)\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('template_answers.pkl', 'rb') as f:\n",
    "    templates_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'number_of_unrecognizing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-0b2d3c22e784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnumber_of_unrecognizing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'number_of_unrecognizing' is not defined"
     ]
    }
   ],
   "source": [
    "number_of_unrecognizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_unrecognizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which next-gen console is the best NITENDO SONYS  PS3 - MICROSOFT XBOX 360?\n",
      "wich is better, the Sony play station or the Microsoft XBOX?\n",
      "Who do you think will win the next-gen war Sony(PS3) or Microsoft(Xbox 360) or Nintendo(revolution)?\n",
      "PS3 or X-BOX 360? We all know that these are the latest platforms by SONY and MICROSOFT. But which is better?\n",
      "If Sony Vs Microsoft, who will win? Thanks.?\n",
      "What is the brief summary of the differences and similarities between Apple and IBM?\n",
      "What's  the best notebook brand and why? Dell, Sony Vaio, Apple, Toshiba, IBM, ... ? (in general comparison)\n",
      "Would you rather have an iPod or a PSP or a Cell Phone!?\n",
      "compare and contrast Honda Fit and Toyota Yaris. Which is better? Mileage and storage space wise?\n",
      "what would be better to buy a Toyota matrix or a Honda CR-V?\n",
      "Is Honda Civic better than Toyota Corolla?\n",
      "Is a Toyota Corolla better than a Honda Accord?\n",
      "Is a PSP better than a Nintendo DS in all aspects?\n",
      "Which Is Better: The Nintendo DS or The Sony PSP?\n",
      "What's the differerance between PSP, Nitendo DS, GameBoy Advance SP?\n",
      "Is Nintendo DS better than PSP?\n",
      "PSP DS GBA GBC NGAGE. which is better?\n",
      "What do you think is better the Nintendo DS or the PSP.?\n",
      "Which seventh generation video game system (Wii, XBOX 360, Nintendo DS, PSP, PS3) will be best?\n",
      "Which one is better to get a Game Boy Micro, Nintendo DS, or a PSP as a portable handheld system ?\n",
      "which do u think is best-->NOKIA,SAMSUNG,SONY ERICSSON?\n",
      "ALCATEL,LG,MOTOROLA,NOKIA,PANASONIC,SAMSUNG,SANYO,SIEMENS,SONY ERICSSION,SHARP....which is best mobile to use?\n",
      "Among Nokia,Sony,Samsung Mobiles phone available in India ..which one is better?\n",
      "What are the strengths, weaknesses and affordability for HP, Apple and Dell computors and laptops?\n",
      "What's  the best notebook brand and why? Dell, Sony Vaio, Apple, Toshiba, IBM, ... ? (in general comparison)\n",
      "Who makes the best/economical laptop tablets (notebooks)? Dell, IBM, HP????\n",
      "What's the best pc on the market DELL IBM OR HP?\n",
      "What's the best brand of Laptop you know? hp, IBM, Dell, etc?\n",
      "Whis is better Laptop-IBM /Dell/HP/Compaq/Acer?\n",
      "What are some advantages and disadvantages of IBM, Dell, and Hewlett Packard?\n",
      "What's  the best notebook brand and why? Dell, Sony Vaio, Apple, Toshiba, IBM, ... ? (in general comparison)\n",
      "DELL INSPIRONE1505, HP PAVILIONDV1677EA,IBM LENOVO 3000N100(TY04BXX) Which Notebook  is the best Buy?\n",
      "What model truck is better Toyota,Ford,Chevy,Dodge,Nissan?\n",
      "What model truck is better Toyota,Ford,Chevy,Dodge,Nissan?\n",
      "What is your opinion on GM vs. Toyota vs. Ford??\n",
      "What model truck is better Toyota,Ford,Chevy,Dodge,Nissan?\n",
      "Is the PSP better than the PS2???\n",
      "how is PSP's graphics?? is it worth buying it ??..can it be compared to PS2??..i dont wanna be place depndt\n",
      "Worst cable news, CNN, CNBC, MSNBC, CNN Headline, FOX?\n",
      "Who makes a good DVD Burner and LCD Monitor?? Dell?? Sony?? HP?? NEC?? Samsung?? or someone else?\n",
      "What's  the best notebook brand and why? Dell, Sony Vaio, Apple, Toshiba, IBM, ... ? (in general comparison)\n",
      "ALCATEL,LG,MOTOROLA,NOKIA,PANASONIC,SAMSUNG,SANYO,SIEMENS,SONY ERICSSION,SHARP....which is best mobile to use?\n",
      "Which brands (LG, Motorola, Samsung, etc.)of cell phones get the best reception?\n",
      "Wich phone would you prefer? -Samsung d807, -Motorola SLVR L7, -Sony-Ericsson W600i?\n",
      "ALCATEL,LG,MOTOROLA,NOKIA,PANASONIC,SAMSUNG,SANYO,SIEMENS,SONY ERICSSION,SHARP....which is best mobile to use?\n",
      "ALCATEL,LG,MOTOROLA,NOKIA,PANASONIC,SAMSUNG,SANYO,SIEMENS,SONY ERICSSION,SHARP....which is best mobile to use?\n",
      "Which Company is Good in Mobile ; Nokia , Motorola , Sony Ericsson?\n",
      "Which is best one sonyericsson K 750 i,Nokia 3230, Motorola V3i?\n",
      "which mobile resell value count more...Nokia,Sony,Motorola,LG..?\n",
      "Is Ruby better than PHP/C# in any way and is Rails all that?\n",
      "What is the best way to build and e-commerce site and why? (Joomla, MySQL/PHP, RubyOnRails?)?\n",
      "compare Honda Pilot to Nissan Pathfinder as far as price, comfort and safety?\n",
      "Which is better, The Nissan Altima SE-R or the Honda Accord?\n",
      "Should I buy an Apple ibook laptop or a Sony laptop?\n",
      "What's  the best notebook brand and why? Dell, Sony Vaio, Apple, Toshiba, IBM, ... ? (in general comparison)\n",
      "what is the different between Windows Xp & Windows Vista?\n",
      "Is Windows Vista Beta 2 better than Windows XP?\n",
      "How much better will be the PS3 than PS2?\n",
      "To people who have seen a PS3, how much better are the graphics than PS2?\n",
      "How is the new PS3 gonna be better than the PS2?\n",
      "what're the best shoes for running? Adidas, Nike, Rebook, Puma..?\n",
      "Which is the best brand ADIDAS OR NIKE?\n",
      "What is the basic difference between Intel & Apple processors?\n",
      "compare the differences between ms-dos windows 98 windows 30 windows xp windows nt and windows 2000?\n",
      "What are the pros and cons of Windows XP, compared to Windows 98?\n",
      "which is a better value? PS2 of Wii?\n",
      "How much different would the world be if Bobby Kennedy had been elected president in 1968 instead of Nixon?\n",
      "which team will win F1 title from these teamsMclaren Renault Ferrari  Honda?\n",
      "How does the 2006 Audi A6 compare to the Lexus ES 300?\n",
      "Would you prefer the Audi A3 or the Lexus IS 250?  Why?\n",
      "Is Python programming language better suited for web development than PHP?\n",
      "Which state would you rather live in: Texas, Oklahoma, Arkansas, Tennessee, Kentucky, Georgia, N. Carolina?\n",
      "PS3 AND NINTENDO Wii which one is the best console?\n",
      "What is the new game system you want the most, the Nintendo Wii, PS3, or Xbox 360?\n",
      "Which one are going to buy this year PS3, 360, or Wii? and  Why?\n",
      "Which is better a Xbox360,PS3,or Nintendo Wii?\n",
      "Which is better ? PS3 Or Nintendo -Wii or Xbox 360?\n",
      "What's the best game system,Xbox360~Wii~or PS3?\n",
      "Which will win? Wii Vs. Xbox360 Vs. PS3?\n",
      "What do people have against the Wii? Cant they see that PS3 & xbox arent even in the same category?\n",
      "What should I buy, what one is better? PS3, Wii, XBOX360?\n",
      "Which r better 1 PS3 OR WII?\n",
      "Whats Better?? PS3 OR NINTENDO WII??\n",
      "which would you prefer: XBOX360, Nintendo Wii, PS3? Why?\n",
      "Which system will win this holiday? (NinTendo Wii, XBOX 360 or PS3)?\n",
      "Which video game system do you think will be the biggest seller, PS3, Nintendo Wii, Or X-box 360?\n",
      "Wat system should i get-360? Wii? Ps3?\n",
      "What is the best System? 360 Wii or PS3?\n",
      "Which should I get a PS3, Nintendo Wii, or X-bOX 360? and why?\n",
      "PS3 - Wii - Xbox360?----Best one----?\n",
      "Xbox306 vs. Sony PS3 vs. Nintendo Wii...Battle Royale! Who will come out on top and why?\n",
      "Now that the PS3, 360, and the Wii are all out, which game system is selling the most.?\n",
      "out of all next gen systems (PS3, Xbox 360, Wii) whats the best?\n",
      "Which is better Wii Ps3?\n",
      "what do you think of the N. Wii, and how do you compare it to the PS3 and Xbox?\n",
      "PS3 vs X-box 360 vs Nintendo Wii?\n",
      "Which seventh generation video game system (Wii, XBOX 360, Nintendo DS, PSP, PS3) will be best?\n",
      "What next-Gen console will win Wii, PS3,Xbox360?\n",
      "How do you think the Nintendo Wii (revolution) go up against the PS3.?\n",
      "Video game wars! Who will win (Xbox 360, PS3 , Wii)? What game are you most looking forward to?\n",
      "What game system should I buy next PS3,Wii, or the 360?\n",
      "Whats the best out of the Ps3, Xbox 360,and the Nintendo Wii???????\n",
      "Which seventh generation video game system (Wii, XBOX 360, Nintendo DS, PSP, PS3) will be best?\n",
      "Which seventh generation video game system (Wii, XBOX 360, Nintendo DS, PSP, PS3) will be best?\n",
      "How is Chevrolet Aveo 1.4 in India?How is its service network in India as compared to Ford/Honda,etc?\n",
      "Which is better The Wii Xbox 360 Playstation 3?\n",
      "Which system should I ask for Christmas? - Xbox 360, Nintendo Wii, or the Playstation 3?\n",
      "Do you think I should get a PLAYSTATION 3, OR A NINTENDO WII?\n",
      "Which one is better of these systems: Nintendo Wii, Xbox 360, PlayStation 3?\n",
      "Which is better, the Xbox preminum 360, Nintendo Wii, or Playstation 3?\n",
      "Is the Playstation 3 better than the Wii??\n",
      "PlayStation 3-XboX 360-Nintendo Wii which console is more innovative of them all???\n",
      "Which will be better, Wii, Xbox 360, Playstation 3?\n",
      "Will the game play for the Legend of Zelda Twilight Princess be different on the Wii system than the Gamecube?\n",
      "Which seventh generation video game system (Wii, XBOX 360, Nintendo DS, PSP, PS3) will be best?\n",
      "Any opinions of a Toshiba MK8032GSX hard drive versus Samsung HM080II?\n",
      "Which seventh generation video game system (Wii, XBOX 360, Nintendo DS, PSP, PS3) will be best?\n"
     ]
    }
   ],
   "source": [
    "number_of_unrecognizing = 0\n",
    "\n",
    "for ind, elem in enumerate(templates_answers):\n",
    "    if (elem == \"We can't recognize objects for comparision\"):\n",
    "        print (df['Question'].values[ind])\n",
    "        number_of_unrecognizing += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can't recognize objects for comparision\n",
      "which next-gen console is the best NITENDO SONYS  PS3 - MICROSOFT XBOX 360?\n",
      "I came to the conclusion that sony is better, because of  and smarter. But it will be useful for you to know that microsoft is quicker, quicker to its missteps and faster.\n",
      "wich is better, the Sony play station or the Microsoft XBOX?\n",
      "We can't recognize objects for comparision\n",
      "Who do you think will win the next-gen war Sony(PS3) or Microsoft(Xbox 360) or Nintendo(revolution)?\n",
      "We can't recognize objects for comparision\n",
      "Which do you prefer Sony's PS3 or Microsoft's Xbox 360?\n",
      "I came to the conclusion that sony is better, because of  and smarter. But you should know that microsoft is quicker, quicker to its missteps and faster.\n",
      "PS3 or X-BOX 360? We all know that these are the latest platforms by SONY and MICROSOFT. But which is better?\n",
      "Looks like sony is better, because of smarter and greater. But i should tell you that microsoft is quicker to its missteps, quicker and easier.\n",
      "which has the best video games? NINTENDO? MICROSOFT or SONY?\n",
      "I came to the conclusion that sony is better, because of  and smarter. Microsoft is quicker, quicker to its missteps and faster.\n",
      "Sony Ps3 vs Microsoft Xbox 360 vs Nintendo wii?\n",
      "After much thought, I realized that  sony is better, because of  and smarter. But it will be useful for you to know that microsoft is quicker, quicker to its missteps and faster.\n",
      "What is worth buying  the Sony PS3 or the Microsoft XBOX 360?????????\n",
      "After much thought, I realized that  sony is better, because of  and smarter. But you should know that microsoft is quicker, quicker to its missteps and faster.\n",
      "If Sony Vs Microsoft, who will win? Thanks.?\n",
      "We can't recognize objects for comparision\n",
      "Whats the difference between Rat and mouse?\n"
     ]
    }
   ],
   "source": [
    "for ind, elem in enumerate(templates_answers[:10]):\n",
    "    print (elem)\n",
    "    print (df['Question'].values[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "  \n",
    "# reading csv file  \n",
    "ds = pd.read_csv(\"Evaluation dataset - Sheet1 (1).csv\") \n",
    "list_of_target1 = ds['Q1']\n",
    "list_of_target2 = ds['Q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It's simple! honda is better, because: quicker, bigger, nicer, weaker.. But you should know that toyota is: lighter, easier, faster, softer.\",\n",
       " 'I would prefer motorolla than nokia.',\n",
       " 'I would prefer sumsung than nokia.',\n",
       " 'Looks like php is better, because: easier to learn, easier to pick up for a noob, easier, java.. But it will be useful for you to know that javascript is: animation, easier to understand, faster, features.',\n",
       " 'I would prefer to use ruby because it is: easier, easier to read, easier to learn, simpler.. But i should tell you that perl is: faster, cleaner, faster to write in ruby, safer.',\n",
       " 'after much thought, I realized that  aluminium is better, because: faster, lighter, easier to mod, greater., but steel is: particles, drinks, ability, cks.',\n",
       " 'I would prefer to use juice because it is: greater, faster, vitamen, water.. But you should know that beer is: lighter, better for you, easier, worse for your teeth.',\n",
       " 'i came to the conclusion that tea is better, because: easier, greater, better for the mind and body to chat while sipping cups of assam and sencha, better to have extra beer left over.. But it will be useful for you to know that beer is: safer, colors, coffee, beverages.',\n",
       " \"It's simple! iphone is better, because: lighter, bigger, device, greater.. But it will be useful for you to know that laptop is: easier to see, experience, easier for an attacker to get to simply because an attacker can get a phone easier, louder.\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores - mean[max(gen, answ_i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rouge(list_of_generated_answers, list_of_best_answers, list_of_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f591f02109f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmy_diviner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTempl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_given_qwestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"qwestion \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_extractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_diviner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "my_diviner = Templ\n",
    "\n",
    "for elem in list_of_given_qwestions[45]:\n",
    "    print (\"qwestion \", elem)\n",
    "    answer = generate_answer(my_extractor, my_diviner, elem)\n",
    "    print (\"answer \", answer)\n",
    "    list_of_template_answers.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why tea is better than beer is because it is very good for your body. You need to drink more tea than beer. When you drink tea, you need less alcohol. This is why tea is better than beer. How long it takes to make a cup of tea?\n",
    "It is a long process. You need to wash your tea leaves and boil them, and then you need to boil them again. To make more tea, you need to boil the tea again. You need to boil the tea for at least one hour. Beer is life.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like tea, but seriously, there is no debate here at all. Beer is life. Why? Because beer goes with pizza. Isnt that enough? Beer makes you social. Would you ever hang out with a person who drinks nothing than tea? If beer was bad, monks wouldt sell it. I had the best time in my life while drinking beer. I tasted like 300 different beers, while only 1020 different type of teas. Beer makes me happy, tea makes me nervous. We say, Let me buy you a beer. But how that sounds, Let me buy you a tea'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_target2[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_big = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_big.append(sttr9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr1 = \"honda is better than toyota because it is quicker, bigger, nicer. The problem is that Honda is not the only one. Toyota has always been the king of the car world. There are a lot of other companies that have created the cars that people love. They do it for the money. But Toyota is the one that has to compete with Honda and Chevrolet. It has to produce cars that people want to buy.I am still not convinced that Toyota will ever get to that level. But it is not impossible. It is just a matter of time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr2 = \"Motorola is better than Nokia. And I'm not sure I've ever heard of a company that's better than Samsung. This is not a bad thing. I am not sure Samsung does a better job than Nokia.Well, it depends what you expect from a phone. If you want good build quality and regular software updates do not ever think of buy a phone of Chinese or Chinese-owned brand (except the phones running on Android One). If you have a tight budget, then you can proceed with Moto. Since Nokias phone are a bit overpriced, you may get one at reasonable price during sales. Also, the Nokia-exclusive Zeiss optics dont have any competitor in their price range. If you want a Moto X4, then Nokia 7 Plus is always ahead. But if you want G5S Plus, then go on with it because Nokia 2.1 or 3.1 are the only available phones from Nokia and have a bit low specs. However you can go on for Nokia 6.1 or 6.1 Plus over Moto G6 because of their build quality and stock software anlog with regular updates and security patches.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr3 = \"Samsung is better than Nokia. Nokia has no market share in the mobile phone industry, and it is not profitable. The company's strategy is to sell its devices to customers in China, and it is trying to win a share of the Chinese market. Samsung is also better than Nokia. Samsung has a high growth rate and is trying to establish itself as a leading player in the mobile phone industry. But Samsung has a long way to go to regain its market position. Samsung is now the second largest phone manufacturer in the world after Apple. The Nokia deal was announced in April, but it was not fully resolved until the end of July.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr4 = \"Php is better than javascript because it is easier to learn, easier to pick up. You should not use the PHP version of your application.You should not use the PHP version of your application. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. The PHP version of your application is not required to work, but it may prove to be beneficial. PHP is not required to work, but it may prove to be beneficial. You will not lose your development experience by using PHP. You will not lose your development experience by using PHP. PHP has a very advanced feature set. PHP has a very advanced feature set. PHP provides a very rich set of functions and modules. PHP provides a very rich set of functions and modules. PHP provides a high degree of flexibility and conciseness.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr5 = \"Ruby is better than Python because ruby because it is: easier, easier to read, easier to learn, simpler. But you can also use any other language that works for you. For example, you can use Ruby instead of Python if you really, really want to. For me, Ruby and Python are the two languages that I use the most. If I had to pick a favorite language, Ruby would be the first one I'd pick. So that was the short version. In the next post, I'll go through some of the most important features of Ruby and Python that you might not know about. If you're curious about the future of Ruby, Python, or both, you can subscribe to the mailing list to get updates about upcoming posts.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr6 = \"Aluminium is better than steel, because it is faster, lighter, easier to mod, greater. It also is more resistant to corrosion. The advantages of aluminium are many. However, it is also more expensive than steel. The steel is usually less expensive than aluminium because of the cost of the alloying process (which is why the price of steel is lower than aluminium). It is also usually harder (but not so much harder that it cannot be used) and more expensive. The main benefits of aluminium are. It is a good conductor of electricity. It is the strongest material known to man, and is also the only one that can resist all the shocks of a trip to the bathroom.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr7 = \"Juice is better than beer because it is: greater, faster, vitamen. I don't think there is a reason to drink beer, but I do believe there is a reason to drink juice.I also don't believe there is a reason to drink beer. I think drinking beer is good for your teeth and keeping my mouth healthy.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr8 = \"Tea is better than beer, because: easier, greater. The reason why tea is better than beer is because it is very good for your body. You need to drink more tea than beer. When you drink tea, you need less alcohol. This is why tea is better than beer. How long it takes to make a cup of tea?It is a long process. You need to wash your tea leaves and boil them, and then you need to boil them again. To make more tea, you need to boil the tea again. You need to boil the tea for at least one hour. Beer is life.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr9 = \"Iphone is better than laptop because it is lighter, bigger, device, greater. If you have a smartphone, it is better than a laptop because it is lighter, bigger, device, greater. But it is not as good as laptop for some things like software development, software testing, or design.  It has a more stable battery, better image quality, better camera, and a better battery life. The iPhone 5s on the other hand is not a great laptop, it's not the best for a long time to come, but it is better than the iPhone 4 and 4s. And with the iPhone 6 and the iPhone 6 Plus, the iPhone 6s is better than the iPhone 6.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_big.append(sttr9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['honda is better than toyota because it is quicker, bigger, nicer. The problem is that Honda is not the only one. Toyota has always been the king of the car world. There are a lot of other companies that have created the cars that people love. They do it for the money. But Toyota is the one that has to compete with Honda and Chevrolet. It has to produce cars that people want to buy.I am still not convinced that Toyota will ever get to that level. But it is not impossible. It is just a matter of time.',\n",
       " \"Motorola is better than Nokia. And I'm not sure I've ever heard of a company that's better than Samsung. This is not a bad thing. I am not sure Samsung does a better job than Nokia.Well, it depends what you expect from a phone. If you want good build quality and regular software updates do not ever think of buy a phone of Chinese or Chinese-owned brand (except the phones running on Android One). If you have a tight budget, then you can proceed with Moto. Since Nokias phone are a bit overpriced, you may get one at reasonable price during sales. Also, the Nokia-exclusive Zeiss optics dont have any competitor in their price range. If you want a Moto X4, then Nokia 7 Plus is always ahead. But if you want G5S Plus, then go on with it because Nokia 2.1 or 3.1 are the only available phones from Nokia and have a bit low specs. However you can go on for Nokia 6.1 or 6.1 Plus over Moto G6 because of their build quality and stock software anlog with regular updates and security patches.\",\n",
       " \"Samsung is better than Nokia. Nokia has no market share in the mobile phone industry, and it is not profitable. The company's strategy is to sell its devices to customers in China, and it is trying to win a share of the Chinese market. Samsung is also better than Nokia. Samsung has a high growth rate and is trying to establish itself as a leading player in the mobile phone industry. But Samsung has a long way to go to regain its market position. Samsung is now the second largest phone manufacturer in the world after Apple. The Nokia deal was announced in April, but it was not fully resolved until the end of July.\",\n",
       " 'Php is better than javascript because it is easier to learn, easier to pick up. You should not use the PHP version of your application.You should not use the PHP version of your application. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. The PHP version of your application is not required to work, but it may prove to be beneficial. PHP is not required to work, but it may prove to be beneficial. You will not lose your development experience by using PHP. You will not lose your development experience by using PHP. PHP has a very advanced feature set. PHP has a very advanced feature set. PHP provides a very rich set of functions and modules. PHP provides a very rich set of functions and modules. PHP provides a high degree of flexibility and conciseness.',\n",
       " \"Ruby is better than Python because ruby because it is: easier, easier to read, easier to learn, simpler. But you can also use any other language that works for you. For example, you can use Ruby instead of Python if you really, really want to. For me, Ruby and Python are the two languages that I use the most. If I had to pick a favorite language, Ruby would be the first one I'd pick. So that was the short version. In the next post, I'll go through some of the most important features of Ruby and Python that you might not know about. If you're curious about the future of Ruby, Python, or both, you can subscribe to the mailing list to get updates about upcoming posts.\",\n",
       " 'Aluminium is better than steel, because it is faster, lighter, easier to mod, greater. It also is more resistant to corrosion. The advantages of aluminium are many. However, it is also more expensive than steel. The steel is usually less expensive than aluminium because of the cost of the alloying process (which is why the price of steel is lower than aluminium). It is also usually harder (but not so much harder that it cannot be used) and more expensive. The main benefits of aluminium are. It is a good conductor of electricity. It is the strongest material known to man, and is also the only one that can resist all the shocks of a trip to the bathroom.',\n",
       " \"Juice is better than beer because it is: greater, faster, vitamen. I don't think there is a reason to drink beer, but I do believe there is a reason to drink juice.I also don't believe there is a reason to drink beer. I think drinking beer is good for your teeth and keeping my mouth healthy.\",\n",
       " 'Tea is better than beer, because: easier, greater. The reason why tea is better than beer is because it is very good for your body. You need to drink more tea than beer. When you drink tea, you need less alcohol. This is why tea is better than beer. How long it takes to make a cup of tea?It is a long process. You need to wash your tea leaves and boil them, and then you need to boil them again. To make more tea, you need to boil the tea again. You need to boil the tea for at least one hour. Beer is life.',\n",
       " \"Iphone is better than laptop because it is lighter, bigger, device, greater. If you have a smartphone, it is better than a laptop because it is lighter, bigger, device, greater. But it is not as good as laptop for some things like software development, software testing, or design.  It has a more stable battery, better image quality, better camera, and a better battery life. The iPhone 5s on the other hand is not a great laptop, it's not the best for a long time to come, but it is better than the iPhone 4 and 4s. And with the iPhone 6 and the iPhone 6 Plus, the iPhone 6s is better than the iPhone 6.\"]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_generator_for_out\n",
      "exist3\n",
      "exist4\n",
      "exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:08<00:00, 23.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "in big gen2  It has a more stable battery, better image quality, better camera, and a better battery life.\n",
      "\n",
      "The iPhone 5s on the other hand is not a great laptop, it's not the best for a long time to come, but it is better than the iPhone 4 and 4s. And with the iPhone 6 and the iPhone 6 Plus, the iPhone 6s is better than the iPhone 6.\n",
      "\n",
      "All these devices are better than the iPhone 4s, but not by much. The iPhone 4s is a pretty mediocre laptop. If you want to buy a laptop, you should look at the Macbook Air. It is faster, cheaper, and better than the Apple MacBook Pros.\n",
      "\n",
      "What is the most important thing you should know about the iPhone 4s?\n",
      "\n",
      "The iPhone 4s is a pretty poor laptop. It's not as fast, or as powerful as the iPhone 5s, or as good as the Apple MacBook Pro.\n",
      "\n",
      "But the iPhone 4\n",
      "qu2\n",
      "qu3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" It has a more stable battery, better image quality, better camera, and a better battery life.\\n\\nThe iPhone 5s on the other hand is not a great laptop, it's not the best for a long time to come, but it is better than the iPhone 4 and 4s. And with the iPhone 6 and the iPhone 6 Plus, the iPhone 6s is better than the iPhone 6.\\n\\nAll these devices are better than the iPhone 4s, but not by much. The iPhone 4s is a pretty mediocre laptop. If you want to buy a laptop, you should look at the Macbook Air. It is faster, cheaper, and better than the Apple MacBook Pros.\\n\\nWhat is the most important thing you should know about the iPhone 4s?\\n\\nThe iPhone 4s is a pretty poor laptop. It's not as fast, or as powerful as the iPhone 5s, or as good as the Apple MacBook Pro.\\n\\nBut the iPhone 4\""
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "text_generator_for_out(\"Iphone is better than laptop because it is lighter, bigger, device, greater.\", LM_BIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT2.model import (GPT2LMHeadModel)\n",
    "from GPT2.utils import load_weight\n",
    "from GPT2.config import GPT2Config\n",
    "from GPT2.sample import sample_sequence\n",
    "from GPT2.encoder import get_encoder\n",
    "\n",
    "\n",
    "def text_generator_for_out(text, model, length = 200, temperature = 0.7, top_k = 40):\n",
    "    print(\"text_generator_for_out\")\n",
    "    \n",
    "    device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print (\"exist3\")\n",
    "    # Load Model\n",
    "    enc = get_encoder()\n",
    "    print (\"exist4\")\n",
    "\n",
    "    quiet = False\n",
    "    print (\"exist\")\n",
    "    length = 200\n",
    "\n",
    "    if length == -1:\n",
    "        length = 1024 // 2\n",
    "    elif length > 1024:\n",
    "        raise ValueError(\"Can't get samples longer than window size: %s\" % 1024)\n",
    "\n",
    "    context_tokens = enc.encode(text)\n",
    "\n",
    "    generated = 0\n",
    "    for _ in range(1):\n",
    "        out = sample_sequence(\n",
    "            model=model, length=length,\n",
    "            context=context_tokens,\n",
    "            start_token=None,\n",
    "            batch_size=1,\n",
    "            temperature=temperature, top_k=top_k, device=device\n",
    "        )\n",
    "        out = out[:, len(context_tokens):].tolist()\n",
    "        for i in range(1):\n",
    "            generated += 1\n",
    "            text = enc.decode(out[i])\n",
    "            if quiet is False:\n",
    "                print (\"qu\")\n",
    "                print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
    "            print(\"in big gen2\", text)\n",
    "            print (\"qu2\")\n",
    "            print (\"qu3\")\n",
    "            return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i came to the conclusion that python is better, because: quicker to develop code, quicker, matplotlib, easier.. But i should tell you that matlab is: faster, better for scientific computing, experience.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "#proxies = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "params = {\n",
    "            'objectA': 'Moscow',\n",
    "            'objectB': 'London',\n",
    "            'fs': str(True).lower()}\n",
    "response = requests.get(url=URL, params=params)#, proxies=proxies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rouge ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rouge2': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n",
      "{'rouge1': Score(precision=0.2222222222222222, recall=0.2222222222222222, fmeasure=0.2222222222222222), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score('The quick brown dog jumps over the lazy fox',\n",
    "                      'The quick brown dog jumps over the lazy fox.')\n",
    "print (scores)\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score('The quick brown dog jumps over the lazy fox',\n",
    "                      'The fast hazel hound skips above the inactive tod.')\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bert embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: nvcc: not found\n"
     ]
    }
   ],
   "source": [
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-embedding\n",
      "  Downloading https://files.pythonhosted.org/packages/62/85/e0d56e29a055d8b3ba6da6e52afe404f209453057de95b90c01475c3ff75/bert_embedding-1.0.1-py3-none-any.whl\n",
      "Collecting mxnet==1.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/e9/241aadccc4522f99adee5b6043f730d58adb7c001e0a68865a3728c3b4ae/mxnet-1.4.0-py2.py3-none-manylinux1_x86_64.whl (29.6MB)\n",
      "\u001b[K     || 29.6MB 8.1MB/s eta 0:00:01    |                            | 3.3MB 1.3MB/s eta 0:00:20\n",
      "\u001b[?25hCollecting typing==3.6.6\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/bd/eee1157fc2d8514970b345d69cb9975dcd1e42cd7e61146ed841f6e68309/typing-3.6.6-py3-none-any.whl\n",
      "Collecting numpy==1.14.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/84/49b7f268741119328aeee0802aafb9bc2e164b36fc312daf83af95dae646/numpy-1.14.6-cp37-cp37m-manylinux1_x86_64.whl (13.8MB)\n",
      "\u001b[K     || 13.8MB 8.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gluonnlp==0.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/07/037585c23bccec19ce333b402997d98b09e43cc8d2d86dc810d57249c5ff/gluonnlp-0.6.0.tar.gz (209kB)\n",
      "\u001b[K     || 215kB 11.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from mxnet==1.4.0->bert-embedding) (2.22.0)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (3.0.4)\n",
      "Building wheels for collected packages: gluonnlp\n",
      "  Building wheel for gluonnlp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gluonnlp: filename=gluonnlp-0.6.0-cp37-none-any.whl size=259918 sha256=ed7ecef7205e89009adf31edbf1f0f6e98544fafd52b82c753d4f0267644598a\n",
      "  Stored in directory: /root/.cache/pip/wheels/ff/48/ac/a77c79aa416ba6dd7bf487f2280b0471034f66141617965914\n",
      "Successfully built gluonnlp\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 requires fastapi==0.38.1, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 requires fuzzywuzzy==0.17.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 requires pymorphy2==0.8, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 requires pymorphy2-dicts-ru, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 requires pyopenssl==19.0.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 requires pytelegrambotapi==3.6.6, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 requires rusenttokenize==0.0.5, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 requires uvicorn==0.9.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 40.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: spacy 2.1.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: phik 0.9.8 has requirement numpy>=1.15.4, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mlxtend 0.17.0 has requirement numpy>=1.16.2, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: imgaug 0.3.0 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: hdbscan 0.8.23 has requirement numpy>=1.16.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.61 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement Cython==0.29.12, but you'll have cython 0.29.14 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement flasgger==0.9.2, but you'll have flasgger 0.9.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement h5py==2.9.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement keras==2.2.4, but you'll have keras 2.3.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement nltk==3.2.5, but you'll have nltk 3.4.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement numpy==1.16.4, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement overrides==1.9, but you'll have overrides 2.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement pandas==0.24.2, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement scikit-learn==0.21.2, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement scipy==1.3.0, but you'll have scipy 1.3.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement tqdm==4.32.2, but you'll have tqdm 4.38.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: blis 0.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "Installing collected packages: graphviz, numpy, mxnet, typing, gluonnlp, bert-embedding\n",
      "  Found existing installation: graphviz 0.13.2\n",
      "    Uninstalling graphviz-0.13.2:\n",
      "      Successfully uninstalled graphviz-0.13.2\n",
      "  Found existing installation: numpy 1.17.4\n",
      "    Uninstalling numpy-1.17.4:\n",
      "      Successfully uninstalled numpy-1.17.4\n",
      "Successfully installed bert-embedding-1.0.1 gluonnlp-0.6.0 graphviz-0.8.4 mxnet-1.4.0 numpy-1.14.6 typing-3.6.6\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install bert-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_embedding import BertEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert embedding    (,    \"  \" \"   \"  - \n",
    "   service bert I - apple \n",
    "\n",
    "I like apple\n",
    "I like apple macbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_embedding import BertEmbedding\n",
    "\n",
    "bert_abstract = \"\"\"The quick brown dog jumps over the lazy fox.\\n The fast hazel hound skips above inactive tod.\"\"\"\n",
    "sentences = bert_abstract.split('\\n')\n",
    "bert_embedding = BertEmbedding()\n",
    "result = bert_embedding(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrgam ('jumps',)\n",
    "list_of_ngrams Counter({('the',): 2, ('just',): 1, ('place',): 1, ('for',): 1, ('a',): 1, ('snark',): 1, ('bellman',): 1, ('cried',): 1})\n",
    "[0.6792433]\n",
    "[0.8161626]\n",
    "[0.6827992]\n",
    "[0]\n",
    "[0.8117111]\n",
    "[0]\n",
    "[0]\n",
    "[0.62362134]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bert_embedding(['jumps', 'just', 'a'])\n",
    "vectors = result[0][1]\n",
    "vectors1 = result[1][1]\n",
    "vectors2 = result[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jumps']"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft\n",
      "has\n",
      "undeniable\n",
      "advantages\n",
      ".\n",
      "They\n",
      "are\n",
      "simpler\n",
      ",\n",
      "friendlier\n",
      "and\n",
      "easier\n",
      "to\n",
      "use\n"
     ]
    }
   ],
   "source": [
    "for elem in list(ngrams1.keys()):\n",
    "    print (' '.join(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The quick brown dog jumps over the lazy fox', 'The fast hazel hound skips above the inactive tod.']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "bert_embedding = BertEmbedding()\n",
    "import collections\n",
    "\n",
    "str_1 = 'The quick brown dog jumps over the lazy fox'\n",
    "str_2 = 'The fast hazel hound skips above the inactive tod.'\n",
    "str_3 = 'Just the place for Snark the Bellman cried'\n",
    "print ([str_1, str_2])\n",
    "result = bert_embedding([str_1, str_2, str_3])\n",
    "ngrams1_embeddings = result[0][1]\n",
    "ngrams2_embeddings = result[1][1]\n",
    "ngrams3_embeddings = result[2][1]\n",
    "\n",
    "ngrams1 = create_ngrams(result[0][0], 2)\n",
    "ngrams2= create_ngrams(result[1][0], 2)\n",
    "ngrams3= create_ngrams(result[2][0], 2)\n",
    "\n",
    "ngrams01 = create_ngrams(result[0][0], 1)\n",
    "ngrams02= create_ngrams(result[1][0], 1)\n",
    "ngrams03= create_ngrams(result[2][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('the', 'quick'): 1,\n",
       "         ('quick', 'brown'): 1,\n",
       "         ('brown', 'dog'): 1,\n",
       "         ('dog', 'jumps'): 1,\n",
       "         ('jumps', 'over'): 1,\n",
       "         ('over', 'the'): 1,\n",
       "         ('the', 'lazy'): 1,\n",
       "         ('lazy', 'fox'): 1})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_target = bert_embedding([' '.join(elem)for elem in list(ngrams1.keys())])\n",
    "embeddings_predictions = bert_embedding([' '.join(elem)for elem in list(ngrams2.keys())])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_target[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def fmeasure(precision, recall):\n",
    "  \"\"\"Computes f-measure given precision and recall values.\"\"\"\n",
    "\n",
    "  if precision + recall > 0:\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "  else:\n",
    "    return 0.0\n",
    "\n",
    "def cos_sim(emb1, emb2):\n",
    "    return cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))\n",
    "\n",
    "def count_ngram_overlap(ngram1_embs, ngram2_embs): #The idea count cousine similarity to every pair. If > 0.6 than add\n",
    "    result = 1\n",
    "    #print (\"ngram1_embs\", len(ngram1_embs), len(ngram1_embs[0]))\n",
    "    for elem in ngram1_embs: #    -\n",
    "        #print (cos_sim(elem, elem))\n",
    "        similarities = [cos_sim(elem, elem2)[0][0] if cos_sim(elem, elem2) >= 0.6 else 0 for elem2 in ngram2_embs]\n",
    "        #print (\"similarities\", similarities)\n",
    "        max_ = max(similarities)\n",
    "        result *= max_\n",
    "    return result\n",
    "        \n",
    "\n",
    "def count_overlap(ngram, ngram_emb, list_of_ngrams2, list_of_ngrams2_embs): # only if ngram not in list_of_ngrams !!!\n",
    "    overlaps = [count_ngram_overlap(ngram_emb, elem[1]) for elem in list_of_ngrams2_embs] #   -\n",
    "    return max(overlaps)\n",
    "\n",
    "def score_ngrams(target_ngrams, prediction_ngrams):\n",
    "    intersection_ngrams_count_pred = 0\n",
    "    intersection_ngrams_count_tg = 0\n",
    "    \n",
    "    #print (\"target_ngrams\", target_ngrams)\n",
    "    #print (\"prediction_ngrams\", prediction_ngrams)\n",
    "    \n",
    "    embeddings_target = bert_embedding([' '.join(elem)for elem in list(target_ngrams.keys())])\n",
    "    embeddings_predictions = bert_embedding([' '.join(elem)for elem in list(prediction_ngrams.keys())])\n",
    "    \n",
    "    for ind, ngram in enumerate(list(target_ngrams.keys())):\n",
    "        #print (\"ind\", ind)\n",
    "        intersection_ngrams_count_tg += min(target_ngrams[ngram],\n",
    "                                         prediction_ngrams[ngram])\n",
    "        #print (\"min\", min(target_ngrams[ngram], prediction_ngrams[ngram]))\n",
    "        if (min(target_ngrams[ngram], prediction_ngrams[ngram]) == 0):\n",
    "            #print (\"ngram\", ngram)\n",
    "            #print ('overlap')\n",
    "            overlap_ngram = count_overlap(ngram, embeddings_target[ind][1], prediction_ngrams, embeddings_predictions) #  -\n",
    "            #print ('overlap ngram', overlap_ngram)\n",
    "            intersection_ngrams_count_tg += overlap_ngram\n",
    "            \n",
    "    for ind, ngram in enumerate(list(prediction_ngrams.keys())):\n",
    "        #print (\"ind\", ind)\n",
    "        intersection_ngrams_count_tg += min(target_ngrams[ngram],\n",
    "                                         prediction_ngrams[ngram])\n",
    "        #print (\"min\", min(target_ngrams[ngram], prediction_ngrams[ngram]))\n",
    "        if (min(target_ngrams[ngram], prediction_ngrams[ngram]) == 0):\n",
    "            #print (\"ngram\", ngram)\n",
    "            #print ('overlap')\n",
    "            overlap_ngram = count_overlap(ngram, embeddings_predictions[ind][1], prediction_ngrams, embeddings_target) #  -\n",
    "            #print ('overlap ngram', overlap_ngram)\n",
    "            intersection_ngrams_count_pred += overlap_ngram\n",
    "            \n",
    "    target_ngrams_count = sum(target_ngrams.values())\n",
    "    prediction_ngrams_count = sum(prediction_ngrams.values())\n",
    "    \n",
    "    precision = intersection_ngrams_count_pred / max(prediction_ngrams_count, 1)\n",
    "    recall = intersection_ngrams_count_tg / max(target_ngrams_count, 1)\n",
    "    \n",
    "    f = fmeasure(precision, recall)\n",
    "    return f, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer_big' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-70596e7556aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_big\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge_scorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRougeScorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rouge2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_stemmer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'answer_big' is not defined"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from nltk.stem import porter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import collections\n",
    "\n",
    "for ind, elem in enumerate(answer_big):\n",
    "    print (ind, \"target1\")\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(elem, list_of_target1[ind])\n",
    "    print (scores)\n",
    "    print (ind, \"target2\")\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(elem, list_of_target2[ind])\n",
    "    print (scores)\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ngrams(['ps3', 'i', 'want', 'one', 'real', 'bad', 'the', '360', 'sucks'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import porter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import collections\n",
    "\n",
    "stemmer = porter.PorterStemmer()\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def create_ngrams(tokens, n): #  \n",
    "    ngrams = collections.Counter()\n",
    "    ngrams_embs = collections.Counter()\n",
    "    for ngram in (tuple(tokens[i:i + n]) for i in range(len(tokens) - n + 1)):\n",
    "        ngrams[ngram] += 1\n",
    "    return ngrams\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_answers, df['Answers'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'll comment on PS3 when it's out but I am looking forward to it (Metal Gear Solid 4! Devil May Cry 4! So many more!).  I own a 360 and so far I'm not impressed.  If you love Racing, Sports and First Person shooters that look great get a 360 cause you'll love it.\\n\\nSadly for me I don't play any of the above genres and thus I own 1 game (Dead Or Alive 4)\",\n",
       " \"I'll comment on PS3 when it's out but I am looking forward to it (Metal Gear Solid 4! Devil May Cry 4! So many more!).  I own a 360 and so far I'm not impressed.  If you love Racing, Sports and First Person shooters that look great get a 360 cause you'll love it. Sadly for me I don't play any of the above genres and thus I own 1 game (Dead Or Alive 4)\",\n",
       " 'The Xbox 360 is the one I prefer becuase it has been released and I can play it. We are not even sure if the PS3 will be released or if it will be a good system. It is just all talk. You guys that are chasing the PS3 will increase and get your hopes high and when it eventually comes out and it is not good, you will start to complain and whine like babies without milk. You guys should cool down and live in the present and not in the future or past. Play the games infront of you now before dreaming of playing future games. As for me and as of now, the Xbox 360 is a solid choice for me. I hope you guys see the point that I am trying to stress here.',\n",
       " 'ps3 i want one real bad the 360 sucks',\n",
       " \"Both of course!!!  Although I'm a full time PC gamer, just stay away from crappy game titles.  Betcha never heard of Eggs of Steel...  here's a good example below\",\n",
       " '360 because i think that the graphics are awesome and because i can accutally play it .',\n",
       " 'Actually i prefer XBOX 360 because its game titles. But PS3 has a lot more speed and better graphic so if i gonna buy a console it would be PS3',\n",
       " 'The 360 for price and availability, yuo know what it is about the PS3 is still shaky',\n",
       " 'PS3! cant wait for it to be released',\n",
       " 'I prefer the 360 at the moment, because I can actually use it.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Answers'].values[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.236236573445915, 0.1387203134769617, 0.7953297972679139),\n",
       " (0.236236573445915, 0.1387203134769617, 0.7953297972679139),\n",
       " (0.15253809844057983, 0.08399902042504903, 0.8287903348604838),\n",
       " (0.8013430237770081, 1.0684573650360107, 0.6410744190216064),\n",
       " (0.40473112583160403, 0.28909366130828856, 0.6745518763860067),\n",
       " (0.6613554731011391, 0.6224522099775427, 0.7054458379745483),\n",
       " (0.4664476643437924, 0.3460740735453944, 0.7152197519938152),\n",
       " (0.6446477138634884, 0.5909270710415311, 0.7091124852498373),\n",
       " (0.7378140091896057, 0.9837520122528076, 0.5902512073516846),\n",
       " (0.7159038265546163, 0.7159038265546163, 0.7159038265546163)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams1 = create_ngrams(tokenizer.tokenize(templates_answers[5]), 1)\n",
    "answ_token_list = [tokenizer.tokenize(elemt) for elemt in df['Answers'].values[ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Object 1': 'baseball', 'Object 2': 'golf', 'Question': 'Would you rather live your life as a Professional GOLFER or BASEBALL Player? Why?', 'Best Answer': 'Golfer', 'Answers': ['Golfer', 'Golfer', 'I would rather be a golfer.  The prestige of being a professional golfer is ever present, but baseball players have a similiar prestige.  But here is what you have to evaluate. How many people in this country, grown men, grown women, older men, older women and children, actually have a baseball bat, a glove and a baseball in their garage or closet?   Now ask yourself how many Americans have golf clubs in their closet or garage (I keep mine in the dining room!) Now ask yourself the same question, except remove the equipment and ask how many times a year the average person plays a game of baseball. Now do the same for rounds of golf in a year. I am sure that you see what I am saying.  Whereas baseball my be the sport that is watched most, golf is played most and is participated in the most.  This means that to have gotten to a professional level means that you are that much better than that many more people....', 'baseball player more fun to play way more money just look at arod', 'baseball look at the money guarantied play or not.', 'Golfer.   Longer career.   Less chance of career-ending injuries. Better scenery.', \"I would rather live my life as a professional GOLFER because it is safer, healthier, and also a more life relevant sport.  With pitches coming in at 90 mph a ballplayer has more to worry about.  If I chose baseball I'd play short like I did when I was a kid but have somebody DH for me... If I had the choice !!!!\", \"Golfer.  There's more money in it, and you can play year round.\", 'Baseball, for sure. Baseball is the greatest game ever. No clock, you have to get 27 people out, and fielders throw the ball to you, instead of you hitting it as far away as possible and having to go retrieve it.', 'Golfer, dont have to worry about people  trying to give you steroids.', \"Let's see..............Dress in the latest fashions, play at beautiful courses around the world, big indorsment money, pick the tourneys I want to play in, take time off when I wnat to, only work up a sweat on hot days, no threat of physical injury. OR......Play numerous games, possible injury, sweat like a pig, shower with neanderthals, be unionized, rely on my teammates in order to win,.........easy choice\"]}\n"
     ]
    }
   ],
   "source": [
    "if (5.0 > 1.0 or 5.0 > 1.0 or 5.0 > 1.0):\n",
    "    print (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1 = tokenizer.tokenize('microsoft has undeniable advantages. They are simpler, friendlier and easier to use.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = create_ngrams(tokens1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = create_ngrams(['ps3', 'i', 'want', 'one', 'real', 'bad', 'the', '360', 'sucks'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection_ngrams_count 5.792976796627045 9.616116285324097\n",
      "intersection_targets_count 9 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6423666437472068, 0.643664088514116, 0.6410744190216064)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_answers[:20] df['Answers'].values[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6177924173754052, 0.42529132684995963, 1.1286631306012471), (0.6177924173754052, 0.42529132684995963, 1.1286631306012471), (0.5417633043265625, 0.34249851228417577, 1.2954570015271505), (0.6423666437472068, 0.643664088514116, 0.6410744190216064), (0.5659986264064666, 0.4355822113246809, 0.80788520971934), (0.5485891474172802, 0.3935013588737039, 0.9054458379745484), (0.6474507223689722, 0.5009005146641885, 0.9152197519938151), (0.6383525513374266, 0.5138627356953092, 0.8424458185831706), (0.44108873583912284, 0.33200809690687394, 0.6569178740183512), (0.613183514819534, 0.46086164712905886, 0.9159038265546163)]\n",
      "target1 (0.6474507223689722, 0.5009005146641885, 0.9152197519938151)\n",
      "3 n2\n",
      "target2 (0.1301963536692799, 0.0877050178096451, 0.2525534976324228)\n",
      "[(0.44695602098635684, 0.5, 0.4040872317094069), (0.44695602098635684, 0.5, 0.4040872317094069), (0.6006068978936199, 0.565392085484096, 0.6404997041592231), (0.4876273191767531, 0.42098140716552734, 0.5793436949069684), (0.6212441137370505, 0.4320090540817806, 1.1054852994588704), (0.5492471936405537, 0.3886665668752458, 0.9359367833687708), (0.5680932980634922, 0.3763320884847035, 1.1583178157989795), (0.5193862745117618, 0.3772239795437566, 0.8335044384002686), (0.6602370128483618, 0.5487642058959374, 0.8285423425527719), (0.5917625257139155, 0.3996454742219713, 1.1395798806960766), (0.46291631596917654, 0.466689129670461, 0.45920401353102464), (0.16026720170820838, 0.15329059687527744, 0.16790912930782026), (0.6701078140698058, 0.46995633071468723, 1.1672192422243266)]\n",
      "target1 (0.6701078140698058, 0.46995633071468723, 1.1672192422243266)\n",
      "5 n2\n",
      "target2 (0.18063877671913145, 0.18303673586509842, 0.17830283625920798)\n",
      "[(0.522782433356117, 0.31321552135574987, 1.5797951698303223), (0.5106459509374665, 0.4425127631739566, 0.6035782013620649), (0.4516257408280867, 0.2773507886073169, 1.2152096918651036), (0.522782433356117, 0.31321552135574987, 1.5797951698303223), (0.6436131732764403, 0.47768433143695194, 0.9861700551850455), (0.0, 0.0, 0.0), (0.5995783187338839, 0.6276634931564331, 0.5738988740103586), (0.5460924886432398, 0.4034792710753048, 0.8446365339415414), (0.4885645232809698, 0.3503486953283611, 0.8068902543612889), (0.47043252871556196, 0.31678544206822173, 0.9134956410952977), (0.5442115588024701, 0.4298471916805614, 0.7414914284433637)]\n",
      "target1 (0.6436131732764403, 0.47768433143695194, 0.9861700551850455)\n",
      "6 n2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rouge_cos(gen_answers, possible_answers):\n",
    "    list_of_n1 = []\n",
    "    list_of_n2 = []\n",
    "    for ind, elem in enumerate(gen_answers):\n",
    "        if (elem != \"We can't recognize objects for comparision\"):\n",
    "            ngrams1 = create_ngrams(tokenizer.tokenize(elem), 1)\n",
    "            answ_token_list = [tokenizer.tokenize(elemt) for elemt in possible_answers]\n",
    "            scores_list_1 = [score_ngrams(ngrams1, create_ngrams(possible_answ, 1)) for possible_answ in answ_token_list]\n",
    "            sorted_scores_1 = sorted(scores_list_1, key=lambda x: x[0], reverse = True)\n",
    "            #print (\"target1\", sorted_scores_1[0])\n",
    "            list_of_n1.append(sorted_scores_1[0])\n",
    "            #print (ind, \"n2\")\n",
    "            ngrams01 = create_ngrams(tokenizer.tokenize(elem), 2)\n",
    "            scores_list_2 = [score_ngrams(ngrams01, create_ngrams(possible_answ, 2)) for possible_answ in answ_token_list]\n",
    "            sorted_scores_2 = sorted(scores_list_2, key=lambda x: x[0], reverse = True)\n",
    "            #print (\"target2\", sorted_scores_2[0])\n",
    "            list_of_n2.append(sorted_scores_2[0])\n",
    "    return {'rouge1':list_of_n1, 'rouge2':list_of_n2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Looks like ruby is better, because: easier, easier to read, easier to learn, simpler.. But it will be useful for you to know that perl is: faster, cleaner, faster to write in ruby, safer.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_template_answers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Perl is an ideal choice for system administration work as well as the web development task whereas Ruby is highly suitable for the traffic-heavy application. ... Perl 5 is less Object-Oriented although Perl 6 has a very good Object-Oriented support whereas Ruby is highly Object-Oriented language.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_target1[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I know a lot more Ruby than Perl, but the primary contrast is :Perl code is much terser than Ruby\\nIf you want terse code that does its job in the least number of lines, Perl is better. If you want expressive, almost poetic and much more generally readable code, and don't mind the cost of a few extra characters, Ruby is much better. This manifests itself in several ways in practice:\\n- Perl One liners (one line perl commands that perform batch manipulation:  of a bunch of files, for instance) are a cult in themselves - see Perl One Liners to get a feel.\\n- Perl is better suited if the primary task is regex - Ruby regex syntax itself is pretty good, arguably close to Perl, but the typical use cases of doing text pattern matching with regexes are better expressed in Perl, in my view. Many developers do regexes with grep, and a natural progression for more complex manipulation not supported by grep is either through sed or awk for a class of tasks, or for more general power, to use Perl.\\n- Perl is used on the command line or with very short batch scripts much more effectively than Ruby, which usually involves longer scripts. So, bottom line, if you do mostly text manipulation and matching, and want quick solutions on the command line or with short scripts, Perl is definitely worth learning in addition to Ruby. If not, perhaps not :-)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_target2[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['after much thought, I realized that  honda is better, because: quicker, bigger, nicer, weaker.. But i should tell you that toyota is: lighter, easier, faster, softer.',\n",
       " 'i came to the conclusion that motorola is better, because: better for me, bigger, easier for me to hold it, quicker., but nokia is: easier, faster, cheaper, t720.',\n",
       " 'Looks like nokia is better, because: days, richer, easier to beat, easier to open and app or enddial a call.. But i should tell you that samsung is: quicker, greater, faster, smart.',\n",
       " \"It's simple! php is better, because: easier to learn, easier to pick up for a noob, easier, java.. But i should tell you that javascript is: animation, easier to understand, faster, features.\",\n",
       " 'Looks like ruby is better, because: easier, easier to read, easier to learn, simpler.. But it will be useful for you to know that perl is: faster, cleaner, faster to write in ruby, safer.',\n",
       " \"It's simple! aluminium is better, because: faster, lighter, easier to mod, greater.. But i should tell you that steel is: particles, drinks, ability, cks.\",\n",
       " \"It's simple! juice is better, because: greater, faster, vitamen, water.. But you should know that beer is: lighter, better for you, easier, worse for your teeth.\",\n",
       " 'i came to the conclusion that tea is better, because: easier, greater, better for the mind and body to chat while sipping cups of assam and sencha, better to have extra beer left over., but beer is: safer, colors, coffee, beverages.',\n",
       " 'Looks like iphone is better, because: lighter, bigger, device, greater.. But i should tell you that laptop is: easier to see, experience, easier for an attacker to get to simply because an attacker can get a phone easier, louder.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_template_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 n1\n",
      "honda is better than toyota because it is quicker, bigger, nicer. The problem is that Honda is not the only one. Toyota has always been the king of the car world. There are a lot of other companies that have created the cars that people love. They do it for the money. But Toyota is the one that has to compete with Honda and Chevrolet. It has to produce cars that people want to buy.I am still not convinced that Toyota will ever get to that level. But it is not impossible. It is just a matter of time.\n",
      "2.319214033453088 0.39343809496079174\n",
      "target1 (0.6727491089405904, 2.319214033453088, 0.39343809496079174)\n",
      "0.35589685977212054 0.8039455850209508\n",
      "target2 (0.49338030423203555, 0.35589685977212054, 0.8039455850209508)\n",
      "0 n2\n",
      "0.4370502454986571 0.07087301278356602\n",
      "target1 (0.12196751037171824, 0.4370502454986571, 0.07087301278356602)\n",
      "0.1786614873475141 0.40560986316732933\n",
      "target2 (0.24805892458167247, 0.1786614873475141, 0.40560986316732933)\n",
      "\n",
      "\n",
      "\n",
      "1 n1\n",
      "Motorola is better than Nokia. And I'm not sure I've ever heard of a company that's better than Samsung. This is not a bad thing. I am not sure Samsung does a better job than Nokia.Well, it depends what you expect from a phone. If you want good build quality and regular software updates do not ever think of buy a phone of Chinese or Chinese-owned brand (except the phones running on Android One). If you have a tight budget, then you can proceed with Moto. Since Nokias phone are a bit overpriced, you may get one at reasonable price during sales. Also, the Nokia-exclusive Zeiss optics dont have any competitor in their price range. If you want a Moto X4, then Nokia 7 Plus is always ahead. But if you want G5S Plus, then go on with it because Nokia 2.1 or 3.1 are the only available phones from Nokia and have a bit low specs. However you can go on for Nokia 6.1 or 6.1 Plus over Moto G6 because of their build quality and stock software anlog with regular updates and security patches.\n",
      "0.8507100805645205 0.5250794277168571\n",
      "target1 (0.649358582206054, 0.8507100805645205, 0.5250794277168571)\n",
      "1.0634089443418715 0.8700618635524403\n",
      "target2 (0.9570680499076845, 1.0634089443418715, 0.8700618635524403)\n",
      "1 n2\n",
      "0.3331037489406138 0.2049869224249931\n",
      "target1 (0.25379333252618197, 0.3331037489406138, 0.2049869224249931)\n",
      "1.0435661488591341 0.8529146408944845\n",
      "target2 (0.9386573825717079, 1.0435661488591341, 0.8529146408944845)\n",
      "\n",
      "\n",
      "\n",
      "2 n1\n",
      "Samsung is better than Nokia. Nokia has no market share in the mobile phone industry, and it is not profitable. The company's strategy is to sell its devices to customers in China, and it is trying to win a share of the Chinese market. Samsung is also better than Nokia. Samsung has a high growth rate and is trying to establish itself as a leading player in the mobile phone industry. But Samsung has a long way to go to regain its market position. Samsung is now the second largest phone manufacturer in the world after Apple. The Nokia deal was announced in April, but it was not fully resolved until the end of July.\n",
      "0.9462399688634006 0.41304125624989707\n",
      "target1 (0.5750629645026192, 0.9462399688634006, 0.41304125624989707)\n",
      "0.7982164909551431 0.5764896879120479\n",
      "target2 (0.6694718956397975, 0.7982164909551431, 0.5764896879120479)\n",
      "2 n2\n",
      "0.31677286962338014 0.13684587967730022\n",
      "target1 (0.19112553027555895, 0.31677286962338014, 0.13684587967730022)\n",
      "0.3455492838001103 0.24879548433607943\n",
      "target2 (0.28929707480939465, 0.3455492838001103, 0.24879548433607943)\n",
      "\n",
      "\n",
      "\n",
      "3 n1\n",
      "Php is better than javascript because it is easier to learn, easier to pick up. You should not use the PHP version of your application.You should not use the PHP version of your application. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. The PHP version of your application is not required to work, but it may prove to be beneficial. PHP is not required to work, but it may prove to be beneficial. You will not lose your development experience by using PHP. You will not lose your development experience by using PHP. PHP has a very advanced feature set. PHP has a very advanced feature set. PHP provides a very rich set of functions and modules. PHP provides a very rich set of functions and modules. PHP provides a high degree of flexibility and conciseness.\n",
      "0.816702878329812 0.3679650330936516\n",
      "target1 (0.5073457274473075, 0.816702878329812, 0.3679650330936516)\n",
      "0.5267935977344624 0.4949544242450169\n",
      "target2 (0.5103779332158248, 0.5267935977344624, 0.4949544242450169)\n",
      "3 n2\n",
      "0.3029508292660024 0.13557468050025523\n",
      "target1 (0.18732074175989463, 0.3029508292660024, 0.13557468050025523)\n",
      "0.20929099061308098 0.19657164864212026\n",
      "target2 (0.20273201369928073, 0.20929099061308098, 0.19657164864212026)\n",
      "\n",
      "\n",
      "\n",
      "4 n1\n",
      "Ruby is better than Python because ruby because it is: easier, easier to read, easier to learn, simpler. But you can also use any other language that works for you. For example, you can use Ruby instead of Python if you really, really want to. For me, Ruby and Python are the two languages that I use the most. If I had to pick a favorite language, Ruby would be the first one I'd pick. So that was the short version. In the next post, I'll go through some of the most important features of Ruby and Python that you might not know about. If you're curious about the future of Ruby, Python, or both, you can subscribe to the mailing list to get updates about upcoming posts.\n",
      "1.2669327576109704 0.4023367541061865\n",
      "target1 (0.6107265600791344, 1.2669327576109704, 0.4023367541061865)\n",
      "0.3811092026855635 0.7107171617649697\n",
      "target2 (0.4961610374585638, 0.3811092026855635, 0.7107171617649697)\n",
      "4 n2\n",
      "0.40951441994941956 0.12814736950798164\n",
      "target1 (0.19520894629713267, 0.40951441994941956, 0.12814736950798164)\n",
      "0.1958466043815882 0.36637970207439974\n",
      "target2 (0.2552503137674728, 0.1958466043815882, 0.36637970207439974)\n",
      "\n",
      "\n",
      "\n",
      "5 n1\n",
      "Aluminium is better than steel, because it is faster, lighter, easier to mod, greater. It also is more resistant to corrosion. The advantages of aluminium are many. However, it is also more expensive than steel. The steel is usually less expensive than aluminium because of the cost of the alloying process (which is why the price of steel is lower than aluminium). It is also usually harder (but not so much harder that it cannot be used) and more expensive. The main benefits of aluminium are. It is a good conductor of electricity. It is the strongest material known to man, and is also the only one that can resist all the shocks of a trip to the bathroom.\n",
      "0.29138578436094575 0.7369104256664497\n",
      "target1 (0.4176330133140454, 0.29138578436094575, 0.7369104256664497)\n",
      "0.622109942138195 0.5049008226049119\n",
      "target2 (0.5574105081558227, 0.622109942138195, 0.5049008226049119)\n",
      "5 n2\n",
      "0.15367021055316518 0.39034476841241955\n",
      "target1 (0.2205246732886659, 0.15367021055316518, 0.39034476841241955)\n",
      "0.27659085900966673 0.22409916313921902\n",
      "target2 (0.24759343024252428, 0.27659085900966673, 0.22409916313921902)\n",
      "\n",
      "\n",
      "\n",
      "6 n1\n",
      "Juice is better than beer because it is: greater, faster, vitamen. I don't think there is a reason to drink beer, but I do believe there is a reason to drink juice.I also don't believe there is a reason to drink beer. I think drinking beer is good for your teeth and keeping my mouth healthy.\n",
      "0.24833407424963438 0.5960017781991225\n",
      "target1 (0.35058928129360145, 0.24833407424963438, 0.5960017781991225)\n",
      "0.2450605491678158 0.6296171032465421\n",
      "target2 (0.3528026871640107, 0.2450605491678158, 0.6296171032465421)\n",
      "6 n2\n",
      "0.06140282517651985 0.148709967224384\n",
      "target1 (0.0869172411174482, 0.06140282517651985, 0.148709967224384)\n",
      "0.06295996288843363 0.1633024037418747\n",
      "target2 (0.09088133773460853, 0.06295996288843363, 0.1633024037418747)\n",
      "\n",
      "\n",
      "\n",
      "7 n1\n",
      "Tea is better than beer, because: easier, greater. The reason why tea is better than beer is because it is very good for your body. You need to drink more tea than beer. When you drink tea, you need less alcohol. This is why tea is better than beer. How long it takes to make a cup of tea?It is a long process. You need to wash your tea leaves and boil them, and then you need to boil them again. To make more tea, you need to boil the tea again. You need to boil the tea for at least one hour. Beer is life.\n",
      "0.9872356162351721 0.4060404550644659\n",
      "target1 (0.5754173306056432, 0.9872356162351721, 0.4060404550644659)\n",
      "0.44085215682714757 0.504846824753669\n",
      "target2 (0.47068425766507493, 0.44085215682714757, 0.504846824753669)\n",
      "7 n2\n",
      "0.5292495873806777 0.2151421086913324\n",
      "target1 (0.3059246169830507, 0.5292495873806777, 0.2151421086913324)\n",
      "0.19821078568146558 0.22721724212265568\n",
      "target2 (0.2117251574324746, 0.19821078568146558, 0.22721724212265568)\n",
      "\n",
      "\n",
      "\n",
      "8 n1\n",
      "Iphone is better than laptop because it is lighter, bigger, device, greater. If you have a smartphone, it is better than a laptop because it is lighter, bigger, device, greater. But it is not as good as laptop for some things like software development, software testing, or design.  It has a more stable battery, better image quality, better camera, and a better battery life. The iPhone 5s on the other hand is not a great laptop, it's not the best for a long time to come, but it is better than the iPhone 4 and 4s. And with the iPhone 6 and the iPhone 6 Plus, the iPhone 6s is better than the iPhone 6.\n",
      "0.3745184953619794 0.564531555508866\n",
      "target1 (0.45030083020062034, 0.3745184953619794, 0.564531555508866)\n",
      "0.4888700436252032 0.4637076149092001\n",
      "target2 (0.475956495303028, 0.4888700436252032, 0.4637076149092001)\n",
      "8 n2\n",
      "0.12961930184271558 0.19586916722899245\n",
      "target1 (0.15600199159831257, 0.12961930184271558, 0.19586916722899245)\n",
      "0.19295336370077187 0.18294837447184295\n",
      "target2 (0.18781772284181594, 0.19295336370077187, 0.18294837447184295)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ind, elem in enumerate(answer_big):\n",
    "    print (ind, \"n1\")\n",
    "    ngrams1 = create_ngrams(tokenizer.tokenize(elem), 1)\n",
    "    ngrams2 = create_ngrams(tokenizer.tokenize(list_of_target1[ind]), 1)\n",
    "    ngrams3 = create_ngrams(tokenizer.tokenize(list_of_target2[ind]), 1)\n",
    "    print (elem)\n",
    "    scores = score_ngrams(ngrams1, ngrams2)\n",
    "    print (\"target1\", scores)\n",
    "    scores = score_ngrams(ngrams1, ngrams3)\n",
    "    print (\"target2\", scores)\n",
    "    print (ind, \"n2\")\n",
    "    ngrams01 =create_ngrams(tokenizer.tokenize(elem), 2)\n",
    "    ngrams02 =create_ngrams(tokenizer.tokenize(list_of_target1[ind]), 2)\n",
    "    ngrams03 =create_ngrams(tokenizer.tokenize(list_of_target2[ind]), 2)\n",
    "    scores = score_ngrams(ngrams01, ngrams02)\n",
    "    print (\"target1\", scores)\n",
    "    scores = score_ngrams(ngrams01, ngrams03)\n",
    "    print (\"target2\", scores)\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6794479370117188 0.7549421522352431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7152083547491778, 0.6794479370117188, 0.7549421522352431)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6794479370117188 0.7549421522352431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7152083547491778, 0.6794479370117188, 0.7549421522352431)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5479773506522179 0.487090978357527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5157433888491462, 0.5479773506522179, 0.487090978357527)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.125, recall=0.1111111111111111, fmeasure=0.11764705882352941), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n"
     ]
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score('The quick brown dog jumps over the lazy fox',\n",
    "                      'The fast hazel hound skips above inactive tod.')\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[0][])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The quick brown dog jumps over the lazy fox.', ' The fast hazel hound skips above inactive tod. ', ' Just the place for a Snark the Bellman cried']\n",
      "Vocab file is not found. Downloading.\n",
      "Downloading /root/.mxnet/models/book_corpus_wiki_en_uncased-a6607397.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/book_corpus_wiki_en_uncased-a6607397.zip...\n",
      "Downloading /root/.mxnet/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip...\n"
     ]
    }
   ],
   "source": [
    "from bert_embedding import BertEmbedding\n",
    "\n",
    "bert_abstract = \"\"\"The quick brown dog jumps over the lazy fox.\\n The fast hazel hound skips above inactive tod. \\n Just the place for a Snark the Bellman cried\"\"\"\n",
    "sentences = bert_abstract.split('\\n')\n",
    "print (sentences)\n",
    "bert_embedding = BertEmbedding()\n",
    "result = bert_embedding(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "from six.moves import map\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'quick')\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'intersection_ngrams_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-0781affcb4b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mngrams2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrams2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mintersection_ngrams_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrams2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intersection_ngrams_count' is not defined"
     ]
    }
   ],
   "source": [
    "for ngram in six.iterkeys(ngrams1):\n",
    "    print (ngram)\n",
    "    print (ngrams1[ngram])\n",
    "    print (ngrams2[ngram])\n",
    "    print (min(ngrams1[ngram], ngrams2[ngram]))\n",
    "    intersection_ngrams_count += min(ngrams1[ngram], ngrams2[ngram])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score_ngrams(target_ngrams, prediction_ngrams):\n",
    "      \"\"\"Compute n-gram based rouge scores.\n",
    "      Args:\n",
    "        target_ngrams: A Counter object mapping each ngram to number of\n",
    "          occurrences for the target text.\n",
    "        prediction_ngrams: A Counter object mapping each ngram to number of\n",
    "          occurrences for the prediction text.\n",
    "      Returns:\n",
    "        A Score object containing computed scores.\n",
    "      \"\"\"\n",
    "\n",
    "      intersection_ngrams_count = 0\n",
    "      for ngram in six.iterkeys(target_ngrams):\n",
    "        intersection_ngrams_count += min(target_ngrams[ngram],\n",
    "                                         prediction_ngrams[ngram])\n",
    "      target_ngrams_count = sum(target_ngrams.values())\n",
    "      prediction_ngrams_count = sum(prediction_ngrams.values())\n",
    "\n",
    "      precision = intersection_ngrams_count / max(prediction_ngrams_count, 1)\n",
    "      recall = intersection_ngrams_count / max(target_ngrams_count, 1)\n",
    "      fmeasure = scoring.fmeasure(precision, recall)\n",
    "\n",
    "      return scoring.Score(precision=precision, recall=recall, fmeasure=fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = \"I've used the Honda the past few years, and they're pretty good. They're just not as fast as a Toyota, but they're much more powerful, lighter, and more durable than the Toyota. They're more comfortable, they're more comfortable, and they're better.have been using the Honda for a while, and I can tell you that they're very good. They're just not as fast as a Toyota, but they're much more powerful, lighter, and more durable than the Toyota. They're more comfortable, they're more comfortable, and thy're better. They're just not as good as the Honda.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = \"They don\\'t have that kind of engine. Maybe they are trying to make this bigger, faster, more powerful. You cannot afford to have a car with a big engine. You need to be careful when you make a big engine. There is no point, because it will explode. There is no point in spending a lot of money on a big engine.(CNN) After the shooting deaths of five police officers in Dallas last week, President Barack Obama offered condolences to the families of the fallen officers, calling the situation an attack on our shared humanity.Yet more than two months after the deaths of Alton Sterling in Louisiana and Philando Castile in Minnesota, the President did not issue a statement or call for unity or reflection. While we mourn for the officers who lost their lives in Dallas, we do not yet know the full extent of the threat that this attack represents, Obama said in a statement.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've used the Honda the past few years, and they're pretty good. They're just not as fast as a Toyota, but they're much more powerful, lighter, and more durable than the Toyota. They're more comfortable, they're more comfortable, and they're better.have been using the Honda for a while, and I can tell you that they're very good. They're just not as fast as a Toyota, but they're much more powerful, lighter, and more durable than the Toyota. They're more comfortable, they're more comfortable, and thy're better. They're just not as good as the Honda.\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bert_embedding([gen_templates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import porter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "stemmer = porter.PorterStemmer()\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen_templates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7044b994d8b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mngrams1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_templates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mngrams2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcreate_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mngrams3\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcreate_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mngrams01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_templates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gen_templates' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ngrams1 = create_ngrams(tokenizer.tokenize(gen_templates), 2)\n",
    "ngrams2= create_ngrams(tokenizer.tokenize(small), 2)\n",
    "ngrams3= create_ngrams(tokenizer.tokenize(big), 2)\n",
    "\n",
    "ngrams01 = create_ngrams(tokenizer.tokenize(gen_templates), 1)\n",
    "ngrams02= create_ngrams(tokenizer.tokenize(small), 1)\n",
    "ngrams03= create_ngrams(tokenizer.tokenize(big), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After much thought, I realized that Honda is better, because: quicker, bigger, nicer, weaker, but Toyota is lighter, easier, faster, softer.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ngrams1_t = create_ngrams(tokenizer.tokenize(target1), 2)\n",
    "ngrams2_t= create_ngrams(tokenizer.tokenize(target2), 2)\n",
    "\n",
    "ngrams01_t = create_ngrams(tokenizer.tokenize(target1), 1)\n",
    "ngrams02_t = create_ngrams(tokenizer.tokenize(target2), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0821059115319384 0.6491498630493879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14577400433389767, 0.0821059115319384, 0.6491498630493879)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams01_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38255592389982573 0.5857887584716082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4628454387923817, 0.38255592389982573, 0.5857887584716082)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams02_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22225900106279275 0.5020672077579158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.30811795763773464, 0.22225900106279275, 0.5020672077579158)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams02, ngrams01_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7212211319378444 0.31553424522280693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.439004167266514, 0.7212211319378444, 0.31553424522280693)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams02, ngrams02_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4667321349321147 0.6709274439649149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5505045694071096, 0.4667321349321147, 0.6709274439649149)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams03, ngrams01_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6459892696263838 0.4582583762028001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7169197707706028, 1.6459892696263838, 0.4582583762028001)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams03, ngrams02_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('I', 'drive'): 1,\n",
       "         ('drive', 'a'): 1,\n",
       "         ('a', 'Honda'): 1,\n",
       "         ('Honda', 'and'): 1,\n",
       "         ('and', 'my'): 1,\n",
       "         ('my', 'wife'): 1,\n",
       "         ('wife', 'a'): 1,\n",
       "         ('a', 'Toyota'): 1,\n",
       "         ('Toyota', '.'): 1,\n",
       "         ('.', 'So'): 1,\n",
       "         ('So', 'by'): 1,\n",
       "         ('by', 'owning'): 1,\n",
       "         ('owning', 'both'): 1,\n",
       "         ('both', 'cars'): 1,\n",
       "         ('cars', 'I'): 1,\n",
       "         ('I', 'have'): 1,\n",
       "         ('have', 'experienced'): 1,\n",
       "         ('experienced', 'both'): 1,\n",
       "         ('both', 'brands'): 2,\n",
       "         ('brands', '.'): 2,\n",
       "         ('.', 'I'): 1,\n",
       "         ('I', ''): 1,\n",
       "         ('', 've'): 1,\n",
       "         ('ve', 'been'): 1,\n",
       "         ('been', 'driving'): 1,\n",
       "         ('driving', 'a'): 1,\n",
       "         ('a', 'honda'): 1,\n",
       "         ('honda', 'city'): 1,\n",
       "         ('city', 'AT'): 1,\n",
       "         ('AT', 'for'): 1,\n",
       "         ('for', 'almost'): 1,\n",
       "         ('almost', '7'): 1,\n",
       "         ('7', 'years'): 1,\n",
       "         ('years', 'and'): 1,\n",
       "         ('and', 'have'): 1,\n",
       "         ('have', 'never'): 1,\n",
       "         ('never', 'faced'): 1,\n",
       "         ('faced', 'any'): 1,\n",
       "         ('any', 'challenge'): 1,\n",
       "         ('challenge', 'whatsoever'): 1,\n",
       "         ('whatsoever', 'with'): 1,\n",
       "         ('with', 'the'): 1,\n",
       "         ('the', 'car'): 1,\n",
       "         ('car', '.'): 2,\n",
       "         ('.', 'The'): 3,\n",
       "         ('The', 'only'): 1,\n",
       "         ('only', 'major'): 1,\n",
       "         ('major', 'expenses'): 1,\n",
       "         ('expenses', 'include'): 1,\n",
       "         ('include', 'Two'): 1,\n",
       "         ('Two', 'sets'): 1,\n",
       "         ('sets', 'of'): 1,\n",
       "         ('of', 'tyres'): 1,\n",
       "         ('tyres', ','): 1,\n",
       "         (',', 'Insurance'): 1,\n",
       "         ('Insurance', 'And'): 1,\n",
       "         ('And', 'fuel'): 1,\n",
       "         ('fuel', '.'): 1,\n",
       "         ('The', 'car'): 1,\n",
       "         ('car', 'has'): 1,\n",
       "         ('has', 'done'): 2,\n",
       "         ('done', 'over'): 1,\n",
       "         ('over', '110k'): 1,\n",
       "         ('110k', 'and'): 1,\n",
       "         ('and', 'still'): 1,\n",
       "         ('still', 'drives'): 1,\n",
       "         ('drives', 'like'): 1,\n",
       "         ('like', 'a'): 2,\n",
       "         ('a', 'dream'): 1,\n",
       "         ('dream', '.'): 1,\n",
       "         ('.', 'Toyota'): 1,\n",
       "         ('Toyota', 'on'): 1,\n",
       "         ('on', 'the'): 2,\n",
       "         ('the', 'other'): 2,\n",
       "         ('other', 'hand'): 2,\n",
       "         ('hand', 'being'): 1,\n",
       "         ('being', 'twice'): 1,\n",
       "         ('twice', 'as'): 1,\n",
       "         ('as', 'expensive'): 1,\n",
       "         ('expensive', 'feels'): 1,\n",
       "         ('feels', 'like'): 2,\n",
       "         ('a', 'premium'): 1,\n",
       "         ('premium', 'car'): 1,\n",
       "         ('car', 'and'): 1,\n",
       "         ('and', 'is'): 1,\n",
       "         ('is', 'rock'): 1,\n",
       "         ('rock', 'solid'): 1,\n",
       "         ('solid', 'trouble'): 1,\n",
       "         ('trouble', 'free'): 1,\n",
       "         ('free', ','): 1,\n",
       "         (',', 'worry'): 1,\n",
       "         ('worry', 'free'): 1,\n",
       "         ('free', 'car'): 1,\n",
       "         ('The', 'biggest'): 1,\n",
       "         ('biggest', 'expense'): 1,\n",
       "         ('expense', 'here'): 1,\n",
       "         ('here', 'was'): 1,\n",
       "         ('was', 'insurance'): 1,\n",
       "         ('insurance', '.'): 1,\n",
       "         ('.', 'This'): 1,\n",
       "         ('This', 'one'): 1,\n",
       "         ('one', 'has'): 1,\n",
       "         ('done', '25k'): 1,\n",
       "         ('25k', 'and'): 1,\n",
       "         ('and', 'feels'): 1,\n",
       "         ('like', 'We'): 1,\n",
       "         ('We', 'bought'): 1,\n",
       "         ('bought', 'it'): 1,\n",
       "         ('it', 'yesterday'): 1,\n",
       "         ('yesterday', '.'): 1,\n",
       "         ('.', 'In'): 1,\n",
       "         ('In', 'terms'): 1,\n",
       "         ('terms', 'of'): 1,\n",
       "         ('of', 'comfort'): 1,\n",
       "         ('comfort', 'Toyota'): 1,\n",
       "         ('Toyota', 'is'): 1,\n",
       "         ('is', 'far'): 1,\n",
       "         ('far', 'superior'): 1,\n",
       "         ('superior', 'than'): 1,\n",
       "         ('than', 'any'): 1,\n",
       "         ('any', 'car'): 2,\n",
       "         ('car', 'in'): 2,\n",
       "         ('in', 'the'): 2,\n",
       "         ('the', 'industry'): 1,\n",
       "         ('industry', 'be'): 1,\n",
       "         ('be', 'it'): 1,\n",
       "         ('it', 'the'): 1,\n",
       "         ('the', 'driver'): 1,\n",
       "         ('driver', 'or'): 1,\n",
       "         ('or', 'the'): 1,\n",
       "         ('the', 'passengers'): 2,\n",
       "         ('passengers', 'there'): 1,\n",
       "         ('there', 'is'): 1,\n",
       "         ('is', 'no'): 2,\n",
       "         ('no', 'match'): 1,\n",
       "         ('match', 'for'): 1,\n",
       "         ('for', 'Innova'): 1,\n",
       "         ('Innova', '.'): 1,\n",
       "         ('.', 'Honda'): 1,\n",
       "         ('Honda', 'city'): 1,\n",
       "         ('city', 'on'): 1,\n",
       "         ('hand', 'is'): 1,\n",
       "         ('is', 'superb'): 1,\n",
       "         ('superb', 'in'): 1,\n",
       "         ('in', 'driving'): 1,\n",
       "         ('driving', '.'): 1,\n",
       "         ('.', 'It'): 1,\n",
       "         ('It', ''): 1,\n",
       "         ('', 's'): 1,\n",
       "         ('s', 'steering'): 1,\n",
       "         ('steering', 'is'): 1,\n",
       "         ('is', 'so'): 1,\n",
       "         ('so', 'light'): 1,\n",
       "         ('light', 'that'): 1,\n",
       "         ('that', 'anyone'): 1,\n",
       "         ('anyone', 'can'): 1,\n",
       "         ('can', 'drive'): 1,\n",
       "         ('drive', 'it'): 1,\n",
       "         ('it', 'with'): 1,\n",
       "         ('with', 'ease'): 1,\n",
       "         ('ease', '.'): 1,\n",
       "         ('.', 'There'): 1,\n",
       "         ('There', 'is'): 1,\n",
       "         ('no', 'engine'): 1,\n",
       "         ('engine', 'sound'): 1,\n",
       "         ('sound', 'at'): 1,\n",
       "         ('at', 'idling'): 1,\n",
       "         ('idling', '.'): 1,\n",
       "         ('.', 'Super'): 1,\n",
       "         ('Super', 'smooth'): 1,\n",
       "         ('smooth', 'ride'): 1,\n",
       "         ('ride', 'and'): 1,\n",
       "         ('and', 'you'): 1,\n",
       "         ('you', 'reach'): 1,\n",
       "         ('reach', 'in'): 1,\n",
       "         ('in', 'comfort'): 1,\n",
       "         ('comfort', 'to'): 1,\n",
       "         ('to', 'your'): 1,\n",
       "         ('your', 'destination'): 1,\n",
       "         ('destination', '.'): 1,\n",
       "         ('.', 'Long'): 1,\n",
       "         ('Long', 'drives'): 1,\n",
       "         ('drives', 'for'): 1,\n",
       "         ('for', 'the'): 1,\n",
       "         ('passengers', 'is'): 1,\n",
       "         ('is', 'not'): 1,\n",
       "         ('not', 'as'): 1,\n",
       "         ('as', 'good'): 1,\n",
       "         ('good', 'as'): 1,\n",
       "         ('as', 'Innova'): 1,\n",
       "         ('Innova', 'though'): 1,\n",
       "         ('though', '.'): 1,\n",
       "         ('.', 'Overall'): 1,\n",
       "         ('Overall', 'to'): 1,\n",
       "         ('to', 'sum'): 1,\n",
       "         ('sum', 'up'): 1,\n",
       "         ('up', 'both'): 1,\n",
       "         ('both', 'are'): 1,\n",
       "         ('are', 'amazing'): 1,\n",
       "         ('amazing', 'brands'): 1,\n",
       "         ('brands', 'super'): 1,\n",
       "         ('super', 'reliable'): 1,\n",
       "         ('reliable', ','): 1,\n",
       "         (',', 'great'): 1,\n",
       "         ('great', 'resale'): 1,\n",
       "         ('resale', 'value'): 1,\n",
       "         ('value', 'for'): 1,\n",
       "         ('for', 'both'): 1,\n",
       "         ('.', 'Service'): 1,\n",
       "         ('Service', 'cost'): 1,\n",
       "         ('cost', 'is'): 1,\n",
       "         ('is', 'comparable'): 1,\n",
       "         ('comparable', 'to'): 1,\n",
       "         ('to', 'any'): 1,\n",
       "         ('the', 'segment'): 1,\n",
       "         ('segment', '.'): 1,\n",
       "         ('.', 'To'): 1,\n",
       "         ('To', 'decide'): 1,\n",
       "         ('decide', 'between'): 1,\n",
       "         ('between', 'one'): 1,\n",
       "         ('one', 'of'): 1,\n",
       "         ('of', 'the'): 1,\n",
       "         ('the', 'two'): 1,\n",
       "         ('two', 'is'): 1,\n",
       "         ('is', 'a'): 1,\n",
       "         ('a', 'difficult'): 1,\n",
       "         ('difficult', 'decision'): 1,\n",
       "         ('decision', 'as'): 1,\n",
       "         ('as', 'both'): 1,\n",
       "         ('both', 'the'): 1,\n",
       "         ('the', 'brands'): 1,\n",
       "         ('brands', 'are'): 1,\n",
       "         ('are', 'of'): 1,\n",
       "         ('of', 'amazing'): 1,\n",
       "         ('amazing', 'quality'): 1,\n",
       "         ('quality', '.'): 1})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams1_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score(gen_templates, target1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.025974025974025976, recall=0.2857142857142857, fmeasure=0.04761904761904762),\n",
       " 'rouge2': Score(precision=0.004347826086956522, recall=0.05, fmeasure=0.008)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.17316017316017315, recall=0.3669724770642202, fmeasure=0.2352941176470588),\n",
       " 'rouge2': Score(precision=0.02608695652173913, recall=0.05555555555555555, fmeasure=0.03550295857988165)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score(small, target1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.23809523809523808, recall=0.34375, fmeasure=0.28132992327365725),\n",
       " 'rouge2': Score(precision=0.02608695652173913, recall=0.03773584905660377, fmeasure=0.030848329048843187)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score(big, target1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.2857142857142857, recall=0.025974025974025976, fmeasure=0.04761904761904762),\n",
       " 'rouge2': Score(precision=0.05, recall=0.004347826086956522, fmeasure=0.008)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score(target1, gen_templates)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In terms of sheer corporate value, Toyota is the most successful, preponderant automaker in the world. Honda is much smaller with an overall value that's just 25 percent of Toyota's. Toyota also sells many more vehicles in the United States every year than Honda.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
