{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from gen import generate_one_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "max_len = 0\n",
    "df = pd.DataFrame(columns=['Object 1', 'Object 2', 'Question', 'Best Answer',  'Answers'])\n",
    "\n",
    "with open('yahoo_answers_positive_questions.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for ind, row in enumerate(reader):\n",
    "        d = {'Object 1': row[0], 'Object 2': row[1], 'Question': row[2], 'Best Answer': row[3],  'Answers': [elem for elem in row[3:]]}\n",
    "        if (ind > 0):\n",
    "            df = df.append(d, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()\n",
    "a = bc.encode(['First do it', 'then do it right', 'then do it better'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13186501,  0.32404107, -0.82704383, -0.51204693, -0.21091762,\n",
       "       -0.0075642 ,  0.27821508,  0.14547256,  0.31613034, -0.80404204],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24873537, -0.12334403, -0.38933882, -0.05058617, -0.28318736,\n",
       "        0.00659929,  0.07119087,  0.523146  ,  0.2606893 , -0.4676088 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.stem import porter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import collections\n",
    "\n",
    "stemmer = porter.PorterStemmer()\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def create_ngrams(tokens, n): #сюда добавть эмбединги\n",
    "    ngrams = collections.Counter()\n",
    "    ngrams_embs = collections.Counter()\n",
    "    for ngram in (tuple(tokens[i:i + n]) for i in range(len(tokens) - n + 1)):\n",
    "        ngrams[ngram] += 1\n",
    "    return ngrams\n",
    "\n",
    "def fmeasure(precision, recall):\n",
    "  \"\"\"Computes f-measure given precision and recall values.\"\"\"\n",
    "\n",
    "  if precision + recall > 0:\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "  else:\n",
    "    return 0.0\n",
    "\n",
    "def cos_sim(emb1, emb2):\n",
    "    return cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))\n",
    "\n",
    "def count_ngram_overlap(ngram1_embs, ngram2_embs): #The idea count cousine similarity to every pair. If > 0.6 than add\n",
    "    result = 1\n",
    "    #print (\"ngram1_embs\", len(ngram1_embs), len(ngram1_embs[0]))\n",
    "    for elem in ngram1_embs: # по словам в н-граме\n",
    "        similarities = [cos_sim(elem, elem2)[0][0] if cos_sim(elem, elem2) >= 0.6 else 0 for elem2 in ngram2_embs]\n",
    "        #print (similarities)\n",
    "        max_ = max(similarities)\n",
    "        result *= max_\n",
    "    return result\n",
    "        \n",
    "\n",
    "def count_overlap(ngram, ngram_emb, list_of_ngrams2, list_of_ngrams2_embs): # only if ngram not in list_of_ngrams !!!\n",
    "    overlaps = [count_ngram_overlap(ngram_emb, elem[1]) for elem in list_of_ngrams2_embs] # по всем н-грамам\n",
    "    return max(overlaps)\n",
    "\n",
    "def score_ngrams(target_ngrams, prediction_ngrams):\n",
    "    intersection_ngrams_count_pred = 0\n",
    "    intersection_ngrams_count_tg = 0\n",
    "    \n",
    "    #print (\"target_ngrams\", target_ngrams.keys())\n",
    "    #print (\"prediction_ngrams\", prediction_ngrams.keys())\n",
    "    \n",
    "    embeddings_target = bert_embedding([' '.join(elem)for elem in list(target_ngrams.keys())])\n",
    "    embeddings_predictions = bert_embedding([' '.join(elem)for elem in list(prediction_ngrams.keys())])\n",
    "    \n",
    "    for ind, ngram in enumerate(list(target_ngrams.keys())):\n",
    "        #print (\"ind\", ind)\n",
    "        intersection_ngrams_count_tg += min(target_ngrams[ngram],\n",
    "                                         prediction_ngrams[ngram])\n",
    "        #print (\"min\", min(target_ngrams[ngram], prediction_ngrams[ngram]))\n",
    "        if (min(target_ngrams[ngram], prediction_ngrams[ngram]) == 0):\n",
    "            #print (\"ngram\", ngram)\n",
    "            #print ('overlap')\n",
    "            overlap_ngram = count_overlap(ngram, embeddings_target[ind][1], prediction_ngrams, embeddings_predictions) #по всем н-грамам\n",
    "            #print ('overlap ngram', overlap_ngram)\n",
    "            intersection_ngrams_count_tg += overlap_ngram\n",
    "            \n",
    "    for ind, ngram in enumerate(list(prediction_ngrams.keys())):\n",
    "        #print (\"ind\", ind)\n",
    "        intersection_ngrams_count_tg += min(target_ngrams[ngram],\n",
    "                                         prediction_ngrams[ngram])\n",
    "        #print (\"min\", min(target_ngrams[ngram], prediction_ngrams[ngram]))\n",
    "        if (min(target_ngrams[ngram], prediction_ngrams[ngram]) == 0):\n",
    "            #print (\"ngram\", ngram)\n",
    "            #print ('overlap')\n",
    "            overlap_ngram = count_overlap(ngram, embeddings_predictions[ind][1], prediction_ngrams, embeddings_target) #по всем н-грамам\n",
    "            #print ('overlap ngram', overlap_ngram)\n",
    "            intersection_ngrams_count_pred += overlap_ngram\n",
    "            \n",
    "    target_ngrams_count = sum(target_ngrams.values())\n",
    "    prediction_ngrams_count = sum(prediction_ngrams.values())\n",
    "    \n",
    "    precision = intersection_ngrams_count_pred / max(prediction_ngrams_count, 1)\n",
    "    recall = intersection_ngrams_count_tg / max(target_ngrams_count, 1)\n",
    "    \n",
    "    f = fmeasure(precision, recall)\n",
    "    return f, precision, recall\n",
    "\n",
    "def score_ngrams_v0(target_ngrams, prediction_ngrams):\n",
    "    intersection_ngrams_count = 0\n",
    "    \n",
    "    #print (\"target_ngrams\", target_ngrams)\n",
    "    #print (\"prediction_ngrams\", prediction_ngrams)\n",
    "    \n",
    "    embeddings_target = bert_embedding([' '.join(elem)for elem in list(target_ngrams.keys())])\n",
    "    embeddings_predictions = bert_embedding([' '.join(elem)for elem in list(prediction_ngrams.keys())])\n",
    "    \n",
    "    for ind, ngram in enumerate(list(target_ngrams.keys())):\n",
    "        #print (\"ind\", ind)\n",
    "        intersection_ngrams_count += min(target_ngrams[ngram],\n",
    "                                         prediction_ngrams[ngram])\n",
    "        if (min(target_ngrams[ngram], prediction_ngrams[ngram]) == 0):\n",
    "            #print (\"ngram\", ngram)\n",
    "            #print ('overlap')\n",
    "            overlap_ngram = count_overlap(ngram, embeddings_target[ind][1], prediction_ngrams, embeddings_predictions) #по всем н-грамам\n",
    "            #print ('overlap ngram', overlap_ngram)\n",
    "            intersection_ngrams_count += overlap_ngram\n",
    "            \n",
    "    target_ngrams_count = sum(target_ngrams.values())\n",
    "    prediction_ngrams_count = sum(prediction_ngrams.values())\n",
    "    \n",
    "    #print (\"intersection_ngrams_count\", intersection_ngrams_count)\n",
    "    #print (\"intersection_targets_count\", prediction_ngrams_count, target_ngrams_count)\n",
    "\n",
    "\n",
    "    precision = intersection_ngrams_count / max(prediction_ngrams_count, 1)\n",
    "    recall = intersection_ngrams_count / max(target_ngrams_count, 1)\n",
    "    #print (precision, recall)\n",
    "    \n",
    "    f = fmeasure(precision, recall)\n",
    "    return f, precision, recall\n",
    "\n",
    "from bert_embedding import BertEmbedding\n",
    "bert_embedding = BertEmbedding()\n",
    "\n",
    "def simple_rouge(generated_answers, possible_aswers_list):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "    rouge_1_list = []\n",
    "    rouge_2_list = []\n",
    "    for ind, elem in enumerate(generated_answers):\n",
    "        if (elem != \"We can't recognize objects for comparision\"):\n",
    "            generated_answer = generated_answers[ind]\n",
    "            scores = [scorer.score(generated_answer, answ) for answ in possible_aswers_list[ind]]\n",
    "            sorted_scores_1 = sorted(scores, key=lambda x: x['rouge1'].fmeasure, reverse = True)\n",
    "            sorted_scores_2 = sorted(scores, key=lambda x: x['rouge2'].fmeasure, reverse = True)\n",
    "            rouge_1_list.append(sorted_scores_1[0]['rouge1'])\n",
    "            rouge_2_list.append(sorted_scores_2[0]['rouge2'])\n",
    "    return {'rouge1':rouge_1_list, 'rouge2':rouge_2_list}\n",
    "\n",
    "\n",
    "def rouge_cos(gen_answers, possible_answers):\n",
    "    list_of_n1 = []\n",
    "    list_of_n2 = []\n",
    "    list_of_n3 = []\n",
    "    for ind, elem in enumerate(gen_answers):\n",
    "        print (ind)\n",
    "        if (elem != \"We can't recognize objects for comparision\"):\n",
    "            ngrams1 = create_ngrams(tokenizer.tokenize(elem), 1)\n",
    "            answ_token_list = [tokenizer.tokenize(elemt) for elemt in possible_answers[0]]\n",
    "            #scores_list_1 = [score_ngrams(ngrams1, create_ngrams(possible_answ, 1)) for possible_answ in answ_token_list]\n",
    "            #sorted_scores_1 = sorted(scores_list_1, key=lambda x: x[0], reverse = True)\n",
    "            #print (\"target1\", sorted_scores_1[0])\n",
    "            #list_of_n1.append(sorted_scores_1[0])\n",
    "            #print (ind, \"n2\")\n",
    "            #ngrams01 = create_ngrams(tokenizer.tokenize(elem), 2)\n",
    "            #scores_list_2 = [score_ngrams(ngrams01, create_ngrams(possible_answ, 2)) for possible_answ in answ_token_list]\n",
    "            #sorted_scores_2 = sorted(scores_list_2, key=lambda x: x[0], reverse = True)\n",
    "            #print (\"target2\", sorted_scores_2[0])\n",
    "            #list_of_n2.append(sorted_scores_2[0])\n",
    "            ngrams001 = create_ngrams(tokenizer.tokenize(elem), 3)\n",
    "            scores_list_3 = [score_ngrams(ngrams001, create_ngrams(possible_answ, 3)) for possible_answ in answ_token_list]\n",
    "            sorted_scores_3 = sorted(scores_list_3, key=lambda x: x[0], reverse = True)\n",
    "            print (\"target3\", sorted_scores_3[0])\n",
    "            list_of_n3.append(sorted_scores_3[0])\n",
    "    return {'rouge1':list_of_n1, 'rouge2':list_of_n2, 'rouge3':list_of_n3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from count_rouge import simple_rouge, rouge_cos3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('template_score3_.pkl', 'rb') as f:\n",
    "    r3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02261789797751744"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(np.array(r3['rouge3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "target3 (0.011686172071296071, 0.0062407829909539225, 0.09169150394401532)\n",
      "4\n",
      "5\n",
      "target3 (0.046036352320734296, 0.03193900900038295, 0.0824113340921053)\n",
      "6\n",
      "target3 (0.0724029720481841, 0.06681907892091077, 0.07900522943948976)\n",
      "7\n",
      "target3 (0.011563533405216004, 0.006446416999450632, 0.056077127078113215)\n",
      "8\n",
      "9\n",
      "target3 (0.016609153707893325, 0.022146965747418226, 0.013286809130026755)\n",
      "10\n",
      "target3 (0.016609153707893325, 0.022146965747418226, 0.013286809130026755)\n",
      "11\n",
      "target3 (0.022020799039727836, 0.017351450352337264, 0.030128507983242063)\n",
      "12\n",
      "target3 (0.02997299542233473, 0.04332746278725177, 0.02291124949869029)\n",
      "13\n",
      "target3 (0.018788948025364894, 0.020705589606136936, 0.017197076792733416)\n",
      "14\n",
      "target3 (0.016609153707893325, 0.022146965747418226, 0.013286809130026755)\n",
      "15\n",
      "target3 (0.018200834129242793, 0.018039350303178152, 0.01836523519670353)\n",
      "16\n",
      "target3 (0.01144149910520515, 0.006110119940999609, 0.08977176221007117)\n",
      "17\n",
      "18\n",
      "target3 (0.02704476074173522, 0.08056483187515548, 0.01624982793269686)\n",
      "19\n",
      "target3 (0.024195730602642802, 0.0212970986393336, 0.028007706857807225)\n",
      "20\n",
      "target3 (0.011104197920386088, 0.005959943401621526, 0.08113435467467282)\n",
      "21\n",
      "target3 (0.009948890763202113, 0.005656167913015977, 0.041272360903292)\n",
      "22\n",
      "23\n",
      "target3 (0.02882641387932847, 0.02836032077356943, 0.029308083167072053)\n",
      "24\n",
      "target3 (0.020359978737715986, 0.02055307466703583, 0.020170477306739504)\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('cam_answers1.pkl', 'rb') as f:\n",
    "    template_answers = pickle.load(f)\n",
    "templ_scors = rouge_cos3(template_answers[:100], df['Answers'].values[:100])\n",
    "with open('cam_score3_.pkl', 'wb') as f:\n",
    "    pickle.dump(templ_scors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cam_answers\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "target_ngrams dict_keys([('microsoft', 'has', 'undeniable'), ('has', 'undeniable', 'advantages'), ('undeniable', 'advantages', '.'), ('advantages', '.', 'They'), ('.', 'They', 'are'), ('They', 'are', 'simpler'), ('are', 'simpler', ','), ('simpler', ',', 'friendlier'), (',', 'friendlier', 'and'), ('friendlier', 'and', 'easier'), ('and', 'easier', 'to'), ('easier', 'to', 'use'), ('to', 'use', '.')])\n",
      "prediction_ngrams dict_keys([('How', 'can', 'you'), ('can', 'you', 'even'), ('you', 'even', 'ask'), ('even', 'ask', 'this'), ('ask', 'this', 'question'), ('this', 'question', 'yet'), ('question', 'yet', '?'), ('yet', '?', 'Only'), ('?', 'Only', 'the'), ('Only', 'the', 'Xbox'), ('the', 'Xbox', '360'), ('Xbox', '360', 'is'), ('360', 'is', 'out'), ('is', 'out', 'at'), ('out', 'at', 'the'), ('at', 'the', 'moment'), ('the', 'moment', 'and'), ('moment', 'and', 'that'), ('and', 'that', \"hasn't\"), ('that', \"hasn't\", 'even'), (\"hasn't\", 'even', 'been'), ('even', 'been', 'tested'), ('been', 'tested', 'by'), ('tested', 'by', 'gamers'), ('by', 'gamers', 'enough'), ('gamers', 'enough', 'to'), ('enough', 'to', 'see'), ('to', 'see', 'truely'), ('see', 'truely', 'how'), ('truely', 'how', 'good'), ('how', 'good', 'or'), ('good', 'or', 'rubbish'), ('or', 'rubbish', 'it'), ('rubbish', 'it', 'is'), ('it', 'is', '.'), ('is', '.', 'You'), ('.', 'You', 'need'), ('You', 'need', 'to'), ('need', 'to', 'ask'), ('to', 'ask', 'the'), ('ask', 'the', 'question'), ('the', 'question', 'again'), ('question', 'again', 'when'), ('again', 'when', 'all'), ('when', 'all', 'three'), ('all', 'three', 'systems'), ('three', 'systems', 'are'), ('systems', 'are', 'out'), ('are', 'out', '!')])\n",
      "target_ngrams dict_keys([('microsoft', 'has', 'undeniable'), ('has', 'undeniable', 'advantages'), ('undeniable', 'advantages', '.'), ('advantages', '.', 'They'), ('.', 'They', 'are'), ('They', 'are', 'simpler'), ('are', 'simpler', ','), ('simpler', ',', 'friendlier'), (',', 'friendlier', 'and'), ('friendlier', 'and', 'easier'), ('and', 'easier', 'to'), ('easier', 'to', 'use'), ('to', 'use', '.')])\n",
      "prediction_ngrams dict_keys([('How', 'can', 'you'), ('can', 'you', 'even'), ('you', 'even', 'ask'), ('even', 'ask', 'this'), ('ask', 'this', 'question'), ('this', 'question', 'yet'), ('question', 'yet', '?'), ('yet', '?', 'Only'), ('?', 'Only', 'the'), ('Only', 'the', 'Xbox'), ('the', 'Xbox', '360'), ('Xbox', '360', 'is'), ('360', 'is', 'out'), ('is', 'out', 'at'), ('out', 'at', 'the'), ('at', 'the', 'moment'), ('the', 'moment', 'and'), ('moment', 'and', 'that'), ('and', 'that', \"hasn't\"), ('that', \"hasn't\", 'even'), (\"hasn't\", 'even', 'been'), ('even', 'been', 'tested'), ('been', 'tested', 'by'), ('tested', 'by', 'gamers'), ('by', 'gamers', 'enough'), ('gamers', 'enough', 'to'), ('enough', 'to', 'see'), ('to', 'see', 'truely'), ('see', 'truely', 'how'), ('truely', 'how', 'good'), ('how', 'good', 'or'), ('good', 'or', 'rubbish'), ('or', 'rubbish', 'it'), ('rubbish', 'it', 'is'), ('it', 'is', '.'), ('is', '.', 'You'), ('.', 'You', 'need'), ('You', 'need', 'to'), ('need', 'to', 'ask'), ('to', 'ask', 'the'), ('ask', 'the', 'question'), ('the', 'question', 'again'), ('question', 'again', 'when'), ('again', 'when', 'all'), ('when', 'all', 'three'), ('all', 'three', 'systems'), ('three', 'systems', 'are'), ('systems', 'are', 'out'), ('are', 'out', '!')])\n",
      "target_ngrams dict_keys([('microsoft', 'has', 'undeniable'), ('has', 'undeniable', 'advantages'), ('undeniable', 'advantages', '.'), ('advantages', '.', 'They'), ('.', 'They', 'are'), ('They', 'are', 'simpler'), ('are', 'simpler', ','), ('simpler', ',', 'friendlier'), (',', 'friendlier', 'and'), ('friendlier', 'and', 'easier'), ('and', 'easier', 'to'), ('easier', 'to', 'use'), ('to', 'use', '.')])\n",
      "prediction_ngrams dict_keys([('The', 'story', 'I'), ('story', 'I', 'keep'), ('I', 'keep', 'hearing'), ('keep', 'hearing', 'is'), ('hearing', 'is', 'that'), ('is', 'that', \"Nintendo's\"), ('that', \"Nintendo's\", 'Revolution'), (\"Nintendo's\", 'Revolution', 'will'), ('Revolution', 'will', 'play'), ('will', 'play', 'all'), ('play', 'all', 'the'), ('all', 'the', 'old'), ('the', 'old', 'Nintendo'), ('old', 'Nintendo', 'games'), ('Nintendo', 'games', 'from'), ('games', 'from', 'most'), ('from', 'most', 'of'), ('most', 'of', 'their'), ('of', 'their', 'different'), ('their', 'different', 'consoles'), ('different', 'consoles', '.'), ('consoles', '.', 'For'), ('.', 'For', 'me'), ('For', 'me', ','), ('me', ',', 'that'), (',', 'that', 'sells'), ('that', 'sells', 'it'), ('sells', 'it', 'more'), ('it', 'more', 'than'), ('more', 'than', 'anything'), ('than', 'anything', '.'), ('anything', '.', 'Being'), ('.', 'Being', 'able'), ('Being', 'able', 'to'), ('able', 'to', 'play'), ('to', 'play', 'Super'), ('play', 'Super', 'Mario'), ('Super', 'Mario', '3'), ('Mario', '3', ','), ('3', ',', 'then'), (',', 'then', 'go'), ('then', 'go', 'to'), ('go', 'to', 'Super'), ('to', 'Super', 'Mario'), ('Super', 'Mario', '64'), ('Mario', '64', ','), ('64', ',', 'then'), ('go', 'to', 'Need'), ('to', 'Need', 'for'), ('Need', 'for', 'Speed'), ('for', 'Speed', 'Underground'), ('Speed', 'Underground', 'all'), ('Underground', 'all', 'on'), ('all', 'on', 'the'), ('on', 'the', 'same'), ('the', 'same', 'box'), ('same', 'box', 'would'), ('box', 'would', 'be'), ('would', 'be', 'awesome'), ('be', 'awesome', '.')])\n",
      "target_ngrams dict_keys([('microsoft', 'has', 'undeniable'), ('has', 'undeniable', 'advantages'), ('undeniable', 'advantages', '.'), ('advantages', '.', 'They'), ('.', 'They', 'are'), ('They', 'are', 'simpler'), ('are', 'simpler', ','), ('simpler', ',', 'friendlier'), (',', 'friendlier', 'and'), ('friendlier', 'and', 'easier'), ('and', 'easier', 'to'), ('easier', 'to', 'use'), ('to', 'use', '.')])\n",
      "prediction_ngrams dict_keys([('They', 'all', 'have'), ('all', 'have', 'their'), ('have', 'their', 'strengths'), ('their', 'strengths', 'and'), ('strengths', 'and', 'weeknesses'), ('and', 'weeknesses', '.'), ('weeknesses', '.', 'Its'), ('.', 'Its', 'really'), ('Its', 'really', 'more'), ('really', 'more', 'or'), ('more', 'or', 'less'), ('or', 'less', 'a'), ('less', 'a', 'view'), ('a', 'view', 'of'), ('view', 'of', 'personal'), ('of', 'personal', 'choice'), ('personal', 'choice', '.'), ('choice', '.', 'More'), ('.', 'More', 'then'), ('More', 'then', 'likely'), ('then', 'likely', 'people'), ('likely', 'people', 'will'), ('people', 'will', 'have'), ('will', 'have', 'multiple'), ('have', 'multiple', 'next'), ('multiple', 'next', 'generation'), ('next', 'generation', 'consoles'), ('generation', 'consoles', 'when'), ('consoles', 'when', 'they'), ('when', 'they', 'can'), ('they', 'can', 'afford'), ('can', 'afford', 'it'), ('afford', 'it', '('), ('it', '(', '400'), ('(', '400', 'dollars'), ('400', 'dollars', 'for'), ('dollars', 'for', 'one'), ('for', 'one', ','), ('one', ',', '400'), (',', '400', 'dollars'), ('dollars', 'for', 'another'), ('for', 'another', ','), ('another', ',', 'with'), (',', 'with', 'the'), ('with', 'the', 'Nitendo'), ('the', 'Nitendo', 'being'), ('Nitendo', 'being', 'the'), ('being', 'the', 'cheapest'), ('the', 'cheapest', 'but'), ('cheapest', 'but', 'mostly'), ('but', 'mostly', 'being'), ('mostly', 'being', 'considered'), ('being', 'considered', 'too'), ('considered', 'too', 'kidish'), ('too', 'kidish', 'based'), ('kidish', 'based', 'to'), ('based', 'to', 'many'), ('to', 'many', ')'), ('many', ')', '.'), (')', '.', 'They'), ('.', 'They', 'all'), ('all', 'have', 'backwards'), ('have', 'backwards', 'compatibility'), ('backwards', 'compatibility', 'in'), ('compatibility', 'in', 'a'), ('in', 'a', 'way'), ('a', 'way', ','), ('way', ',', 'Xbox'), (',', 'Xbox', 'will'), ('Xbox', 'will', 'have'), ('will', 'have', 'a'), ('have', 'a', 'emulator'), ('a', 'emulator', ','), ('emulator', ',', 'Ps3'), (',', 'Ps3', 'will'), ('Ps3', 'will', 'just'), ('will', 'just', 'have'), ('just', 'have', 'backwards'), ('have', 'backwards', 'capatibility'), ('backwards', 'capatibility', 'from'), ('capatibility', 'from', 'the'), ('from', 'the', 'get'), ('the', 'get', 'go'), ('get', 'go', ','), ('go', ',', 'and'), (',', 'and', 'even'), ('and', 'even', 'Nitendo'), ('even', 'Nitendo', 'I'), ('Nitendo', 'I', 'believe'), ('I', 'believe', '.'), ('believe', '.', 'What'), ('.', 'What', 'it'), ('What', 'it', 'comes'), ('it', 'comes', 'down'), ('comes', 'down', 'to'), ('down', 'to', 'though'), ('to', 'though', 'is'), ('though', 'is', 'the'), ('is', 'the', 'games'), ('the', 'games', ','), ('games', ',', 'which'), (',', 'which', 'is'), ('which', 'is', 'why'), ('is', 'why', 'people'), ('why', 'people', 'will'), ('people', 'will', 'own'), ('will', 'own', 'many'), ('own', 'many', 'console'), ('many', 'console', 'systems'), ('console', 'systems', 'in'), ('systems', 'in', 'the'), ('in', 'the', 'future'), ('the', 'future', '.'), ('future', '.', 'The'), ('.', 'The', 'first'), ('The', 'first', 'Xbox'), ('first', 'Xbox', 'may'), ('Xbox', 'may', 'of'), ('may', 'of', 'been'), ('of', 'been', 'better'), ('been', 'better', 'with'), ('better', 'with', 'graphics'), ('with', 'graphics', ','), ('graphics', ',', 'but'), (',', 'but', 'it'), ('but', 'it', \"wasn't\"), ('it', \"wasn't\", 'enough'), (\"wasn't\", 'enough', 'to'), ('enough', 'to', 'lure'), ('to', 'lure', 'everybody'), ('lure', 'everybody', 'from'), ('everybody', 'from', 'the'), ('from', 'the', 'Ps2'), ('the', 'Ps2', 'simply'), ('Ps2', 'simply', 'because'), ('simply', 'because', 'the'), ('because', 'the', 'Ps2'), ('the', 'Ps2', 'had'), ('Ps2', 'had', 'some'), ('had', 'some', 'damn'), ('some', 'damn', 'awesome'), ('damn', 'awesome', 'games'), ('awesome', 'games', '.'), ('games', '.', \"We'll\"), ('.', \"We'll\", 'see'), (\"We'll\", 'see', 'how'), ('see', 'how', 'the'), ('how', 'the', 'games'), ('the', 'games', 'fan'), ('games', 'fan', 'out'), ('fan', 'out', ','), ('out', ',', '18'), (',', '18', 'games'), ('18', 'games', 'for'), ('games', 'for', 'the'), ('for', 'the', 'Xbox'), ('the', 'Xbox', '360'), ('Xbox', '360', '/'), ('360', '/', 'NOW'), ('/', 'NOW', '/'), ('NOW', '/', \"isn't\"), ('/', \"isn't\", 'enough'), (\"isn't\", 'enough', 'to'), ('enough', 'to', 'go'), ('to', 'go', 'crazy'), ('go', 'crazy', 'over'), ('crazy', 'over', '.'), ('over', '.', 'Save'), ('.', 'Save', 'your'), ('Save', 'your', 'money'), ('your', 'money', 'until'), ('money', 'until', 'you'), ('until', 'you', 'can'), ('you', 'can', 'tell'), ('can', 'tell', 'which'), ('tell', 'which', 'is'), ('which', 'is', 'better'), ('is', 'better', 'by'), ('better', 'by', 'who'), ('by', 'who', 'has'), ('who', 'has', 'the'), ('has', 'the', 'best'), ('the', 'best', 'games'), ('best', 'games', 'that'), ('games', 'that', 'you'), ('that', 'you', 'absolutely'), ('you', 'absolutely', 'must'), ('absolutely', 'must', 'have'), ('must', 'have', '.')])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fe61134d54d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cam_answers1.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcam_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcam_scors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge_cos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam_answers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Answers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cam_score03.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam_scors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-85678993568b>\u001b[0m in \u001b[0;36mrouge_cos\u001b[0;34m(gen_answers, possible_answers)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;31m#list_of_n2.append(sorted_scores_2[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mngrams001\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mscores_list_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_answ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpossible_answ\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mansw_token_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0msorted_scores_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_list_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"target3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_scores_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-85678993568b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;31m#list_of_n2.append(sorted_scores_2[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mngrams001\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mscores_list_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_answ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpossible_answ\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mansw_token_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0msorted_scores_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_list_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"target3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_scores_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-85678993568b>\u001b[0m in \u001b[0;36mscore_ngrams\u001b[0;34m(target_ngrams, prediction_ngrams)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0membeddings_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ngrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0membeddings_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_ngrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ngrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/bert_embedding/bert.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sentences, oov_way)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moov_way\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moov_way\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/bert_embedding/bert.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(self, sentences, oov_way)\u001b[0m\n\u001b[1;32m    136\u001b[0m                                          valid_length.astype(self.dtype))\n\u001b[1;32m    137\u001b[0m             for token_id, sequence_output in zip(token_ids.asnumpy(),\n\u001b[0;32m--> 138\u001b[0;31m                                                  sequence_outputs.asnumpy()):\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moov_way\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "print (\"cam_answers\")   \n",
    "with open('cam_answers1.pkl', 'rb') as f:\n",
    "    cam_answers = pickle.load(f)\n",
    "cam_scors = rouge_cos(cam_answers, df['Answers'].values)\n",
    "with open('cam_score03.pkl', 'wb') as f:\n",
    "    pickle.dump(cam_scors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rat and mouse are actually not scientific classifications. These words are common names for rodents that look alike to the casual eye.\\n\\nRat is used to describe medium-sized rodents with long thin tails. There are many species of rodent that are called rats -- kangaroo rats, cotton rats, Norway rats, black rats, African pouched rats, naked mole rats, wood rats, pack rats, Polynesian rats, and many others. These different rodent species may not be closely related to each other at all!\\n\\nMouse is used to describe tiny, sparrow-sized rodents with long thin tails. As with rats, there are many species of rodents called mice which may or may not be closely related to each other: house mice, field mice, deer mice, smoky mice, spiny mice, and dormice are all called mice.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Best Answer'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rat and mouse are actually not scientific classifications. These words are common names for rodents that look alike to the casual eye.\\n\\nRat is used to describe medium-sized rodents with long thin tails. There are many species of rodent that are called rats -- kangaroo rats, cotton rats, Norway rats, black rats, African pouched rats, naked mole rats, wood rats, pack rats, Polynesian rats, and many others. These different rodent species may not be closely related to each other at all!\\n\\nMouse is used to describe tiny, sparrow-sized rodents with long thin tails. As with rats, there are many species of rodents called mice which may or may not be closely related to each other: house mice, field mice, deer mice, smoky mice, spiny mice, and dormice are all called mice.',\n",
       " 'Rat and mouse are actually not scientific classifications. These words are common names for rodents that look alike to the casual eye. Rat is used to describe medium-sized rodents with long thin tails. There are many species of rodent that are called rats -- kangaroo rats, cotton rats, Norway rats, black rats, African pouched rats, naked mole rats, wood rats, pack rats, Polynesian rats, and many others. These different rodent species may not be closely related to each other at all! Mouse is used to describe tiny, sparrow-sized rodents with long thin tails. As with rats, there are many species of rodents called mice which may or may not be closely related to each other: house mice, field mice, deer mice, smoky mice, spiny mice, and dormice are all called mice.',\n",
       " \"a rat is an animal, a mouse is a computer's hardware\"]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Answers'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from count_rouge_new import rouge_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rat and mouse are actually not scientific classifications. These words are common names for rodents that look alike to the casual eye.\\n\\nRat is used to describe medium-sized rodents with long thin tails. There are many species of rodent that are called rats -- kangaroo rats, cotton rats, Norway rats, black rats, African pouched rats, naked mole rats, wood rats, pack rats, Polynesian rats, and many others. These different rodent species may not be closely related to each other at all!\\n\\nMouse is used to describe tiny, sparrow-sized rodents with long thin tails. As with rats, there are many species of rodents called mice which may or may not be closely related to each other: house mice, field mice, deer mice, smoky mice, spiny mice, and dormice are all called mice.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_answers = [df.Answers[10][0]]\n",
    "possible_answers = df.Answers[10]\n",
    "possible_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0, 2.0)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"a rat is an animal, a mouse is a computer's hardware\"]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.Answers[10][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Rat and mouse are actually not scientific classifications. These words are common names for rodents that look alike to the casual eye.\n",
      "\n",
      "Rat is used to describe medium-sized rodents with long thin tails. There are many species of rodent that are called rats -- kangaroo rats, cotton rats, Norway rats, black rats, African pouched rats, naked mole rats, wood rats, pack rats, Polynesian rats, and many others. These different rodent species may not be closely related to each other at all!\n",
      "\n",
      "Mouse is used to describe tiny, sparrow-sized rodents with long thin tails. As with rats, there are many species of rodents called mice which may or may not be closely related to each other: house mice, field mice, deer mice, smoky mice, spiny mice, and dormice are all called mice.\n",
      "target_ngrams 76\n",
      "prediction_ngrams 9\n",
      "target1 (0.4255484593227026, 0.42695072293281555, 0.42415537666051817)\n",
      "target_ngrams 121\n",
      "prediction_ngrams 11\n",
      "target2 (0.7016925133386461, 0.858322490345348, 0.5934055878270057)\n",
      "target_ngrams 140\n",
      "prediction_ngrams 10\n",
      "target2 (0.738389664764429, 0.8275334715843201, 0.6665837335122096)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': [(0.4255484593227026, 0.42695072293281555, 0.42415537666051817)],\n",
       " 'rouge2': [(0.7016925133386461, 0.858322490345348, 0.5934055878270057)],\n",
       " 'rouge3': [(0.738389664764429, 0.8275334715843201, 0.6665837335122096)]}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_cos1([df.Answers[10][0]], [df.Answers[10][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object 1</th>\n",
       "      <th>Object 2</th>\n",
       "      <th>Question</th>\n",
       "      <th>Best Answer</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>sony</td>\n",
       "      <td>which next-gen console is the best NITENDO SON...</td>\n",
       "      <td>How can you even ask this question yet? Only t...</td>\n",
       "      <td>[How can you even ask this question yet? Only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>sony</td>\n",
       "      <td>wich is better, the Sony play station or the M...</td>\n",
       "      <td>For a wide selection, choose PS2. However, XBO...</td>\n",
       "      <td>[For a wide selection, choose PS2. However, XB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>sony</td>\n",
       "      <td>Who do you think will win the next-gen war Son...</td>\n",
       "      <td>PS3 hands down</td>\n",
       "      <td>[PS3 hands down, PS3 hands down, I think Sony ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>sony</td>\n",
       "      <td>Which do you prefer Sony's PS3 or Microsoft's ...</td>\n",
       "      <td>I'll comment on PS3 when it's out but I am loo...</td>\n",
       "      <td>[I'll comment on PS3 when it's out but I am lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>sony</td>\n",
       "      <td>PS3 or X-BOX 360? We all know that these are t...</td>\n",
       "      <td>I'm sure you knew when you posted this that we...</td>\n",
       "      <td>[I'm sure you knew when you posted this that w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Object 1 Object 2                                           Question  \\\n",
       "0  microsoft     sony  which next-gen console is the best NITENDO SON...   \n",
       "1  microsoft     sony  wich is better, the Sony play station or the M...   \n",
       "2  microsoft     sony  Who do you think will win the next-gen war Son...   \n",
       "3  microsoft     sony  Which do you prefer Sony's PS3 or Microsoft's ...   \n",
       "4  microsoft     sony  PS3 or X-BOX 360? We all know that these are t...   \n",
       "\n",
       "                                         Best Answer  \\\n",
       "0  How can you even ask this question yet? Only t...   \n",
       "1  For a wide selection, choose PS2. However, XBO...   \n",
       "2                                     PS3 hands down   \n",
       "3  I'll comment on PS3 when it's out but I am loo...   \n",
       "4  I'm sure you knew when you posted this that we...   \n",
       "\n",
       "                                             Answers  \n",
       "0  [How can you even ask this question yet? Only ...  \n",
       "1  [For a wide selection, choose PS2. However, XB...  \n",
       "2  [PS3 hands down, PS3 hands down, I think Sony ...  \n",
       "3  [I'll comment on PS3 when it's out but I am lo...  \n",
       "4  [I'm sure you knew when you posted this that w...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# set width of bar\n",
    "barWidth = 0.20\n",
    "\n",
    "labels = ['Objects', 'Predicates', 'Aspects']\n",
    "simple = [57.22, 30.1, 11.98]\n",
    "elmo = [66.03, 41.57, 10.26]\n",
    "bert = [64.24, 53.25, 11.46]\n",
    "bert_plus = [69.21, 72.70, 19.05]\n",
    " \n",
    "# set height of bar\n",
    "bars1 = [12, 30, 1, 8, 22]\n",
    "bars2 = [28, 6, 16, 5, 10]\n",
    "bars3 = [29, 3, 24, 25, 17]\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(simple))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, simple, color='gold', width=barWidth, edgecolor='white', label='GloVe')\n",
    "plt.bar(r2, elmo, color='darkturquoise', width=barWidth, edgecolor='white', label='ELMO')\n",
    "plt.bar(r3, bert, color='dodgerblue', width=barWidth, edgecolor='white', label='BERT')\n",
    "plt.bar(r4, bert_plus, color='#2d7f5e', width=barWidth, edgecolor='white', label='BERT finetuned')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.ylabel('F1-score', fontsize=15)\n",
    "plt.xticks([r + barWidth for r in range(len(simple))], ['Objects', 'Predicates', 'Aspects'], fontsize=14)\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.savefig(\"F1_nlu.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = ['Objects', 'Predicates', 'Aspects']\n",
    "simple = [57.22, 30.1, 11.98]\n",
    "elmo = [66.03, 41.57, 10.26]\n",
    "bert = [64.24, 53.25, 11.46]\n",
    "bert_plus = [69.21, 72.70, 19.05]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/4, simple, width, label='Glove')\n",
    "rects2 = ax.bar(x - width/4, elmo, width, label='Elmo')\n",
    "rects3 = ax.bar(x + width/4, bert, width, label='BERT')\n",
    "rects4 = ax.bar(x + width/2, bert_plus, width, label='BERT fine-tuned')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('F1-score')\n",
    "ax.set_title('Scores by group and gender')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 4, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'honda is better than toyota because it is quicker, bigger, nicer. And it has some of the best engines in the market. But it is still competitive. The good news is that Honda is in the very early stages of making the right choice for the sportscar market. The bad news is that Honda is not taking any of the market-leading advantages of Toyota or Honda.'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_small[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['after much thought, I realized that  honda is better, because: quicker, bigger, nicer, weaker.. But i should tell you that toyota is: lighter, easier, faster, softer.',\n",
       " 'i came to the conclusion that motorola is better, because: better for me, bigger, easier for me to hold it, quicker., but nokia is: easier, faster, cheaper, t720.',\n",
       " 'Looks like nokia is better, because: days, richer, easier to beat, easier to open and app or enddial a call.. But i should tell you that samsung is: quicker, greater, faster, smart.',\n",
       " \"It's simple! php is better, because: easier to learn, easier to pick up for a noob, easier, java.. But i should tell you that javascript is: animation, easier to understand, faster, features.\",\n",
       " 'Looks like ruby is better, because: easier, easier to read, easier to learn, simpler.. But it will be useful for you to know that perl is: faster, cleaner, faster to write in ruby, safer.',\n",
       " \"It's simple! aluminium is better, because: faster, lighter, easier to mod, greater.. But i should tell you that steel is: particles, drinks, ability, cks.\",\n",
       " \"It's simple! juice is better, because: greater, faster, vitamen, water.. But you should know that beer is: lighter, better for you, easier, worse for your teeth.\",\n",
       " 'i came to the conclusion that tea is better, because: easier, greater, better for the mind and body to chat while sipping cups of assam and sencha, better to have extra beer left over., but beer is: safer, colors, coffee, beverages.',\n",
       " 'Looks like iphone is better, because: lighter, bigger, device, greater.. But i should tell you that laptop is: easier to see, experience, easier for an attacker to get to simply because an attacker can get a phone easier, louder.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_template_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will be loaded\n",
      "loading\n",
      "extract_objects_predicates gpu 2\n"
     ]
    }
   ],
   "source": [
    "my_extractor = extractor()\n",
    "my_diviner = Templ\n",
    "\n",
    "def generate_answer(my_extractor, my_diviner, input_string):\n",
    "    my_extractor.from_string(input_string)\n",
    "    print (\"9\")\n",
    "    my_responser = responser()\n",
    "    print (\"9\")\n",
    "    try:\n",
    "        obj1, obj2, predicates = my_extractor.get_params()\n",
    "    except:\n",
    "        return (\"smth wrong in extractor, please try again\")\n",
    "    print (\"9\")\n",
    "    print (\"len(obj1), len(obj2)\", len(obj1), len(obj2))\n",
    "    print (\"obj1, obj2, predicates\", obj1, obj2, predicates)\n",
    "    if (len(obj1) > 0 and len(obj2) > 0):\n",
    "        response =  my_responser.get_response(first_object = obj1, second_object = obj2, fast_search=True, aspects = predicates, weights = [1 for predicate in predicates])\n",
    "        try:\n",
    "            response_json = response.json()\n",
    "        except:\n",
    "            return (\"smth wrong in response, please try again\")\n",
    "        try:\n",
    "            my_diviner.create_from_json(response_json, predicates)\n",
    "            print (2)\n",
    "        except:\n",
    "            return (\"smth wrong in diviner, please try again\")\n",
    "        try:\n",
    "            answer = my_diviner.generate_advice()\n",
    "            print (\"answer0\", answer)\n",
    "        except:\n",
    "            return (\"smth wrong in answer generation, please try again\")\n",
    "    elif (len(obj1) > 0 and len(obj2) == 0):\n",
    "        print (\"len(obj1) > 0 and len(obj2) == 0\")\n",
    "        response =  my_responser.get_response(first_object = obj1, second_object = 'and', fast_search=True, aspects = predicates, weights = [1 for predicate in predicates])\n",
    "        try:\n",
    "            response_json = response.json()\n",
    "            my_diviner = Cam\n",
    "            my_diviner.create_from_json(response_json, predicates)\n",
    "            answer = my_diviner.generate_advice(is_object_single = True)\n",
    "            print (\"answer1\", answer)  \n",
    "        except:\n",
    "            answer = \"smth wrong in response, please try again\"\n",
    "    else:\n",
    "        answer = \"We can't recognize objects for comparision\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_template_answers = []\n",
    "list_of_given_qwestions = [\"What is better Toyota or Honda ?\", \"What is better Nokia or Motorola ?\", \"What is better Nokia or Samsung ?\", \"What is better JavaScript or PHP\", \"What is better Perl or Ruby\", \"What is better aluminium or steel\", \"What is better beer or juice ?\", \"What is better beer or tea ? \",  \"What is better laptop or iphone?\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 target1\n",
      "{'rouge1': Score(precision=0.2222222222222222, recall=0.04, fmeasure=0.06779661016949154), 'rouge2': Score(precision=0.058823529411764705, recall=0.010101010101010102, fmeasure=0.01724137931034483)}\n",
      "0 target2\n",
      "{'rouge1': Score(precision=0.23376623376623376, recall=0.54, fmeasure=0.32628398791540786), 'rouge2': Score(precision=0.034782608695652174, recall=0.08080808080808081, fmeasure=0.0486322188449848)}\n",
      "\n",
      "\n",
      "\n",
      "1 target1\n",
      "{'rouge1': Score(precision=0.4406779661016949, recall=0.26262626262626265, fmeasure=0.3291139240506329), 'rouge2': Score(precision=0.02564102564102564, recall=0.015228426395939087, fmeasure=0.019108280254777073)}\n",
      "1 target2\n",
      "{'rouge1': Score(precision=1.0, recall=0.803030303030303, fmeasure=0.8907563025210083), 'rouge2': Score(precision=1.0, recall=0.8020304568527918, fmeasure=0.8901408450704225)}\n",
      "\n",
      "\n",
      "\n",
      "2 target1\n",
      "{'rouge1': Score(precision=0.3617021276595745, recall=0.14655172413793102, fmeasure=0.2085889570552147), 'rouge2': Score(precision=0.043478260869565216, recall=0.017391304347826087, fmeasure=0.02484472049689441)}\n",
      "2 target2\n",
      "{'rouge1': Score(precision=0.4482758620689655, recall=0.33620689655172414, fmeasure=0.3842364532019705), 'rouge2': Score(precision=0.08139534883720931, recall=0.06086956521739131, fmeasure=0.06965174129353234)}\n",
      "\n",
      "\n",
      "\n",
      "3 target1\n",
      "{'rouge1': Score(precision=0.3466666666666667, recall=0.15757575757575756, fmeasure=0.21666666666666665), 'rouge2': Score(precision=0.08108108108108109, recall=0.036585365853658534, fmeasure=0.050420168067226885)}\n",
      "3 target2\n",
      "{'rouge1': Score(precision=0.30718954248366015, recall=0.28484848484848485, fmeasure=0.2955974842767295), 'rouge2': Score(precision=0.039473684210526314, recall=0.036585365853658534, fmeasure=0.0379746835443038)}\n",
      "\n",
      "\n",
      "\n",
      "4 target1\n",
      "{'rouge1': Score(precision=0.22448979591836735, recall=0.08396946564885496, fmeasure=0.12222222222222222), 'rouge2': Score(precision=0.020833333333333332, recall=0.007692307692307693, fmeasure=0.011235955056179775)}\n",
      "4 target2\n",
      "{'rouge1': Score(precision=0.23236514522821577, recall=0.42748091603053434, fmeasure=0.3010752688172043), 'rouge2': Score(precision=0.025, recall=0.046153846153846156, fmeasure=0.032432432432432434)}\n",
      "\n",
      "\n",
      "\n",
      "5 target1\n",
      "{'rouge1': Score(precision=0.17034700315457413, recall=0.453781512605042, fmeasure=0.24770642201834864), 'rouge2': Score(precision=0.0189873417721519, recall=0.05084745762711865, fmeasure=0.027649769585253454)}\n",
      "5 target2\n",
      "{'rouge1': Score(precision=0.2523364485981308, recall=0.226890756302521, fmeasure=0.23893805309734512), 'rouge2': Score(precision=0.018867924528301886, recall=0.01694915254237288, fmeasure=0.017857142857142856)}\n",
      "\n",
      "\n",
      "\n",
      "6 target1\n",
      "{'rouge1': Score(precision=0.1095890410958904, recall=0.2711864406779661, fmeasure=0.15609756097560976), 'rouge2': Score(precision=0.006896551724137931, recall=0.017241379310344827, fmeasure=0.009852216748768473)}\n",
      "6 target2\n",
      "{'rouge1': Score(precision=0.125, recall=0.3220338983050847, fmeasure=0.18009478672985782), 'rouge2': Score(precision=0.006622516556291391, recall=0.017241379310344827, fmeasure=0.009569377990430623)}\n",
      "\n",
      "\n",
      "\n",
      "7 target1\n",
      "{'rouge1': Score(precision=0.3404255319148936, recall=0.14953271028037382, fmeasure=0.2077922077922078), 'rouge2': Score(precision=0.06521739130434782, recall=0.02830188679245283, fmeasure=0.039473684210526314)}\n",
      "7 target2\n",
      "{'rouge1': Score(precision=0.19672131147540983, recall=0.22429906542056074, fmeasure=0.2096069868995633), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "\n",
      "\n",
      "8 target1\n",
      "{'rouge1': Score(precision=0.1686046511627907, recall=0.25, fmeasure=0.2013888888888889), 'rouge2': Score(precision=0.011695906432748537, recall=0.017391304347826087, fmeasure=0.013986013986013986)}\n",
      "8 target2\n",
      "{'rouge1': Score(precision=0.17647058823529413, recall=0.15517241379310345, fmeasure=0.1651376146788991), 'rouge2': Score(precision=0.009900990099009901, recall=0.008695652173913044, fmeasure=0.009259259259259259)}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "for ind, elem in enumerate(answer_big):\n",
    "    print (ind, \"target1\")\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(elem, list_of_target1[ind])\n",
    "    print (scores)\n",
    "    print (ind, \"target2\")\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(elem, list_of_target2[ind])\n",
    "    print (scores)\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "  \n",
    "# reading csv file  \n",
    "ds = pd.read_csv(\"Evaluation dataset - Sheet1 (1).csv\") \n",
    "list_of_target1 = ds['Q1']\n",
    "list_of_target2 = ds['Q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It's simple! honda is better, because: quicker, bigger, nicer, weaker.. But you should know that toyota is: lighter, easier, faster, softer.\",\n",
       " 'I would prefer motorolla than nokia.',\n",
       " 'I would prefer sumsung than nokia.',\n",
       " 'Looks like php is better, because: easier to learn, easier to pick up for a noob, easier, java.. But it will be useful for you to know that javascript is: animation, easier to understand, faster, features.',\n",
       " 'I would prefer to use ruby because it is: easier, easier to read, easier to learn, simpler.. But i should tell you that perl is: faster, cleaner, faster to write in ruby, safer.',\n",
       " 'after much thought, I realized that  aluminium is better, because: faster, lighter, easier to mod, greater., but steel is: particles, drinks, ability, cks.',\n",
       " 'I would prefer to use juice because it is: greater, faster, vitamen, water.. But you should know that beer is: lighter, better for you, easier, worse for your teeth.',\n",
       " 'i came to the conclusion that tea is better, because: easier, greater, better for the mind and body to chat while sipping cups of assam and sencha, better to have extra beer left over.. But it will be useful for you to know that beer is: safer, colors, coffee, beverages.',\n",
       " \"It's simple! iphone is better, because: lighter, bigger, device, greater.. But it will be useful for you to know that laptop is: easier to see, experience, easier for an attacker to get to simply because an attacker can get a phone easier, louder.\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_template_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f591f02109f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmy_diviner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTempl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_given_qwestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"qwestion \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_extractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_diviner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "my_diviner = Templ\n",
    "\n",
    "for elem in list_of_given_qwestions[45]:\n",
    "    print (\"qwestion \", elem)\n",
    "    answer = generate_answer(my_extractor, my_diviner, elem)\n",
    "    print (\"answer \", answer)\n",
    "    list_of_template_answers.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why tea is better than beer is because it is very good for your body. You need to drink more tea than beer. When you drink tea, you need less alcohol. This is why tea is better than beer. How long it takes to make a cup of tea?\n",
    "It is a long process. You need to wash your tea leaves and boil them, and then you need to boil them again. To make more tea, you need to boil the tea again. You need to boil the tea for at least one hour. Beer is life.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like tea, but seriously, there is no debate here at all. Beer is life. Why? Because beer goes with pizza. Isn’t that enough? Beer makes you social. Would you ever hang out with a person who drinks nothing than tea? If beer was bad, monks would’t sell it. I had the best time in my life while drinking beer. I tasted like 300 different beers, while only 10–20 different type of teas. Beer makes me happy, tea makes me nervous. We say, “Let me buy you a beer.” But how that sounds, “Let me buy you a tea”…'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_target2[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_big = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_big.append(sttr9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr1 = \"honda is better than toyota because it is quicker, bigger, nicer. The problem is that Honda is not the only one. Toyota has always been the king of the car world. There are a lot of other companies that have created the cars that people love. They do it for the money. But Toyota is the one that has to compete with Honda and Chevrolet. It has to produce cars that people want to buy.I am still not convinced that Toyota will ever get to that level. But it is not impossible. It is just a matter of time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr2 = \"Motorola is better than Nokia. And I'm not sure I've ever heard of a company that's better than Samsung. This is not a bad thing. I am not sure Samsung does a better job than Nokia.Well, it depends what you expect from a phone. If you want good build quality and regular software updates do not ever think of buy a phone of Chinese or Chinese-owned brand (except the phones running on Android One). If you have a tight budget, then you can proceed with Moto. Since Nokia’s phone are a bit overpriced, you may get one at reasonable price during sales. Also, the Nokia-exclusive Zeiss optics don’t have any competitor in their price range. If you want a Moto X4, then Nokia 7 Plus is always ahead. But if you want G5S Plus, then go on with it because Nokia 2.1 or 3.1 are the only available phones from Nokia and have a bit low specs. However you can go on for Nokia 6.1 or 6.1 Plus over Moto G6 because of their build quality and stock software anlog with regular updates and security patches.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr3 = \"Samsung is better than Nokia. Nokia has no market share in the mobile phone industry, and it is not profitable. The company's strategy is to sell its devices to customers in China, and it is trying to win a share of the Chinese market. Samsung is also better than Nokia. Samsung has a high growth rate and is trying to establish itself as a leading player in the mobile phone industry. But Samsung has a long way to go to regain its market position. Samsung is now the second largest phone manufacturer in the world after Apple. The Nokia deal was announced in April, but it was not fully resolved until the end of July.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr4 = \"Php is better than javascript because it is easier to learn, easier to pick up. You should not use the PHP version of your application.You should not use the PHP version of your application. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. The PHP version of your application is not required to work, but it may prove to be beneficial. PHP is not required to work, but it may prove to be beneficial. You will not lose your development experience by using PHP. You will not lose your development experience by using PHP. PHP has a very advanced feature set. PHP has a very advanced feature set. PHP provides a very rich set of functions and modules. PHP provides a very rich set of functions and modules. PHP provides a high degree of flexibility and conciseness.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr5 = \"Ruby is better than Python because ruby because it is: easier, easier to read, easier to learn, simpler. But you can also use any other language that works for you. For example, you can use Ruby instead of Python if you really, really want to. For me, Ruby and Python are the two languages that I use the most. If I had to pick a favorite language, Ruby would be the first one I'd pick. So that was the short version. In the next post, I'll go through some of the most important features of Ruby and Python that you might not know about. If you're curious about the future of Ruby, Python, or both, you can subscribe to the mailing list to get updates about upcoming posts.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr6 = \"Aluminium is better than steel, because it is faster, lighter, easier to mod, greater. It also is more resistant to corrosion. The advantages of aluminium are many. However, it is also more expensive than steel. The steel is usually less expensive than aluminium because of the cost of the alloying process (which is why the price of steel is lower than aluminium). It is also usually harder (but not so much harder that it cannot be used) and more expensive. The main benefits of aluminium are. It is a good conductor of electricity. It is the strongest material known to man, and is also the only one that can resist all the shocks of a trip to the bathroom.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr7 = \"Juice is better than beer because it is: greater, faster, vitamen. I don't think there is a reason to drink beer, but I do believe there is a reason to drink juice.I also don't believe there is a reason to drink beer. I think drinking beer is good for your teeth and keeping my mouth healthy.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr8 = \"Tea is better than beer, because: easier, greater. The reason why tea is better than beer is because it is very good for your body. You need to drink more tea than beer. When you drink tea, you need less alcohol. This is why tea is better than beer. How long it takes to make a cup of tea?It is a long process. You need to wash your tea leaves and boil them, and then you need to boil them again. To make more tea, you need to boil the tea again. You need to boil the tea for at least one hour. Beer is life.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttr9 = \"Iphone is better than laptop because it is lighter, bigger, device, greater. If you have a smartphone, it is better than a laptop because it is lighter, bigger, device, greater. But it is not as good as laptop for some things like software development, software testing, or design.  It has a more stable battery, better image quality, better camera, and a better battery life. The iPhone 5s on the other hand is not a great laptop, it's not the best for a long time to come, but it is better than the iPhone 4 and 4s. And with the iPhone 6 and the iPhone 6 Plus, the iPhone 6s is better than the iPhone 6.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_big.append(sttr9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['honda is better than toyota because it is quicker, bigger, nicer. The problem is that Honda is not the only one. Toyota has always been the king of the car world. There are a lot of other companies that have created the cars that people love. They do it for the money. But Toyota is the one that has to compete with Honda and Chevrolet. It has to produce cars that people want to buy.I am still not convinced that Toyota will ever get to that level. But it is not impossible. It is just a matter of time.',\n",
       " \"Motorola is better than Nokia. And I'm not sure I've ever heard of a company that's better than Samsung. This is not a bad thing. I am not sure Samsung does a better job than Nokia.Well, it depends what you expect from a phone. If you want good build quality and regular software updates do not ever think of buy a phone of Chinese or Chinese-owned brand (except the phones running on Android One). If you have a tight budget, then you can proceed with Moto. Since Nokia’s phone are a bit overpriced, you may get one at reasonable price during sales. Also, the Nokia-exclusive Zeiss optics don’t have any competitor in their price range. If you want a Moto X4, then Nokia 7 Plus is always ahead. But if you want G5S Plus, then go on with it because Nokia 2.1 or 3.1 are the only available phones from Nokia and have a bit low specs. However you can go on for Nokia 6.1 or 6.1 Plus over Moto G6 because of their build quality and stock software anlog with regular updates and security patches.\",\n",
       " \"Samsung is better than Nokia. Nokia has no market share in the mobile phone industry, and it is not profitable. The company's strategy is to sell its devices to customers in China, and it is trying to win a share of the Chinese market. Samsung is also better than Nokia. Samsung has a high growth rate and is trying to establish itself as a leading player in the mobile phone industry. But Samsung has a long way to go to regain its market position. Samsung is now the second largest phone manufacturer in the world after Apple. The Nokia deal was announced in April, but it was not fully resolved until the end of July.\",\n",
       " 'Php is better than javascript because it is easier to learn, easier to pick up. You should not use the PHP version of your application.You should not use the PHP version of your application. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. The PHP version of your application is not required to work, but it may prove to be beneficial. PHP is not required to work, but it may prove to be beneficial. You will not lose your development experience by using PHP. You will not lose your development experience by using PHP. PHP has a very advanced feature set. PHP has a very advanced feature set. PHP provides a very rich set of functions and modules. PHP provides a very rich set of functions and modules. PHP provides a high degree of flexibility and conciseness.',\n",
       " \"Ruby is better than Python because ruby because it is: easier, easier to read, easier to learn, simpler. But you can also use any other language that works for you. For example, you can use Ruby instead of Python if you really, really want to. For me, Ruby and Python are the two languages that I use the most. If I had to pick a favorite language, Ruby would be the first one I'd pick. So that was the short version. In the next post, I'll go through some of the most important features of Ruby and Python that you might not know about. If you're curious about the future of Ruby, Python, or both, you can subscribe to the mailing list to get updates about upcoming posts.\",\n",
       " 'Aluminium is better than steel, because it is faster, lighter, easier to mod, greater. It also is more resistant to corrosion. The advantages of aluminium are many. However, it is also more expensive than steel. The steel is usually less expensive than aluminium because of the cost of the alloying process (which is why the price of steel is lower than aluminium). It is also usually harder (but not so much harder that it cannot be used) and more expensive. The main benefits of aluminium are. It is a good conductor of electricity. It is the strongest material known to man, and is also the only one that can resist all the shocks of a trip to the bathroom.',\n",
       " \"Juice is better than beer because it is: greater, faster, vitamen. I don't think there is a reason to drink beer, but I do believe there is a reason to drink juice.I also don't believe there is a reason to drink beer. I think drinking beer is good for your teeth and keeping my mouth healthy.\",\n",
       " 'Tea is better than beer, because: easier, greater. The reason why tea is better than beer is because it is very good for your body. You need to drink more tea than beer. When you drink tea, you need less alcohol. This is why tea is better than beer. How long it takes to make a cup of tea?It is a long process. You need to wash your tea leaves and boil them, and then you need to boil them again. To make more tea, you need to boil the tea again. You need to boil the tea for at least one hour. Beer is life.',\n",
       " \"Iphone is better than laptop because it is lighter, bigger, device, greater. If you have a smartphone, it is better than a laptop because it is lighter, bigger, device, greater. But it is not as good as laptop for some things like software development, software testing, or design.  It has a more stable battery, better image quality, better camera, and a better battery life. The iPhone 5s on the other hand is not a great laptop, it's not the best for a long time to come, but it is better than the iPhone 4 and 4s. And with the iPhone 6 and the iPhone 6 Plus, the iPhone 6s is better than the iPhone 6.\"]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_generator_for_out\n",
      "exist3\n",
      "exist4\n",
      "exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:08<00:00, 23.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "in big gen2  It has a more stable battery, better image quality, better camera, and a better battery life.\n",
      "\n",
      "The iPhone 5s on the other hand is not a great laptop, it's not the best for a long time to come, but it is better than the iPhone 4 and 4s. And with the iPhone 6 and the iPhone 6 Plus, the iPhone 6s is better than the iPhone 6.\n",
      "\n",
      "All these devices are better than the iPhone 4s, but not by much. The iPhone 4s is a pretty mediocre laptop. If you want to buy a laptop, you should look at the Macbook Air. It is faster, cheaper, and better than the Apple MacBook Pros.\n",
      "\n",
      "What is the most important thing you should know about the iPhone 4s?\n",
      "\n",
      "The iPhone 4s is a pretty poor laptop. It's not as fast, or as powerful as the iPhone 5s, or as good as the Apple MacBook Pro.\n",
      "\n",
      "But the iPhone 4\n",
      "qu2\n",
      "qu3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" It has a more stable battery, better image quality, better camera, and a better battery life.\\n\\nThe iPhone 5s on the other hand is not a great laptop, it's not the best for a long time to come, but it is better than the iPhone 4 and 4s. And with the iPhone 6 and the iPhone 6 Plus, the iPhone 6s is better than the iPhone 6.\\n\\nAll these devices are better than the iPhone 4s, but not by much. The iPhone 4s is a pretty mediocre laptop. If you want to buy a laptop, you should look at the Macbook Air. It is faster, cheaper, and better than the Apple MacBook Pros.\\n\\nWhat is the most important thing you should know about the iPhone 4s?\\n\\nThe iPhone 4s is a pretty poor laptop. It's not as fast, or as powerful as the iPhone 5s, or as good as the Apple MacBook Pro.\\n\\nBut the iPhone 4\""
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "text_generator_for_out(\"Iphone is better than laptop because it is lighter, bigger, device, greater.\", LM_BIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT2.model import (GPT2LMHeadModel)\n",
    "from GPT2.utils import load_weight\n",
    "from GPT2.config import GPT2Config\n",
    "from GPT2.sample import sample_sequence\n",
    "from GPT2.encoder import get_encoder\n",
    "\n",
    "\n",
    "def text_generator_for_out(text, model, length = 200, temperature = 0.7, top_k = 40):\n",
    "    print(\"text_generator_for_out\")\n",
    "    \n",
    "    device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print (\"exist3\")\n",
    "    # Load Model\n",
    "    enc = get_encoder()\n",
    "    print (\"exist4\")\n",
    "\n",
    "    quiet = False\n",
    "    print (\"exist\")\n",
    "    length = 200\n",
    "\n",
    "    if length == -1:\n",
    "        length = 1024 // 2\n",
    "    elif length > 1024:\n",
    "        raise ValueError(\"Can't get samples longer than window size: %s\" % 1024)\n",
    "\n",
    "    context_tokens = enc.encode(text)\n",
    "\n",
    "    generated = 0\n",
    "    for _ in range(1):\n",
    "        out = sample_sequence(\n",
    "            model=model, length=length,\n",
    "            context=context_tokens,\n",
    "            start_token=None,\n",
    "            batch_size=1,\n",
    "            temperature=temperature, top_k=top_k, device=device\n",
    "        )\n",
    "        out = out[:, len(context_tokens):].tolist()\n",
    "        for i in range(1):\n",
    "            generated += 1\n",
    "            text = enc.decode(out[i])\n",
    "            if quiet is False:\n",
    "                print (\"qu\")\n",
    "                print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
    "            print(\"in big gen2\", text)\n",
    "            print (\"qu2\")\n",
    "            print (\"qu3\")\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i came to the conclusion that python is better, because: quicker to develop code, quicker, matplotlib, easier.. But i should tell you that matlab is: faster, better for scientific computing, experience.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "#proxies = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "params = {\n",
    "            'objectA': 'Moscow',\n",
    "            'objectB': 'London',\n",
    "            'fs': str(True).lower()}\n",
    "response = requests.get(url=URL, params=params)#, proxies=proxies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rouge ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rouge2': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n",
      "{'rouge1': Score(precision=0.2222222222222222, recall=0.2222222222222222, fmeasure=0.2222222222222222), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score('The quick brown dog jumps over the lazy fox',\n",
    "                      'The quick brown dog jumps over the lazy fox.')\n",
    "print (scores)\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score('The quick brown dog jumps over the lazy fox',\n",
    "                      'The fast hazel hound skips above the inactive tod.')\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bert embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: nvcc: not found\n"
     ]
    }
   ],
   "source": [
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_embedding import BertEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert embedding лучше учитывает контекст (так, что в словах \"Я лублю яблоки\" \"Мне нравятся яблочные макбуки\" Я - разное\n",
    "В случае с service bert I -одинаковое apple одинаковок\n",
    "\n",
    "I like apple\n",
    "I like apple macbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_embedding import BertEmbedding\n",
    "\n",
    "bert_abstract = \"\"\"The quick brown dog jumps over the lazy fox.\\n The fast hazel hound skips above inactive tod.\"\"\"\n",
    "sentences = bert_abstract.split('\\n')\n",
    "bert_embedding = BertEmbedding()\n",
    "result = bert_embedding(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrgam ('jumps',)\n",
    "list_of_ngrams Counter({('the',): 2, ('just',): 1, ('place',): 1, ('for',): 1, ('a',): 1, ('snark',): 1, ('bellman',): 1, ('cried',): 1})\n",
    "[0.6792433]\n",
    "[0.8161626]\n",
    "[0.6827992]\n",
    "[0]\n",
    "[0.8117111]\n",
    "[0]\n",
    "[0]\n",
    "[0.62362134]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bert_embedding(['jumps', 'just', 'a'])\n",
    "vectors = result[0][1]\n",
    "vectors1 = result[1][1]\n",
    "vectors2 = result[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jumps']"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quick\n",
      "quick brown\n",
      "brown dog\n",
      "dog jumps\n",
      "jumps over\n",
      "over the\n",
      "the lazy\n",
      "lazy fox\n"
     ]
    }
   ],
   "source": [
    "for elem in list(ngrams1.keys()):\n",
    "    print (' '.join(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The quick brown dog jumps over the lazy fox', 'The fast hazel hound skips above the inactive tod.']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "bert_embedding = BertEmbedding()\n",
    "import collections\n",
    "\n",
    "str_1 = 'The quick brown dog jumps over the lazy fox'\n",
    "str_2 = 'The fast hazel hound skips above the inactive tod.'\n",
    "str_3 = 'Just the place for Snark the Bellman cried'\n",
    "print ([str_1, str_2])\n",
    "result = bert_embedding([str_1, str_2, str_3])\n",
    "ngrams1_embeddings = result[0][1]\n",
    "ngrams2_embeddings = result[1][1]\n",
    "ngrams3_embeddings = result[2][1]\n",
    "\n",
    "ngrams1 = create_ngrams(result[0][0], 2)\n",
    "ngrams2= create_ngrams(result[1][0], 2)\n",
    "ngrams3= create_ngrams(result[2][0], 2)\n",
    "\n",
    "ngrams01 = create_ngrams(result[0][0], 1)\n",
    "ngrams02= create_ngrams(result[1][0], 1)\n",
    "ngrams03= create_ngrams(result[2][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('the', 'quick'): 1,\n",
       "         ('quick', 'brown'): 1,\n",
       "         ('brown', 'dog'): 1,\n",
       "         ('dog', 'jumps'): 1,\n",
       "         ('jumps', 'over'): 1,\n",
       "         ('over', 'the'): 1,\n",
       "         ('the', 'lazy'): 1,\n",
       "         ('lazy', 'fox'): 1})"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_target = bert_embedding([' '.join(elem)for elem in list(ngrams1.keys())])\n",
    "embeddings_predictions = bert_embedding([' '.join(elem)for elem in list(ngrams2.keys())])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_target[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def fmeasure(precision, recall):\n",
    "  \"\"\"Computes f-measure given precision and recall values.\"\"\"\n",
    "\n",
    "  if precision + recall > 0:\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "  else:\n",
    "    return 0.0\n",
    "\n",
    "def cos_sim(emb1, emb2):\n",
    "    return cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))\n",
    "\n",
    "def count_ngram_overlap(ngram1_embs, ngram2_embs): #The idea count cousine similarity to every pair. If > 0.6 than add\n",
    "    result = 1\n",
    "    #print (\"ngram1_embs\", len(ngram1_embs), len(ngram1_embs[0]))\n",
    "    for elem in ngram1_embs: # по словам в н-граме\n",
    "        similarities = [cos_sim(elem, elem2)[0][0] if cos_sim(elem, elem2) >= 0.6 else 0 for elem2 in ngram2_embs]\n",
    "        #print (similarities)\n",
    "        max_ = max(similarities)\n",
    "        result *= max_\n",
    "    return result\n",
    "        \n",
    "\n",
    "def count_overlap(ngram, ngram_emb, list_of_ngrams2, list_of_ngrams2_embs): # only if ngram not in list_of_ngrams !!!\n",
    "    overlaps = [count_ngram_overlap(ngram_emb, elem[1]) for elem in list_of_ngrams2_embs] # по всем н-грамам\n",
    "    return max(overlaps)\n",
    "\n",
    "def score_ngrams(target_ngrams, prediction_ngrams):\n",
    "    intersection_ngrams_count = 0\n",
    "    \n",
    "    #print (\"target_ngrams\", target_ngrams)\n",
    "    #print (\"prediction_ngrams\", prediction_ngrams)\n",
    "    \n",
    "    embeddings_target = bert_embedding([' '.join(elem)for elem in list(target_ngrams.keys())])\n",
    "    embeddings_predictions = bert_embedding([' '.join(elem)for elem in list(prediction_ngrams.keys())])\n",
    "    \n",
    "    for ind, ngram in enumerate(list(target_ngrams.keys())):\n",
    "        #print (\"ind\", ind)\n",
    "        intersection_ngrams_count += min(target_ngrams[ngram],\n",
    "                                         prediction_ngrams[ngram])\n",
    "        if (min(target_ngrams[ngram], prediction_ngrams[ngram]) == 0):\n",
    "            #print (\"ngram\", ngram)\n",
    "            #print ('overlap')\n",
    "            overlap_ngram = count_overlap(ngram, embeddings_target[ind][1], prediction_ngrams, embeddings_predictions) #по всем н-грамам\n",
    "            #print ('overlap ngram', overlap_ngram)\n",
    "            intersection_ngrams_count += overlap_ngram\n",
    "            \n",
    "    target_ngrams_count = sum(target_ngrams.values())\n",
    "    prediction_ngrams_count = sum(prediction_ngrams.values())\n",
    "    \n",
    "    #print (\"intersection_ngrams_count\", intersection_ngrams_count)\n",
    "    #print (\"intersection_targets_count\", prediction_ngrams_count, target_ngrams_count)\n",
    "\n",
    "\n",
    "    precision = intersection_ngrams_count / max(prediction_ngrams_count, 1)\n",
    "    recall = intersection_ngrams_count / max(target_ngrams_count, 1)\n",
    "    print (precision, recall)\n",
    "    \n",
    "    f = fmeasure(precision, recall)\n",
    "    return f, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import porter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import collections\n",
    "\n",
    "\n",
    "stemmer = porter.PorterStemmer()\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def create_ngrams(tokens, n): #сюда добавть эмбединги\n",
    "    ngrams = collections.Counter()\n",
    "    ngrams_embs = collections.Counter()\n",
    "    for ngram in (tuple(tokens[i:i + n]) for i in range(len(tokens) - n + 1)):\n",
    "        ngrams[ngram] += 1\n",
    "    return ngrams\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Looks like ruby is better, because: easier, easier to read, easier to learn, simpler.. But it will be useful for you to know that perl is: faster, cleaner, faster to write in ruby, safer.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_template_answers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Perl is an ideal choice for system administration work as well as the web development task whereas Ruby is highly suitable for the traffic-heavy application. ... Perl 5 is less Object-Oriented although Perl 6 has a very good Object-Oriented support whereas Ruby is highly Object-Oriented language.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_target1[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I know a lot more Ruby than Perl, but the primary contrast is :Perl code is much terser than Ruby\\nIf you want terse code that does its job in the least number of lines, Perl is better. If you want expressive, almost poetic and much more generally readable code, and don't mind the cost of a few extra characters, Ruby is much better. This manifests itself in several ways in practice:\\n- Perl One liners (one line perl commands that perform batch manipulation:  of a bunch of files, for instance) are a cult in themselves - see Perl One Liners to get a feel.\\n- Perl is better suited if the primary task is regex - Ruby regex syntax itself is pretty good, arguably close to Perl, but the typical use cases of doing text pattern matching with regexes are better expressed in Perl, in my view. Many developers do regexes with grep, and a natural progression for more complex manipulation not supported by grep is either through sed or awk for a class of tasks, or for more general power, to use Perl.\\n- Perl is used on the command line or with very short batch scripts much more effectively than Ruby, which usually involves longer scripts. So, bottom line, if you do mostly text manipulation and matching, and want quick solutions on the command line or with short scripts, Perl is definitely worth learning in addition to Ruby. If not, perhaps not :-)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_target2[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['after much thought, I realized that  honda is better, because: quicker, bigger, nicer, weaker.. But i should tell you that toyota is: lighter, easier, faster, softer.',\n",
       " 'i came to the conclusion that motorola is better, because: better for me, bigger, easier for me to hold it, quicker., but nokia is: easier, faster, cheaper, t720.',\n",
       " 'Looks like nokia is better, because: days, richer, easier to beat, easier to open and app or enddial a call.. But i should tell you that samsung is: quicker, greater, faster, smart.',\n",
       " \"It's simple! php is better, because: easier to learn, easier to pick up for a noob, easier, java.. But i should tell you that javascript is: animation, easier to understand, faster, features.\",\n",
       " 'Looks like ruby is better, because: easier, easier to read, easier to learn, simpler.. But it will be useful for you to know that perl is: faster, cleaner, faster to write in ruby, safer.',\n",
       " \"It's simple! aluminium is better, because: faster, lighter, easier to mod, greater.. But i should tell you that steel is: particles, drinks, ability, cks.\",\n",
       " \"It's simple! juice is better, because: greater, faster, vitamen, water.. But you should know that beer is: lighter, better for you, easier, worse for your teeth.\",\n",
       " 'i came to the conclusion that tea is better, because: easier, greater, better for the mind and body to chat while sipping cups of assam and sencha, better to have extra beer left over., but beer is: safer, colors, coffee, beverages.',\n",
       " 'Looks like iphone is better, because: lighter, bigger, device, greater.. But i should tell you that laptop is: easier to see, experience, easier for an attacker to get to simply because an attacker can get a phone easier, louder.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_template_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 n1\n",
      "honda is better than toyota because it is quicker, bigger, nicer. The problem is that Honda is not the only one. Toyota has always been the king of the car world. There are a lot of other companies that have created the cars that people love. They do it for the money. But Toyota is the one that has to compete with Honda and Chevrolet. It has to produce cars that people want to buy.I am still not convinced that Toyota will ever get to that level. But it is not impossible. It is just a matter of time.\n",
      "2.319214033453088 0.39343809496079174\n",
      "target1 (0.6727491089405904, 2.319214033453088, 0.39343809496079174)\n",
      "0.35589685977212054 0.8039455850209508\n",
      "target2 (0.49338030423203555, 0.35589685977212054, 0.8039455850209508)\n",
      "0 n2\n",
      "0.4370502454986571 0.07087301278356602\n",
      "target1 (0.12196751037171824, 0.4370502454986571, 0.07087301278356602)\n",
      "0.1786614873475141 0.40560986316732933\n",
      "target2 (0.24805892458167247, 0.1786614873475141, 0.40560986316732933)\n",
      "\n",
      "\n",
      "\n",
      "1 n1\n",
      "Motorola is better than Nokia. And I'm not sure I've ever heard of a company that's better than Samsung. This is not a bad thing. I am not sure Samsung does a better job than Nokia.Well, it depends what you expect from a phone. If you want good build quality and regular software updates do not ever think of buy a phone of Chinese or Chinese-owned brand (except the phones running on Android One). If you have a tight budget, then you can proceed with Moto. Since Nokia’s phone are a bit overpriced, you may get one at reasonable price during sales. Also, the Nokia-exclusive Zeiss optics don’t have any competitor in their price range. If you want a Moto X4, then Nokia 7 Plus is always ahead. But if you want G5S Plus, then go on with it because Nokia 2.1 or 3.1 are the only available phones from Nokia and have a bit low specs. However you can go on for Nokia 6.1 or 6.1 Plus over Moto G6 because of their build quality and stock software anlog with regular updates and security patches.\n",
      "0.8507100805645205 0.5250794277168571\n",
      "target1 (0.649358582206054, 0.8507100805645205, 0.5250794277168571)\n",
      "1.0634089443418715 0.8700618635524403\n",
      "target2 (0.9570680499076845, 1.0634089443418715, 0.8700618635524403)\n",
      "1 n2\n",
      "0.3331037489406138 0.2049869224249931\n",
      "target1 (0.25379333252618197, 0.3331037489406138, 0.2049869224249931)\n",
      "1.0435661488591341 0.8529146408944845\n",
      "target2 (0.9386573825717079, 1.0435661488591341, 0.8529146408944845)\n",
      "\n",
      "\n",
      "\n",
      "2 n1\n",
      "Samsung is better than Nokia. Nokia has no market share in the mobile phone industry, and it is not profitable. The company's strategy is to sell its devices to customers in China, and it is trying to win a share of the Chinese market. Samsung is also better than Nokia. Samsung has a high growth rate and is trying to establish itself as a leading player in the mobile phone industry. But Samsung has a long way to go to regain its market position. Samsung is now the second largest phone manufacturer in the world after Apple. The Nokia deal was announced in April, but it was not fully resolved until the end of July.\n",
      "0.9462399688634006 0.41304125624989707\n",
      "target1 (0.5750629645026192, 0.9462399688634006, 0.41304125624989707)\n",
      "0.7982164909551431 0.5764896879120479\n",
      "target2 (0.6694718956397975, 0.7982164909551431, 0.5764896879120479)\n",
      "2 n2\n",
      "0.31677286962338014 0.13684587967730022\n",
      "target1 (0.19112553027555895, 0.31677286962338014, 0.13684587967730022)\n",
      "0.3455492838001103 0.24879548433607943\n",
      "target2 (0.28929707480939465, 0.3455492838001103, 0.24879548433607943)\n",
      "\n",
      "\n",
      "\n",
      "3 n1\n",
      "Php is better than javascript because it is easier to learn, easier to pick up. You should not use the PHP version of your application.You should not use the PHP version of your application. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. It is possible, but not recommended, that you must use PHP versions 5.3+ to use this framework. The PHP version of your application is not required to work, but it may prove to be beneficial. PHP is not required to work, but it may prove to be beneficial. You will not lose your development experience by using PHP. You will not lose your development experience by using PHP. PHP has a very advanced feature set. PHP has a very advanced feature set. PHP provides a very rich set of functions and modules. PHP provides a very rich set of functions and modules. PHP provides a high degree of flexibility and conciseness.\n",
      "0.816702878329812 0.3679650330936516\n",
      "target1 (0.5073457274473075, 0.816702878329812, 0.3679650330936516)\n",
      "0.5267935977344624 0.4949544242450169\n",
      "target2 (0.5103779332158248, 0.5267935977344624, 0.4949544242450169)\n",
      "3 n2\n",
      "0.3029508292660024 0.13557468050025523\n",
      "target1 (0.18732074175989463, 0.3029508292660024, 0.13557468050025523)\n",
      "0.20929099061308098 0.19657164864212026\n",
      "target2 (0.20273201369928073, 0.20929099061308098, 0.19657164864212026)\n",
      "\n",
      "\n",
      "\n",
      "4 n1\n",
      "Ruby is better than Python because ruby because it is: easier, easier to read, easier to learn, simpler. But you can also use any other language that works for you. For example, you can use Ruby instead of Python if you really, really want to. For me, Ruby and Python are the two languages that I use the most. If I had to pick a favorite language, Ruby would be the first one I'd pick. So that was the short version. In the next post, I'll go through some of the most important features of Ruby and Python that you might not know about. If you're curious about the future of Ruby, Python, or both, you can subscribe to the mailing list to get updates about upcoming posts.\n",
      "1.2669327576109704 0.4023367541061865\n",
      "target1 (0.6107265600791344, 1.2669327576109704, 0.4023367541061865)\n",
      "0.3811092026855635 0.7107171617649697\n",
      "target2 (0.4961610374585638, 0.3811092026855635, 0.7107171617649697)\n",
      "4 n2\n",
      "0.40951441994941956 0.12814736950798164\n",
      "target1 (0.19520894629713267, 0.40951441994941956, 0.12814736950798164)\n",
      "0.1958466043815882 0.36637970207439974\n",
      "target2 (0.2552503137674728, 0.1958466043815882, 0.36637970207439974)\n",
      "\n",
      "\n",
      "\n",
      "5 n1\n",
      "Aluminium is better than steel, because it is faster, lighter, easier to mod, greater. It also is more resistant to corrosion. The advantages of aluminium are many. However, it is also more expensive than steel. The steel is usually less expensive than aluminium because of the cost of the alloying process (which is why the price of steel is lower than aluminium). It is also usually harder (but not so much harder that it cannot be used) and more expensive. The main benefits of aluminium are. It is a good conductor of electricity. It is the strongest material known to man, and is also the only one that can resist all the shocks of a trip to the bathroom.\n",
      "0.29138578436094575 0.7369104256664497\n",
      "target1 (0.4176330133140454, 0.29138578436094575, 0.7369104256664497)\n",
      "0.622109942138195 0.5049008226049119\n",
      "target2 (0.5574105081558227, 0.622109942138195, 0.5049008226049119)\n",
      "5 n2\n",
      "0.15367021055316518 0.39034476841241955\n",
      "target1 (0.2205246732886659, 0.15367021055316518, 0.39034476841241955)\n",
      "0.27659085900966673 0.22409916313921902\n",
      "target2 (0.24759343024252428, 0.27659085900966673, 0.22409916313921902)\n",
      "\n",
      "\n",
      "\n",
      "6 n1\n",
      "Juice is better than beer because it is: greater, faster, vitamen. I don't think there is a reason to drink beer, but I do believe there is a reason to drink juice.I also don't believe there is a reason to drink beer. I think drinking beer is good for your teeth and keeping my mouth healthy.\n",
      "0.24833407424963438 0.5960017781991225\n",
      "target1 (0.35058928129360145, 0.24833407424963438, 0.5960017781991225)\n",
      "0.2450605491678158 0.6296171032465421\n",
      "target2 (0.3528026871640107, 0.2450605491678158, 0.6296171032465421)\n",
      "6 n2\n",
      "0.06140282517651985 0.148709967224384\n",
      "target1 (0.0869172411174482, 0.06140282517651985, 0.148709967224384)\n",
      "0.06295996288843363 0.1633024037418747\n",
      "target2 (0.09088133773460853, 0.06295996288843363, 0.1633024037418747)\n",
      "\n",
      "\n",
      "\n",
      "7 n1\n",
      "Tea is better than beer, because: easier, greater. The reason why tea is better than beer is because it is very good for your body. You need to drink more tea than beer. When you drink tea, you need less alcohol. This is why tea is better than beer. How long it takes to make a cup of tea?It is a long process. You need to wash your tea leaves and boil them, and then you need to boil them again. To make more tea, you need to boil the tea again. You need to boil the tea for at least one hour. Beer is life.\n",
      "0.9872356162351721 0.4060404550644659\n",
      "target1 (0.5754173306056432, 0.9872356162351721, 0.4060404550644659)\n",
      "0.44085215682714757 0.504846824753669\n",
      "target2 (0.47068425766507493, 0.44085215682714757, 0.504846824753669)\n",
      "7 n2\n",
      "0.5292495873806777 0.2151421086913324\n",
      "target1 (0.3059246169830507, 0.5292495873806777, 0.2151421086913324)\n",
      "0.19821078568146558 0.22721724212265568\n",
      "target2 (0.2117251574324746, 0.19821078568146558, 0.22721724212265568)\n",
      "\n",
      "\n",
      "\n",
      "8 n1\n",
      "Iphone is better than laptop because it is lighter, bigger, device, greater. If you have a smartphone, it is better than a laptop because it is lighter, bigger, device, greater. But it is not as good as laptop for some things like software development, software testing, or design.  It has a more stable battery, better image quality, better camera, and a better battery life. The iPhone 5s on the other hand is not a great laptop, it's not the best for a long time to come, but it is better than the iPhone 4 and 4s. And with the iPhone 6 and the iPhone 6 Plus, the iPhone 6s is better than the iPhone 6.\n",
      "0.3745184953619794 0.564531555508866\n",
      "target1 (0.45030083020062034, 0.3745184953619794, 0.564531555508866)\n",
      "0.4888700436252032 0.4637076149092001\n",
      "target2 (0.475956495303028, 0.4888700436252032, 0.4637076149092001)\n",
      "8 n2\n",
      "0.12961930184271558 0.19586916722899245\n",
      "target1 (0.15600199159831257, 0.12961930184271558, 0.19586916722899245)\n",
      "0.19295336370077187 0.18294837447184295\n",
      "target2 (0.18781772284181594, 0.19295336370077187, 0.18294837447184295)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ind, elem in enumerate(answer_big):\n",
    "    print (ind, \"n1\")\n",
    "    ngrams1 =create_ngrams(tokenizer.tokenize(elem), 1)\n",
    "    ngrams2 =create_ngrams(tokenizer.tokenize(list_of_target1[ind]), 1)\n",
    "    ngrams3 =create_ngrams(tokenizer.tokenize(list_of_target2[ind]), 1)\n",
    "    print (elem)\n",
    "    scores = score_ngrams(ngrams1, ngrams2)\n",
    "    print (\"target1\", scores)\n",
    "    scores = score_ngrams(ngrams1, ngrams3)\n",
    "    print (\"target2\", scores)\n",
    "    print (ind, \"n2\")\n",
    "    ngrams01 =create_ngrams(tokenizer.tokenize(elem), 2)\n",
    "    ngrams02 =create_ngrams(tokenizer.tokenize(list_of_target1[ind]), 2)\n",
    "    ngrams03 =create_ngrams(tokenizer.tokenize(list_of_target2[ind]), 2)\n",
    "    scores = score_ngrams(ngrams01, ngrams02)\n",
    "    print (\"target1\", scores)\n",
    "    scores = score_ngrams(ngrams01, ngrams03)\n",
    "    print (\"target2\", scores)\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6794479370117188 0.7549421522352431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7152083547491778, 0.6794479370117188, 0.7549421522352431)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6794479370117188 0.7549421522352431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7152083547491778, 0.6794479370117188, 0.7549421522352431)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5479773506522179 0.487090978357527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5157433888491462, 0.5479773506522179, 0.487090978357527)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.125, recall=0.1111111111111111, fmeasure=0.11764705882352941), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n"
     ]
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score('The quick brown dog jumps over the lazy fox',\n",
    "                      'The fast hazel hound skips above inactive tod.')\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[0][])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The quick brown dog jumps over the lazy fox.', ' The fast hazel hound skips above inactive tod. ', ' Just the place for a Snark the Bellman cried']\n"
     ]
    }
   ],
   "source": [
    "from bert_embedding import BertEmbedding\n",
    "\n",
    "bert_abstract = \"\"\"The quick brown dog jumps over the lazy fox.\\n The fast hazel hound skips above inactive tod. \\n Just the place for a Snark the Bellman cried\"\"\"\n",
    "sentences = bert_abstract.split('\\n')\n",
    "print (sentences)\n",
    "bert_embedding = BertEmbedding()\n",
    "result = bert_embedding(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "from six.moves import map\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'quick')\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'intersection_ngrams_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-0781affcb4b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mngrams2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrams2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mintersection_ngrams_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrams2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intersection_ngrams_count' is not defined"
     ]
    }
   ],
   "source": [
    "for ngram in six.iterkeys(ngrams1):\n",
    "    print (ngram)\n",
    "    print (ngrams1[ngram])\n",
    "    print (ngrams2[ngram])\n",
    "    print (min(ngrams1[ngram], ngrams2[ngram]))\n",
    "    intersection_ngrams_count += min(ngrams1[ngram], ngrams2[ngram])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score_ngrams(target_ngrams, prediction_ngrams):\n",
    "      \"\"\"Compute n-gram based rouge scores.\n",
    "      Args:\n",
    "        target_ngrams: A Counter object mapping each ngram to number of\n",
    "          occurrences for the target text.\n",
    "        prediction_ngrams: A Counter object mapping each ngram to number of\n",
    "          occurrences for the prediction text.\n",
    "      Returns:\n",
    "        A Score object containing computed scores.\n",
    "      \"\"\"\n",
    "\n",
    "      intersection_ngrams_count = 0\n",
    "      for ngram in six.iterkeys(target_ngrams):\n",
    "        intersection_ngrams_count += min(target_ngrams[ngram],\n",
    "                                         prediction_ngrams[ngram])\n",
    "      target_ngrams_count = sum(target_ngrams.values())\n",
    "      prediction_ngrams_count = sum(prediction_ngrams.values())\n",
    "\n",
    "      precision = intersection_ngrams_count / max(prediction_ngrams_count, 1)\n",
    "      recall = intersection_ngrams_count / max(target_ngrams_count, 1)\n",
    "      fmeasure = scoring.fmeasure(precision, recall)\n",
    "\n",
    "      return scoring.Score(precision=precision, recall=recall, fmeasure=fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = \"I've used the Honda the past few years, and they're pretty good. They're just not as fast as a Toyota, but they're much more powerful, lighter, and more durable than the Toyota. They're more comfortable, they're more comfortable, and they're better.have been using the Honda for a while, and I can tell you that they're very good. They're just not as fast as a Toyota, but they're much more powerful, lighter, and more durable than the Toyota. They're more comfortable, they're more comfortable, and thy're better. They're just not as good as the Honda.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = \"They don\\'t have that kind of engine. Maybe they are trying to make this bigger, faster, more powerful. You cannot afford to have a car with a big engine. You need to be careful when you make a big engine. There is no point, because it will explode. There is no point in spending a lot of money on a big engine.(CNN) After the shooting deaths of five police officers in Dallas last week, President Barack Obama offered condolences to the families of the fallen officers, calling the situation an attack on our shared humanity.Yet more than two months after the deaths of Alton Sterling in Louisiana and Philando Castile in Minnesota, the President did not issue a statement or call for unity or reflection. While we mourn for the officers who lost their lives in Dallas, we do not yet know the full extent of the threat that this attack represents, Obama said in a statement.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've used the Honda the past few years, and they're pretty good. They're just not as fast as a Toyota, but they're much more powerful, lighter, and more durable than the Toyota. They're more comfortable, they're more comfortable, and they're better.have been using the Honda for a while, and I can tell you that they're very good. They're just not as fast as a Toyota, but they're much more powerful, lighter, and more durable than the Toyota. They're more comfortable, they're more comfortable, and thy're better. They're just not as good as the Honda.\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bert_embedding([gen_templates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import porter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "stemmer = porter.PorterStemmer()\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ngrams1 = create_ngrams(tokenizer.tokenize(gen_templates), 2)\n",
    "ngrams2= create_ngrams(tokenizer.tokenize(small), 2)\n",
    "ngrams3= create_ngrams(tokenizer.tokenize(big), 2)\n",
    "\n",
    "ngrams01 = create_ngrams(tokenizer.tokenize(gen_templates), 1)\n",
    "ngrams02= create_ngrams(tokenizer.tokenize(small), 1)\n",
    "ngrams03= create_ngrams(tokenizer.tokenize(big), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After much thought, I realized that Honda is better, because: quicker, bigger, nicer, weaker, but Toyota is lighter, easier, faster, softer.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ngrams1_t = create_ngrams(tokenizer.tokenize(target1), 2)\n",
    "ngrams2_t= create_ngrams(tokenizer.tokenize(target2), 2)\n",
    "\n",
    "ngrams01_t = create_ngrams(tokenizer.tokenize(target1), 1)\n",
    "ngrams02_t = create_ngrams(tokenizer.tokenize(target2), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0821059115319384 0.6491498630493879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14577400433389767, 0.0821059115319384, 0.6491498630493879)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams01_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38255592389982573 0.5857887584716082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4628454387923817, 0.38255592389982573, 0.5857887584716082)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams01, ngrams02_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22225900106279275 0.5020672077579158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.30811795763773464, 0.22225900106279275, 0.5020672077579158)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams02, ngrams01_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7212211319378444 0.31553424522280693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.439004167266514, 0.7212211319378444, 0.31553424522280693)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams02, ngrams02_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4667321349321147 0.6709274439649149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5505045694071096, 0.4667321349321147, 0.6709274439649149)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams03, ngrams01_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6459892696263838 0.4582583762028001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7169197707706028, 1.6459892696263838, 0.4582583762028001)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(ngrams03, ngrams02_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('I', 'drive'): 1,\n",
       "         ('drive', 'a'): 1,\n",
       "         ('a', 'Honda'): 1,\n",
       "         ('Honda', 'and'): 1,\n",
       "         ('and', 'my'): 1,\n",
       "         ('my', 'wife'): 1,\n",
       "         ('wife', 'a'): 1,\n",
       "         ('a', 'Toyota'): 1,\n",
       "         ('Toyota', '.'): 1,\n",
       "         ('.', 'So'): 1,\n",
       "         ('So', 'by'): 1,\n",
       "         ('by', 'owning'): 1,\n",
       "         ('owning', 'both'): 1,\n",
       "         ('both', 'cars'): 1,\n",
       "         ('cars', 'I'): 1,\n",
       "         ('I', 'have'): 1,\n",
       "         ('have', 'experienced'): 1,\n",
       "         ('experienced', 'both'): 1,\n",
       "         ('both', 'brands'): 2,\n",
       "         ('brands', '.'): 2,\n",
       "         ('.', 'I'): 1,\n",
       "         ('I', '’'): 1,\n",
       "         ('’', 've'): 1,\n",
       "         ('ve', 'been'): 1,\n",
       "         ('been', 'driving'): 1,\n",
       "         ('driving', 'a'): 1,\n",
       "         ('a', 'honda'): 1,\n",
       "         ('honda', 'city'): 1,\n",
       "         ('city', 'AT'): 1,\n",
       "         ('AT', 'for'): 1,\n",
       "         ('for', 'almost'): 1,\n",
       "         ('almost', '7'): 1,\n",
       "         ('7', 'years'): 1,\n",
       "         ('years', 'and'): 1,\n",
       "         ('and', 'have'): 1,\n",
       "         ('have', 'never'): 1,\n",
       "         ('never', 'faced'): 1,\n",
       "         ('faced', 'any'): 1,\n",
       "         ('any', 'challenge'): 1,\n",
       "         ('challenge', 'whatsoever'): 1,\n",
       "         ('whatsoever', 'with'): 1,\n",
       "         ('with', 'the'): 1,\n",
       "         ('the', 'car'): 1,\n",
       "         ('car', '.'): 2,\n",
       "         ('.', 'The'): 3,\n",
       "         ('The', 'only'): 1,\n",
       "         ('only', 'major'): 1,\n",
       "         ('major', 'expenses'): 1,\n",
       "         ('expenses', 'include'): 1,\n",
       "         ('include', 'Two'): 1,\n",
       "         ('Two', 'sets'): 1,\n",
       "         ('sets', 'of'): 1,\n",
       "         ('of', 'tyres'): 1,\n",
       "         ('tyres', ','): 1,\n",
       "         (',', 'Insurance'): 1,\n",
       "         ('Insurance', 'And'): 1,\n",
       "         ('And', 'fuel'): 1,\n",
       "         ('fuel', '.'): 1,\n",
       "         ('The', 'car'): 1,\n",
       "         ('car', 'has'): 1,\n",
       "         ('has', 'done'): 2,\n",
       "         ('done', 'over'): 1,\n",
       "         ('over', '110k'): 1,\n",
       "         ('110k', 'and'): 1,\n",
       "         ('and', 'still'): 1,\n",
       "         ('still', 'drives'): 1,\n",
       "         ('drives', 'like'): 1,\n",
       "         ('like', 'a'): 2,\n",
       "         ('a', 'dream'): 1,\n",
       "         ('dream', '.'): 1,\n",
       "         ('.', 'Toyota'): 1,\n",
       "         ('Toyota', 'on'): 1,\n",
       "         ('on', 'the'): 2,\n",
       "         ('the', 'other'): 2,\n",
       "         ('other', 'hand'): 2,\n",
       "         ('hand', 'being'): 1,\n",
       "         ('being', 'twice'): 1,\n",
       "         ('twice', 'as'): 1,\n",
       "         ('as', 'expensive'): 1,\n",
       "         ('expensive', 'feels'): 1,\n",
       "         ('feels', 'like'): 2,\n",
       "         ('a', 'premium'): 1,\n",
       "         ('premium', 'car'): 1,\n",
       "         ('car', 'and'): 1,\n",
       "         ('and', 'is'): 1,\n",
       "         ('is', 'rock'): 1,\n",
       "         ('rock', 'solid'): 1,\n",
       "         ('solid', 'trouble'): 1,\n",
       "         ('trouble', 'free'): 1,\n",
       "         ('free', ','): 1,\n",
       "         (',', 'worry'): 1,\n",
       "         ('worry', 'free'): 1,\n",
       "         ('free', 'car'): 1,\n",
       "         ('The', 'biggest'): 1,\n",
       "         ('biggest', 'expense'): 1,\n",
       "         ('expense', 'here'): 1,\n",
       "         ('here', 'was'): 1,\n",
       "         ('was', 'insurance'): 1,\n",
       "         ('insurance', '.'): 1,\n",
       "         ('.', 'This'): 1,\n",
       "         ('This', 'one'): 1,\n",
       "         ('one', 'has'): 1,\n",
       "         ('done', '25k'): 1,\n",
       "         ('25k', 'and'): 1,\n",
       "         ('and', 'feels'): 1,\n",
       "         ('like', 'We'): 1,\n",
       "         ('We', 'bought'): 1,\n",
       "         ('bought', 'it'): 1,\n",
       "         ('it', 'yesterday'): 1,\n",
       "         ('yesterday', '.'): 1,\n",
       "         ('.', 'In'): 1,\n",
       "         ('In', 'terms'): 1,\n",
       "         ('terms', 'of'): 1,\n",
       "         ('of', 'comfort'): 1,\n",
       "         ('comfort', 'Toyota'): 1,\n",
       "         ('Toyota', 'is'): 1,\n",
       "         ('is', 'far'): 1,\n",
       "         ('far', 'superior'): 1,\n",
       "         ('superior', 'than'): 1,\n",
       "         ('than', 'any'): 1,\n",
       "         ('any', 'car'): 2,\n",
       "         ('car', 'in'): 2,\n",
       "         ('in', 'the'): 2,\n",
       "         ('the', 'industry'): 1,\n",
       "         ('industry', 'be'): 1,\n",
       "         ('be', 'it'): 1,\n",
       "         ('it', 'the'): 1,\n",
       "         ('the', 'driver'): 1,\n",
       "         ('driver', 'or'): 1,\n",
       "         ('or', 'the'): 1,\n",
       "         ('the', 'passengers'): 2,\n",
       "         ('passengers', 'there'): 1,\n",
       "         ('there', 'is'): 1,\n",
       "         ('is', 'no'): 2,\n",
       "         ('no', 'match'): 1,\n",
       "         ('match', 'for'): 1,\n",
       "         ('for', 'Innova'): 1,\n",
       "         ('Innova', '.'): 1,\n",
       "         ('.', 'Honda'): 1,\n",
       "         ('Honda', 'city'): 1,\n",
       "         ('city', 'on'): 1,\n",
       "         ('hand', 'is'): 1,\n",
       "         ('is', 'superb'): 1,\n",
       "         ('superb', 'in'): 1,\n",
       "         ('in', 'driving'): 1,\n",
       "         ('driving', '.'): 1,\n",
       "         ('.', 'It'): 1,\n",
       "         ('It', '’'): 1,\n",
       "         ('’', 's'): 1,\n",
       "         ('s', 'steering'): 1,\n",
       "         ('steering', 'is'): 1,\n",
       "         ('is', 'so'): 1,\n",
       "         ('so', 'light'): 1,\n",
       "         ('light', 'that'): 1,\n",
       "         ('that', 'anyone'): 1,\n",
       "         ('anyone', 'can'): 1,\n",
       "         ('can', 'drive'): 1,\n",
       "         ('drive', 'it'): 1,\n",
       "         ('it', 'with'): 1,\n",
       "         ('with', 'ease'): 1,\n",
       "         ('ease', '.'): 1,\n",
       "         ('.', 'There'): 1,\n",
       "         ('There', 'is'): 1,\n",
       "         ('no', 'engine'): 1,\n",
       "         ('engine', 'sound'): 1,\n",
       "         ('sound', 'at'): 1,\n",
       "         ('at', 'idling'): 1,\n",
       "         ('idling', '.'): 1,\n",
       "         ('.', 'Super'): 1,\n",
       "         ('Super', 'smooth'): 1,\n",
       "         ('smooth', 'ride'): 1,\n",
       "         ('ride', 'and'): 1,\n",
       "         ('and', 'you'): 1,\n",
       "         ('you', 'reach'): 1,\n",
       "         ('reach', 'in'): 1,\n",
       "         ('in', 'comfort'): 1,\n",
       "         ('comfort', 'to'): 1,\n",
       "         ('to', 'your'): 1,\n",
       "         ('your', 'destination'): 1,\n",
       "         ('destination', '.'): 1,\n",
       "         ('.', 'Long'): 1,\n",
       "         ('Long', 'drives'): 1,\n",
       "         ('drives', 'for'): 1,\n",
       "         ('for', 'the'): 1,\n",
       "         ('passengers', 'is'): 1,\n",
       "         ('is', 'not'): 1,\n",
       "         ('not', 'as'): 1,\n",
       "         ('as', 'good'): 1,\n",
       "         ('good', 'as'): 1,\n",
       "         ('as', 'Innova'): 1,\n",
       "         ('Innova', 'though'): 1,\n",
       "         ('though', '.'): 1,\n",
       "         ('.', 'Overall'): 1,\n",
       "         ('Overall', 'to'): 1,\n",
       "         ('to', 'sum'): 1,\n",
       "         ('sum', 'up'): 1,\n",
       "         ('up', 'both'): 1,\n",
       "         ('both', 'are'): 1,\n",
       "         ('are', 'amazing'): 1,\n",
       "         ('amazing', 'brands'): 1,\n",
       "         ('brands', 'super'): 1,\n",
       "         ('super', 'reliable'): 1,\n",
       "         ('reliable', ','): 1,\n",
       "         (',', 'great'): 1,\n",
       "         ('great', 'resale'): 1,\n",
       "         ('resale', 'value'): 1,\n",
       "         ('value', 'for'): 1,\n",
       "         ('for', 'both'): 1,\n",
       "         ('.', 'Service'): 1,\n",
       "         ('Service', 'cost'): 1,\n",
       "         ('cost', 'is'): 1,\n",
       "         ('is', 'comparable'): 1,\n",
       "         ('comparable', 'to'): 1,\n",
       "         ('to', 'any'): 1,\n",
       "         ('the', 'segment'): 1,\n",
       "         ('segment', '.'): 1,\n",
       "         ('.', 'To'): 1,\n",
       "         ('To', 'decide'): 1,\n",
       "         ('decide', 'between'): 1,\n",
       "         ('between', 'one'): 1,\n",
       "         ('one', 'of'): 1,\n",
       "         ('of', 'the'): 1,\n",
       "         ('the', 'two'): 1,\n",
       "         ('two', 'is'): 1,\n",
       "         ('is', 'a'): 1,\n",
       "         ('a', 'difficult'): 1,\n",
       "         ('difficult', 'decision'): 1,\n",
       "         ('decision', 'as'): 1,\n",
       "         ('as', 'both'): 1,\n",
       "         ('both', 'the'): 1,\n",
       "         ('the', 'brands'): 1,\n",
       "         ('brands', 'are'): 1,\n",
       "         ('are', 'of'): 1,\n",
       "         ('of', 'amazing'): 1,\n",
       "         ('amazing', 'quality'): 1,\n",
       "         ('quality', '.'): 1})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams1_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score(gen_templates, target1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.025974025974025976, recall=0.2857142857142857, fmeasure=0.04761904761904762),\n",
       " 'rouge2': Score(precision=0.004347826086956522, recall=0.05, fmeasure=0.008)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.17316017316017315, recall=0.3669724770642202, fmeasure=0.2352941176470588),\n",
       " 'rouge2': Score(precision=0.02608695652173913, recall=0.05555555555555555, fmeasure=0.03550295857988165)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score(small, target1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.23809523809523808, recall=0.34375, fmeasure=0.28132992327365725),\n",
       " 'rouge2': Score(precision=0.02608695652173913, recall=0.03773584905660377, fmeasure=0.030848329048843187)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score(big, target1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.2857142857142857, recall=0.025974025974025976, fmeasure=0.04761904761904762),\n",
       " 'rouge2': Score(precision=0.05, recall=0.004347826086956522, fmeasure=0.008)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "scores = scorer.score(target1, gen_templates)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In terms of sheer corporate value, Toyota is the most successful, preponderant automaker in the world. Honda is much smaller with an overall value that's just 25 percent of Toyota's. Toyota also sells many more vehicles in the United States every year than Honda.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
