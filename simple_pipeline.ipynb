{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import torch\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "PATH_TO_PRETRAINED = '/home/vika/cqas_flask/external_pretrained_models/'\n",
    "MODEL_NAMES = ['bert_simple1.hdf5']\n",
    "\n",
    "def load(checkpoint_fn, gpu=-1):\n",
    "    if not os.path.isfile(PATH_TO_PRETRAINED + checkpoint_fn):\n",
    "        raise ValueError('Can''t find tagger in file \"%s\". Please, run the main script with non-empty \\\n",
    "                         \"--save-best-path\" param to create it.' % checkpoint_fn)\n",
    "    tagger = torch.load(PATH_TO_PRETRAINED + checkpoint_fn)\n",
    "    tagger.gpu = gpu\n",
    "\n",
    "    tagger.word_seq_indexer.gpu = gpu # hotfix\n",
    "    tagger.tag_seq_indexer.gpu = gpu # hotfix\n",
    "    if hasattr(tagger, 'char_embeddings_layer'):# very hot hotfix\n",
    "        tagger.char_embeddings_layer.char_seq_indexer.gpu = gpu # hotfix\n",
    "    tagger.self_ensure_gpu()\n",
    "    return tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The python is better than matlab. The reason is easier, quicker to develop code, quicker, matplotlib.  I think that it is more efficient, faster to write, and more fun to work with. I have used it extensively as a development platform (more on that later).I have been using it for a while now, and it is a very pleasant experience. I find that it provides more flexibility when it comes to code generation. For example, I have been able to use a matrix method to generate my own code from my data, instead of having to do it all in matlab. There are many other ways to do it, I will just mention a few of the more common ones.I have been able to use matplotlib matplotlib-core matplotlib-r matplotlib-ggplot matplotlib-lumbarI use matplotlib-core from time to time, but I find it very useful for the things I do with matplotlib. It provides a lot of advanced features, like color picker and an interactive\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'better', 'for', 'deep', 'learning:', 'matlab', 'or', 'python?']]\n",
      "2\n",
      "[['O', 'O', 'B-PREDFULL', 'I-PREDFULL', 'I-PREDFULL', 'O', 'B-OBJ', 'O', 'O']]\n",
      "['matlab']\n",
      "['better']\n",
      "We try to use spacy\n",
      "split_sent ['what', 'is', 'better', 'for', 'deep', 'learning:', 'matlab', 'or', 'python?']\n",
      "tokens  ['What', 'is', 'better', 'for', 'deep', 'learning', ':', 'Matlab', 'or', 'Python', '?']\n",
      "or simple split_sent 8\n",
      "Matlab Python\n",
      "len(obj1), len(obj2) 6 6\n",
      "obj1, obj2, predicates Matlab Python ['better']\n",
      "aspects ['better']\n",
      "weights [1]\n",
      "get url\n",
      "1\n",
      "create fro json predicates ['better']\n",
      "create fro json self.predicates better\n",
      "aspects  ['easier', 'quicker to develop code', 'quicker', 'matplotlib'] ['eigenvalues', 'faster', 'better for scientific computing', 'pythonnumpy']\n",
      "2\n",
      "winnder: python  other: matlab\n",
      "acpect winner  easier, quicker to develop code, quicker, matplotlib\n",
      "acpect other  eigenvalues, faster, better for scientific computing, pythonnumpy\n",
      "type  cam\n",
      "winnder: python  other: matlab\n",
      "acpect winner  easier, quicker to develop code, quicker, matplotlib\n",
      "acpect other  eigenvalues, faster, better for scientific computing, pythonnumpy\n",
      "self predicate  better\n",
      "answer begin:  The python is better than matlab. The reason is easier, quicker to develop code, quicker, matplotlib. \n",
      "answer_begin cam The python is better than matlab. The reason is easier, quicker to develop code, quicker, matplotlib. \n",
      "cam_summarize\n"
     ]
    }
   ],
   "source": [
    "from my_functions import answerer\n",
    "a = answerer(\"What is better for deep learning: Matlab or Python? \", tp = 'cam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vika/cqas_flask/generation/pytorch-transformers/pytorch_transformers/models/gpt2-large-pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "from text_gen_big import text_generator_for_out_big\n",
    "text_generator_for_out_big(\"what is better bread or pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ping: not found\n"
     ]
    }
   ],
   "source": [
    "! ping http://0.0.0.0:6000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_template(comparing_pair, mode=\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProxyError",
     "evalue": "HTTPConnectionPool(host='165.225.66.34', port=10015): Max retries exceeded with url: http://0.0.0.0:6000/templates (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f2cbe6a2c18>: Failed to establish a new connection: [Errno 110] Connection timed out',)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 141\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 150\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f2cbe6a2c18>: Failed to establish a new connection: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 )\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 639\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='165.225.66.34', port=10015): Max retries exceeded with url: http://0.0.0.0:6000/templates (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f2cbe6a2c18>: Failed to establish a new connection: [Errno 110] Connection timed out',)))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProxyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-820597a8f4df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mproxies_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"http://185.46.212.97:10015/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"https\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"https://185.46.212.98:10015/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://0.0.0.0:6000/templates'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What is bwteer bread or pizza\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \"\"\"\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    510\u001b[0m         }\n\u001b[1;32m    511\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ProxyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProxyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProxyError\u001b[0m: HTTPConnectionPool(host='165.225.66.34', port=10015): Max retries exceeded with url: http://0.0.0.0:6000/templates (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f2cbe6a2c18>: Failed to establish a new connection: [Errno 110] Connection timed out',)))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "proxies_ = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "r = requests.post('http://0.0.0.0:6000/templates', data = \"What is bwteer bread or pizza\")\n",
    "print (r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f174f77c0f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mes_requester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArgument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from utils.es_requester import extract_sentences\n",
    "from utils.objects import Argument\n",
    "\n",
    "\n",
    "all_sentences = extract_sentences(rjson)\n",
    "remove_questions(all_sentences)\n",
    "prepared_sentences = prepare_sentence_DF(all_sentences, obj_a, obj_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obj_a_aspects' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2f599994add4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcomparing_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_a_aspects\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_b_aspects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcomparing_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'winner_aspects'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_a_aspects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcomparing_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loser_aspects'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_b_aspects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'obj_a_aspects' is not defined"
     ]
    }
   ],
   "source": [
    "from template_generation import generate_template\n",
    "comparing_pair = {}\n",
    "\n",
    "if len(obj_a_aspects) > len(obj_b_aspects):\n",
    "    comparing_pair['winner_aspects'] = obj_a_aspects\n",
    "    comparing_pair['loser_aspects'] = obj_b_aspects\n",
    "    comparing_pair['winner'] = obj_a.name\n",
    "    comparing_pair['loser'] = obj_b.name\n",
    "else:\n",
    "    comparing_pair['winner_aspects'] = obj_b_aspects\n",
    "    comparing_pair['loser_aspects'] = obj_a_aspects\n",
    "    comparing_pair['winner'] = obj_b.name\n",
    "    comparing_pair['loser'] = obj_a.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "504\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Response' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9e6a58131569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://130.138.20.25:6000/templates'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What is bwteer bread or pizza\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mrjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Response' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "print (\"qu\")\n",
    "proxies_ = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "r = requests.post('http://130.138.20.25:6000/templates', data = \"What is bwteer bread or pizza\", proxies = proxies_)\n",
    "print (r.status_code)\n",
    "print (r.data)\n",
    "rjson = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_simple1.hdf5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/vika/targer')\n",
    "from src.factories.factory_tagger import TaggerFactory\n",
    "from src.layers import layer_context_word_embeddings_bert\n",
    "\n",
    "for MODEL_NAME in ['bert_simple1.hdf5']:\n",
    "    print (MODEL_NAME)\n",
    "    model = TaggerFactory.load(PATH_TO_PRETRAINED + MODEL_NAME, 2)\n",
    "    print (model.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.\n",
      "Warning:  apex was installed without --cuda_ext. Fused syncbn kernels will be unavailable.  Python fallbacks will be used instead.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedAdam will be unavailable.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedLayerNorm will be unavailable.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/vika/cqas_flask/generation/pytorch-transformers/pytorch_transformers\")\n",
    "from text_gen_big import text_generator_for_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vika/cqas_flask/generation/pytorch-transformers/pytorch_transformers/models/gpt2-large-pytorch_model.bin\n",
      "Whats is better bread or pizza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== SAMPLE 1 ========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"? This is a question we are asked a lot. It's one of those questions you have to think about if you want to keep your sanity. One of the common choices is pizza because it's easy to make and it's usually good. However, if you're like me and you're trying to be healthy, you want to go for something that is healthier and more nutrient dense, especially if it's a pizza. Bread is good for you, but it's not as nutritious as a pizza. This is true for the two main reasons.\\n\\nFirst, bread has a lot of carbohydrates. This means you need to eat a lot of it to get the same amount of energy as you get from a pizza. So it's not a good choice for a healthy diet. It's not even a good choice for a good eating plan because you need to eat lots of bread to get the same amount of energy as you get from a pizza. Secondly, bread is basically a high-fat\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator_for_out(\"Whats is better bread or pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.\n",
      "Warning:  apex was installed without --cuda_ext. Fused syncbn kernels will be unavailable.  Python fallbacks will be used instead.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedAdam will be unavailable.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedLayerNorm will be unavailable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't find a vocabulary file at path 'vocab.txt'. To load the vocabulary from a Google pretrained model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-39a0ba912c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmy_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdo_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswerer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/vika/cqas_flask/my_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# for generate answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdiviner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pathes to pretrained extraction model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vika/cqas_flask/generation/generation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtext_gen_big\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_generator_for_out_big\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtext_gen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_generator_for_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcam_summarize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcam_summarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mdiviner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vika/cqas_flask/generation/Student/cam_summarize.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtokenizer_custom_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'vocab.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vika/cqas_flask/generation/Student/tokenizer_custom_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, do_lower_case)\u001b[0m\n\u001b[1;32m    171\u001b[0m             raise ValueError(\n\u001b[1;32m    172\u001b[0m                 \u001b[0;34m\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\".format(vocab_file))\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         self.ids_to_tokens = collections.OrderedDict(\n",
      "\u001b[0;31mValueError\u001b[0m: Can't find a vocabulary file at path 'vocab.txt'. To load the vocabulary from a Google pretrained model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`"
     ]
    }
   ],
   "source": [
    "from my_functions import do_sum, answerer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['whats', 'is', 'better', 'bread', 'or', 'pizza']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'src.layers.layer_context_word_embeddings_bert.LayerContextWordEmbeddingsBert' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LogSoftmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/.local/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.loss.NLLLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'B-OBJ', 'O', 'O']]\n",
      "['bread']\n",
      "['better']\n",
      "We try to use spacy\n",
      "split_sent ['whats', 'is', 'better', 'bread', 'or', 'pizza']\n",
      "tokens  ['What', 's', 'is', 'better', 'bread', 'or', 'pizza']\n",
      "or simple split_sent 5\n",
      "bread pizza\n",
      "len(obj1), len(obj2) 5 5\n",
      "obj1, obj2, predicates bread pizza ['better']\n",
      "aspects ['better']\n",
      "weights [1]\n",
      "get url\n",
      "1\n",
      "create fro json predicates ['better']\n",
      "create fro json self.predicates better\n",
      "aspects  ['faster', 'easier to make', 'lighter', 'bigger'] ['safer', 'bit', 'cycle', 'production']\n",
      "2\n",
      "winnder: pizza  other: bread\n",
      "acpect winner  faster, easier to make, lighter, bigger\n",
      "acpect other  safer, bit, cycle, production\n",
      "self predicate  better\n",
      "answer begin:  The pizza is better than bread.\n",
      "/home/vika/cqas_flask/generation/pytorch-transformers/pytorch_transformers/models/gpt2-large-pytorch_model.bin\n",
      "The pizza is better than bread.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== SAMPLE 1 ========================================\n",
      "answer end str:   The pizza is better than food.\n",
      "\n",
      "I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.\n",
      "\n",
      "I hope you are enjoying your pizza.\n",
      "\n",
      "The pizza is better than bread.\n",
      "\n",
      "The pizza is better than food.\n",
      "\n",
      "I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.\n",
      "\n",
      "I hope you are enjoying your pizza.\n",
      "\n",
      "The pizza is better than bread.\n",
      "\n",
      "The pizza is better than food.\n",
      "\n",
      "I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.\n",
      "\n",
      "I hope you are enjoying your pizza.\n",
      "\n",
      "The pizza is better than bread.\n",
      "\n",
      "The pizza is better than food.\n",
      "\n",
      "I would like to take\n",
      "answer end str:   The pizza is better than food.I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.I hope you are enjoying your pizza.The pizza is better than bread.\n",
      "full answer  The pizza is better than bread.The reason is faster, easier to make, lighter, bigger. The pizza is better than food.I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.I hope you are enjoying your pizza.The pizza is better than bread.\n",
      "answer The pizza is better than bread.The reason is faster, easier to make, lighter, bigger. The pizza is better than food.I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.I hope you are enjoying your pizza.The pizza is better than bread.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The pizza is better than bread.The reason is faster, easier to make, lighter, bigger. The pizza is better than food.I would like to take this opportunity to thank you for your support of me and my work. We really appreciate all the support you have given us so far.I hope you are enjoying your pizza.The pizza is better than bread.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answerer(\"Whats is better bread or pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(model.birnn_layer.parameters()) + list(model.lin_layer.parameters()) + list(model.log_softmax_layer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30522, 768])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30522, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for kv in a[:14]:\n",
    "    print (kv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30522, 768])\n",
      "torch.Size([512, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for kv in b[:14]:\n",
    "    print (kv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-ee8c2ab6104b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m215\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m215\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "torch.eq(b[215], a[215]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 768])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new = []\n",
    "for elem in a:\n",
    "    if len(elem.shape) > 1:\n",
    "        a_new.append(elem.view((elem.shape[1], elem.shape[0])))\n",
    "    else:\n",
    "        a_new.append(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30522, 768])\n",
      "torch.Size([768, 30522])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-58bf1456f8cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "for ind, kv in enumerate(b):\n",
    "    print (kv.shape)\n",
    "    print (kv.view((kv.shape[1], kv.shape[0])).shape)\n",
    "    if (kv.view((kv.shape[1], kv.shape[0])) not in a_new):\n",
    "        c.append(kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_from_sentence(str_sentences):\n",
    "    return [str_sentence.lower().split() for str_sentence in str_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = create_sequence_from_sentence(['what is better amazon or itunes', 'who is better mouse or rat', 'what is easier to make bread or pizza', 'what is better for startap python or mathlab', 'what is better memory foam or gel memory foam', 'what is better perl or python', 'what is better cuda or opencl', 'what is better gamecube or ps2', 'what is preferable beer or milk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/vika/NER_RNN/targer')\n",
    "from src.factories.factory_tagger import TaggerFactory\n",
    "\n",
    "def create_sequence_from_sentence(str_sentences):\n",
    "    return [str_sentence.lower().split() for str_sentence in str_sentences]\n",
    "\n",
    "class extractor:\n",
    "    def __init__(self, input_sentence, model_name = 'bert_simple1.hdf5', model_path = '/home/vika/cqas_flask/external_pretrained_models/'):\n",
    "        self.input_str = input_sentence\n",
    "        self.answ = \"UNKNOWN ERROR\"\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "        self.first_object = ''\n",
    "        self.second_object = ''\n",
    "        self.predicates = ''\n",
    "        \n",
    "    def get_objects_predicates(self, list_words, list_tags):\n",
    "        obj_list = []\n",
    "        pred_list = []\n",
    "        for ind, elem in enumerate(list_tags):\n",
    "            if elem == 'B-OBJ':\n",
    "                obj_list.append(list_words[ind])\n",
    "            if elem == 'B-PREDFULL':\n",
    "                pred_list.append(list_words[ind])    \n",
    "        return obj_list, pred_list\n",
    "    \n",
    "    def extract_objects_predicates(self, input_sentence):\n",
    "        words = create_sequence_from_sentence([input_sentence])\n",
    "        print (words)\n",
    "        model = TaggerFactory.load(self.model_path + self.model_name, -1)\n",
    "        print (model.gpu)\n",
    "        #model.cuda(device=2)\n",
    "        #model.gpu = 2\n",
    "        tags = model.predict_tags_from_words(words)\n",
    "        print (tags)\n",
    "        objects, predicates = self.get_objects_predicates(words[0], tags[0])\n",
    "        print (objects)\n",
    "        print (predicates)\n",
    "        self.predicates = predicates\n",
    "        if len(objects) >= 2:\n",
    "            self.first_object = objects[0]\n",
    "            self.second_object = objects[1]\n",
    "        else: # try to use spacy\n",
    "            \n",
    "            print(\"We try to use spacy\")\n",
    "            doc = nlp(input_sentence)\n",
    "            tokens = [token.text for token in doc]\n",
    "            split_sent = words[0]\n",
    "            if 'or' in split_sent:\n",
    "                comp_elem = 'or'\n",
    "            elif 'vs' in split_sent:\n",
    "                comp_elem = 'vs'\n",
    "            elif 'vs.' in split_sent:\n",
    "                comp_elem = 'vs.'\n",
    "            else:\n",
    "                self.answ = \"We can't recognize two objects for compare\"  \n",
    "                return;\n",
    "    \n",
    "            if (comp_elem in tokens):\n",
    "                or_index = tokens.index(comp_elem)\n",
    "                if (len (doc.ents) >= 2):\n",
    "                    for ent in doc.ents:\n",
    "                        print (\"or index doc snet\", or_index)\n",
    "                        print (\"begin end \", ent.start, ent.end, ent.text)\n",
    "                        if (ent.end == or_index):\n",
    "                            print (\"obj1 spacy doc sent\", ent.text)\n",
    "                            self.first_object = ent.text\n",
    "                        if (ent.start == or_index + 1):\n",
    "                            print (\"obj2 spacy doc sent\", ent.text)\n",
    "                            self.second_object = ent.text\n",
    "\n",
    "                else:\n",
    "                    print (\"or simple split_sent\", or_index)\n",
    "                    try:\n",
    "                        obj1 = split_sent[or_index - 1]\n",
    "                        obj2 = split_sent[or_index + 1]\n",
    "                        print (obj1, obj2)\n",
    "                        self.first_object = obj1\n",
    "                        self.second_object = obj2\n",
    "                    except:\n",
    "                        self.answ = \"We can't recognize two objects for compare\" \n",
    "\n",
    "            else:\n",
    "                self.answ = \"We can't recognize two objects for compare\" \n",
    "                \n",
    "    def get_params(self):\n",
    "        self.extract_objects_predicates(self.input_str)\n",
    "        return self.first_object.strip(\".,!/?\"), self.second_object.strip(\".,!/?\"), self.predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'better', 'moscow', 'or', 'london?']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'O', 'O', 'O']]\n",
      "[]\n",
      "['better']\n",
      "We try to use spacy\n",
      "or index doc snet 4\n",
      "begin end  3 4 Moscow\n",
      "obj1 spacy doc sent Moscow\n",
      "or index doc snet 4\n",
      "begin end  5 6 London\n",
      "obj2 spacy doc sent London\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Moscow', 'London', ['better'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_extractor = extractor(\"What is better Moscow or London?\")\n",
    "my_extractor.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os.path\n",
    "import torch\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "\n",
    "proxies = {\n",
    "  \"http\": \"http://185.46.212.97:10015/\",\n",
    "  \"https\": \"https://185.46.212.98:10015/\",\n",
    "}\n",
    "\n",
    "def get_response(first_object, second_object, fast_search=True, \n",
    "               aspects=None, weights=None):\n",
    "    num_aspects = len(aspects) if aspects is not None else 0\n",
    "    num_weights = len(weights) if weights is not None else 0\n",
    "    if num_aspects != num_weights:\n",
    "        raise ValueError(\n",
    "            \"Number of weights should be equal to the number of aspects\")\n",
    "    params = {\n",
    "        'objectA': first_object,\n",
    "        'objectB': second_object,\n",
    "        'fs': str(fast_search).lower()\n",
    "    }\n",
    "    if num_aspects:\n",
    "        params.update({'aspect{}'.format(i + 1): aspect \n",
    "                       for i, aspect in enumerate(aspects)})\n",
    "        params.update({'weight{}'.format(i + 1): weight \n",
    "                       for i, weight in enumerate(weights)})\n",
    "    print (\"get url\")\n",
    "    response = requests.get(url=URL, params=params, proxies=proxies)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class responser:\n",
    "    def __init__(self):\n",
    "        self.URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "        self.proxies = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "        \n",
    "    def get_response(self, first_object, second_object, fast_search=True, \n",
    "               aspects=None, weights=None):\n",
    "        print (\"aspects\", aspects)\n",
    "        print (\"weights\", weights)\n",
    "        num_aspects = len(aspects) if aspects is not None else 0\n",
    "        num_weights = len(weights) if weights is not None else 0\n",
    "        if num_aspects != num_weights:\n",
    "            raise ValueError(\n",
    "                \"Number of weights should be equal to the number of aspects\")\n",
    "        params = {\n",
    "            'objectA': first_object,\n",
    "            'objectB': second_object,\n",
    "            'fs': str(fast_search).lower()\n",
    "        }\n",
    "        if num_aspects:\n",
    "            params.update({'aspect{}'.format(i + 1): aspect \n",
    "                           for i, aspect in enumerate(aspects)})\n",
    "            params.update({'weight{}'.format(i + 1): weight \n",
    "                           for i, weight in enumerate(weights)})\n",
    "        print (\"get url\", params)\n",
    "        response = requests.get(url=URL, params=params, proxies=proxies)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProxyError",
     "evalue": "HTTPConnectionPool(host='165.225.66.34', port=10015): Max retries exceeded with url: http://ltdemos.informatik.uni-hamburg.de/cam-api?objectA=Moscow&objectB=London&fs=true (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efc9709cf98>: Failed to establish a new connection: [Errno 110] Connection timed out',)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 141\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 150\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7efc9709cf98>: Failed to establish a new connection: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 )\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 639\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='165.225.66.34', port=10015): Max retries exceeded with url: http://ltdemos.informatik.uni-hamburg.de/cam-api?objectA=Moscow&objectB=London&fs=true (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efc9709cf98>: Failed to establish a new connection: [Errno 110] Connection timed out',)))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProxyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b3b3125ef2cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m'objectB'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'London'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             'fs': str(True).lower()}\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, proxies=proxies)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    510\u001b[0m         }\n\u001b[1;32m    511\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ProxyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProxyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProxyError\u001b[0m: HTTPConnectionPool(host='165.225.66.34', port=10015): Max retries exceeded with url: http://ltdemos.informatik.uni-hamburg.de/cam-api?objectA=Moscow&objectB=London&fs=true (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efc9709cf98>: Failed to establish a new connection: [Errno 110] Connection timed out',)))"
     ]
    }
   ],
   "source": [
    "URL = 'http://ltdemos.informatik.uni-hamburg.de/cam-api'\n",
    "#proxies = {\"http\": \"http://185.46.212.97:10015/\",\"https\": \"https://185.46.212.98:10015/\",}\n",
    "params = {\n",
    "            'objectA': 'Moscow',\n",
    "            'objectB': 'London',\n",
    "            'fs': str(True).lower()}\n",
    "response = requests.get(url=URL, params=params)#, proxies=proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CAM_score': 0.725490820169457,\n",
       "  'ES_score': 22.56571,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': ['argument',\n",
       "   'power',\n",
       "   'authority',\n",
       "   'argument',\n",
       "   'power',\n",
       "   'authority'],\n",
       "  'id_pair': {'http://hitchensblog.mailonsunday.co.uk/2007/02/index.html': 664,\n",
       "   'http://hitchensblog.mailonsunday.co.uk/2007/02/other_peoples_c.html': 11},\n",
       "  'text': 'Though it was interesting that the state schools in Moscow were far better than their equivalents in London.'},\n",
       " {'CAM_score': 0.69932320732406,\n",
       "  'ES_score': 21.751791,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': [],\n",
       "  'id_pair': {'https://www.craigmurray.org.uk/archives/2012/07/martial-law-britain/': 334},\n",
       "  'text': 'In fact I came across a number of estates in London, particularly multi-apartment estates that are far worse than average Moscow estates.'},\n",
       " {'CAM_score': 0.6548178919407949,\n",
       "  'ES_score': 20.367495,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': ['fresher', 'smarter'],\n",
       "  'id_pair': {'http://www.smh.com.au/sport/athletics/towards-russia-with-dreams-20121207-2b1ph.html?skin=text-only': 7},\n",
       "  'text': 'Next year though he will tweak his preparation and arrive in Moscow for the world championships fresher and smarter than he did when he arrived in London an Olympic debutant.'},\n",
       " {'CAM_score': 0.5996259973778343,\n",
       "  'ES_score': 18.650803,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': ['easier'],\n",
       "  'id_pair': {'http://www.glutenfreemrsd.com/2011/06/': 3},\n",
       "  'text': 'When I graduated from University I moved to Moscow, Russia which was a lot easier and a whole heap more fun than getting a job in recession hit 90s London.'},\n",
       " {'CAM_score': 0.594508466097352,\n",
       "  'ES_score': 18.491627,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': ['faster'],\n",
       "  'id_pair': {'http://www.bloomberg.com/news/articles/2012-05-16/gazprom-at-discount-after-ny-oil-trails-london-russia-overnight': 3},\n",
       "  'text': \"OAO Gazprom and OAO Lukoil's U.S.- traded shares are fetching a discount to their Moscow stock for the first time in three years after oil tumbled faster in New York than in London.\"},\n",
       " {'CAM_score': 0.5468930101086482,\n",
       "  'ES_score': 17.010593,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': ['faster'],\n",
       "  'id_pair': {'http://www.theguardian.com/business/2008/may/01/automotive.russia1': 3},\n",
       "  'text': \"Once you've got the car you then have to negotiate the ubiquitous traffic jams in Moscow where cars move at a sedate average of 12mph - slightly faster than in London, which clocks in at a 11mph.\"},\n",
       " {'CAM_score': 0.5445108130578451,\n",
       "  'ES_score': 16.936497,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': [],\n",
       "  'id_pair': {\"http://www.theday.com/article/20140302/NWS14/303029922/1070/New-London-orders-biker-club-shut-down/Without-firing-shot-Putin's-troops-move-in-on-Ukrainian-peninsula\": 30},\n",
       "  'text': '\"Russia and the West find themselves on the brink of a confrontation far worse than in 2008 over Georgia,\" Dmitri Trenin, the director of Carnegie Moscow Center, said in a commentary posted on its website.'},\n",
       " {'CAM_score': 0.5319529990618588,\n",
       "  'ES_score': 16.545898,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': [],\n",
       "  'id_pair': {'http://en.chessbase.com/post/london-claic-carlsen-probably-the-best-che-player-in-the-world': 71},\n",
       "  'text': \"I don't want to tempt fate, and it is very wrong of me to make odious comparisons, but I can't resist: that's a much better percentage than the ten decisive games out of 45 played in Moscow recently.\"},\n",
       " {'CAM_score': 0.5307218093072094,\n",
       "  'ES_score': 16.507603,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': [],\n",
       "  'id_pair': {'http://yourfreedomandours.blogspot.co.uk/2010_03_01_archive.html': 55,\n",
       "   'http://yourfreedomandours.blogspot.com/2010/03/trying-to-understand-what-happened-in.html': 22},\n",
       "  'text': 'If that account of the immediate after-effects is correct and the pictures indicate that it might be, one can only say that Moscow seemed a good deal better organized and better prepared than London was back in 2005.'},\n",
       " {'CAM_score': 0.5276398000775462,\n",
       "  'ES_score': 16.41174,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': [],\n",
       "  'id_pair': {'http://issuu.com/tntmagazinelondon/docs/issue-1527?mode=window&backgroundColor=%23222222': 2556,\n",
       "   'http://www.tntdownunder.com/travel/world-travel/christmas-getaways-overseas-festive-holiday-ideas': 28,\n",
       "   'http://www.tntmagazine.com/travel/big-trip/christmas-getaways-overseas-festive-holiday-ideas': 28},\n",
       "  'text': 'Then take matters into your own hands and jet off to Moscow for the holidays where your chances of seeing snowflakes falling on December 25 are infinitely better than they are in London.'},\n",
       " {'CAM_score': 0.5246421206749216,\n",
       "  'ES_score': 16.3185,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': ['braver'],\n",
       "  'id_pair': {'http://www.theguardian.com/commentisfree/2014/mar/15/ukraine-crimea-sanctions-russian-investment-london': 34},\n",
       "  'text': 'Our legal profession was not bothered in the slightest that Magnitsky was a better and braver lawyer than they would or could ever be; a man who had died in a Moscow prison for the \"crime\" of exposing a gigantic tax fraud.'},\n",
       " {'CAM_score': 0.5005132448947179,\n",
       "  'ES_score': 15.567994,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': [],\n",
       "  'id_pair': {'http://www.irishtimes.com/sport/golf/mo-farah-strikes-gold-at-world-championships-1.1490740': 7,\n",
       "   'https://www.rte.ie/sport/athletics/2013/0810/467470-farah-strolls-to-10-000m-gold-medal/': 7},\n",
       "  'text': 'The 30-year-old had said ahead of Moscow he now has a target on his back every time he raced, but warned his rivals he was a better athlete this year than at London 2012.'},\n",
       " {'CAM_score': 0.4837269153930387,\n",
       "  'ES_score': 15.045871,\n",
       "  'confidence': 1,\n",
       "  'context_aspects': ['better for the people of wales'],\n",
       "  'id_pair': {'http://ufdc.ufl.edu/UF00072012/00008': 825},\n",
       "  'text': 'The learned Solicitor General seemed to think that a judge in the neighbourhood was an evil, and he would probably think a judgment delivered at Moscow even better for the people of Wales than one delivered in London.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['object1']['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'better', 'moscow', 'or', 'london?']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'O', 'O', 'O']]\n",
      "[]\n",
      "['better']\n",
      "We try to use spacy\n",
      "or index doc snet 4\n",
      "begin end  3 4 Moscow\n",
      "obj1 spacy doc sent Moscow\n",
      "or index doc snet 4\n",
      "begin end  5 6 London\n",
      "obj2 spacy doc sent London\n",
      "Moscow London ['better']\n",
      "aspects ['better']\n",
      "weights [1]\n",
      "get url {'objectA': 'Moscow', 'objectB': 'London', 'fs': 'true', 'aspect1': 'better', 'weight1': 1}\n"
     ]
    }
   ],
   "source": [
    "my_responser = responser()\n",
    "obj1, obj2, predicates = my_extractor.get_params()\n",
    "print (obj1, obj2, predicates)\n",
    "if (len(obj1) > 0 and len(obj2) > 0):\n",
    "    response = my_responser.get_response(first_object = obj1, second_object = obj2, fast_search=True, aspects = predicates, weights = [1 for predicate in predicates])\n",
    "else:\n",
    "    print (\"smth wrong with objects obj1 %s obj2 %s\", obj1, obj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answerer(input_string):\n",
    "    my_extractor = extractor(input_string)\n",
    "    my_responser = responser()\n",
    "    obj1, obj2, predicates = my_extractor.get_params()\n",
    "    print (obj1, obj2, predicates)\n",
    "    if (len(obj1) > 0 and len(obj2) > 0):\n",
    "        response =  my_responser.get_response(first_object = obj1, second_object = obj2, fast_search=True, aspects = predicates, weights = [1 for predicate in predicates])\n",
    "        try:\n",
    "            response_json = response.json()\n",
    "            my_diviner = diviner()\n",
    "            my_diviner.create_from_json(response_json, predicates)\n",
    "            answer = my_diviner.generate_advice()\n",
    "            return answer\n",
    "        except:\n",
    "            return (\"smth wrong in response, please try again\")\n",
    "    else:\n",
    "        return (\"smth wrong with objects obj1 %s obj2 %s\", obj1, obj2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'better', 'moscow', 'or', 'london?']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'O', 'O', 'O']]\n",
      "[]\n",
      "['better']\n",
      "We try to use spacy\n",
      "or index doc snet 4\n",
      "begin end  3 4 Moscow\n",
      "obj1 spacy doc sent Moscow\n",
      "or index doc snet 4\n",
      "begin end  5 6 London\n",
      "obj2 spacy doc sent London\n",
      "Moscow London ['better']\n",
      "aspects ['better']\n",
      "weights [1]\n",
      "get url {'objectA': 'Moscow', 'objectB': 'London', 'fs': 'true', 'aspect1': 'better', 'weight1': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'smth wrong in response, please try again'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answerer(\"What is better Moscow or London?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/vika/cqas_flask/generation/gpt-2-Pytorch\")\n",
    "from text_gen import text_generator_for_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:00<00:04, 42.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The moscow is better than london\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 42.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answer_end = text_generator_for_out(\"The moscow is better than london\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['. You know the difference. It\\'s not like they\\'re trying to sell you something. It\\'s just that they\\'re looking for a way to make money off of it. It\\'s because they do it that they\\'re going to make money off of it.\"',\n",
       " '',\n",
       " \"I'm not going to lie. I'm not going to lie to you. I think it's amazing how much money they are making off of it.\",\n",
       " '',\n",
       " \"They do make money off of it. But it's not that they can't make money off of it. It's just that it's not that they know how to make money off of it.\",\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.',\n",
       " '',\n",
       " 'They make money off of it.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".\\n\\n\\nI'll leave you with a link to the video where the muscow shows you how to make the moscow but without the mushroom, you need to cut off the ends of the mushroom and then the mushrooms.\\n\\nHere are some pics of the muscow,\\n\\n(click them to enlarge):\\n\\n\\nThe mushroom is a wonderful gift and the mushroom is very useful because you can grow it for a long time.\\n\\n\\nHere's my muscow that you can grow for a long time.\\n\\n\\nHere's a picture of my muscow.\\n\\n\\nNow, I'm going to show you how a muscow is made from the following:\\n\\nA muscow with a mushroom as its base.\\n\\nA muscow with a mushroom as its top.\\n\\nA muscow with a mushroom as its base.\\n\\nA muscow with a mushroom as its top.\\n\\nYou can choose between 3 different shapes for your muscow.\\n\\n\\nHere\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.exists('/home/vika/cqas_flask/generation/gpt-2-Pytorch' + '/' + 'gpt2-pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".\\n\\n\\nI'll leave you with a link to the video where the muscow shows you how to make the moscow but without the mushroom, you need to cut off the ends of the mushroom and then the mushrooms.\\n\\nHere are some pics of the muscow,\\n\\n(click them to enlarge):\\n\\n\\nThe mushroom is a wonderful gift and the mushroom is very useful because you can grow it for a long time.\\n\\n\\nHere's my muscow that you can grow for a long time.\\n\\n\\nHere's a picture of my muscow.\\n\\n\\nNow, I'm going to show you how a muscow is made from the following:\\n\\nA muscow with a mushroom as its base.\\n\\nA muscow with a mushroom as its top.\\n\\nA muscow with a mushroom as its base.\\n\\nA muscow with a mushroom as its top.\\n\\nYou can choose between 3 different shapes for your muscow.\\n\\n\\nHere\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vika/cqas_flask\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "aspects  ['greater', 'safer', 'bigger', 'quicker'] ['argument', 'power', 'authority', 'faster']\n",
      "winnder: london  other: moscow\n",
      "acpect winner  greater, safer, bigger, quicker\n",
      "acpect other  argument, power, authority, faster\n",
      "self predicate  better\n",
      "answer begin  The london is better than moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:00<00:05, 38.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The london is better than moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 41.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "answer end   https://t.co/0Wl4jqXVfZ — Ralf Bering (@Bering_Ralf) November 17, 2017\n",
      "\n",
      "The Daily Mail has confirmed the club's new owner, who is from Leeds, will take over the club from his former boss, Mark Hughes.\n",
      "\n",
      "In a statement, Ralf said: \"I feel like I can say this, although I don't think I've ever been the kind of person who would talk about my life in the media.\n",
      "\n",
      "\"I've never been an editor of a Sunday newspaper and I didn't ever have a real agenda. My job in the media was to get the news and to be the news.\n",
      "\n",
      "\"I have a very limited amount of time in the media so I have never been in a position to work on everything.\n",
      "\n",
      "\"My career has been going on for over 20 years now and I'm still a little bit of an outsider. I've also got\n",
      "full answer  The london is better than moscow.The reason is greater, safer, bigger, quicker https://t.co/0Wl4jqXVfZ — Ralf Bering (@Bering_Ralf) November 17, 2017\n",
      "\n",
      "The Daily Mail has confirmed the club's new owner, who is from Leeds, will take over the club from his former boss, Mark Hughes.\n",
      "\n",
      "In a statement, Ralf said: \"I feel like I can say this, although I don't think I've ever been the kind of person who would talk about my life in the media.\n",
      "\n",
      "\"I've never been an editor of a Sunday newspaper and I didn't ever have a real agenda. My job in the media was to get the news and to be the news.\n",
      "\n",
      "\"I have a very limited amount of time in the media so I have never been in a position to work on everything.\n",
      "\n",
      "\"My career has been going on for over 20 years now and I'm still a little bit of an outsider. I've also got\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The london is better than moscow.The reason is greater, safer, bigger, quicker https://t.co/0Wl4jqXVfZ — Ralf Bering (@Bering_Ralf) November 17, 2017\\n\\nThe Daily Mail has confirmed the club\\'s new owner, who is from Leeds, will take over the club from his former boss, Mark Hughes.\\n\\nIn a statement, Ralf said: \"I feel like I can say this, although I don\\'t think I\\'ve ever been the kind of person who would talk about my life in the media.\\n\\n\"I\\'ve never been an editor of a Sunday newspaper and I didn\\'t ever have a real agenda. My job in the media was to get the news and to be the news.\\n\\n\"I have a very limited amount of time in the media so I have never been in a position to work on everything.\\n\\n\"My career has been going on for over 20 years now and I\\'m still a little bit of an outsider. I\\'ve also got'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import os.path\n",
    "import torch\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "\n",
    "from generation.generation import diviner\n",
    "\n",
    "response_json = response.json()\n",
    "Merlin = diviner()\n",
    "Merlin.create_from_json(response_json, 'better')\n",
    "Merlin.generate_advice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winnder: london  other: moscow\n",
      "acpect winner  greater, safer, bigger, quicker\n",
      "acpect other  argument, power, authority, faster\n",
      "self predicate  better\n",
      "answer begin  The london is better than moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:00<00:05, 34.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The london is better than moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "answer end  \n",
      "\n",
      "This is the most interesting thing about the london. It is not just a london but a city or a city and a city is the london. It is only when the london is a city that the city is a city. The london is the london where you don't have to be a city. Its the london where you do not need to be a city to be a london.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is where your friends are. Its the london where you don't have to be a city.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is where you don't have to be a city.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is\n",
      "full answer  The london is better than moscow.The reason is greater, safer, bigger, quicker\n",
      "\n",
      "This is the most interesting thing about the london. It is not just a london but a city or a city and a city is the london. It is only when the london is a city that the city is a city. The london is the london where you don't have to be a city. Its the london where you do not need to be a city to be a london.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is where your friends are. Its the london where you don't have to be a city.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is where you don't have to be a city.\n",
      "\n",
      "The london is the london where you don't have to be a city to be a london. The london is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The london is better than moscow.The reason is greater, safer, bigger, quicker\\n\\nThis is the most interesting thing about the london. It is not just a london but a city or a city and a city is the london. It is only when the london is a city that the city is a city. The london is the london where you don't have to be a city. Its the london where you do not need to be a city to be a london.\\n\\nThe london is the london where you don't have to be a city to be a london. The london is where your friends are. Its the london where you don't have to be a city.\\n\\nThe london is the london where you don't have to be a city to be a london. The london is where you don't have to be a city.\\n\\nThe london is the london where you don't have to be a city to be a london. The london is\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Merlin.generate_advice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'better', 'tea', 'or', 'coffee?']]\n",
      "-2\n",
      "[['O', 'O', 'B-PREDFULL', 'B-OBJ', 'O', 'O']]\n",
      "['tea']\n",
      "['better']\n",
      "We try to use spacy\n",
      "or simple split_sent 4\n",
      "tea coffee?\n",
      "len(obj1), len(obj2) 3 6\n",
      "obj1, obj2, predicates tea coffee ['better']\n",
      "aspects ['better']\n",
      "weights [1]\n",
      "get url\n",
      "1\n",
      "aspects  ['better for you', 'easier', 'better for the environment', 'safer'] ['greater', 'easier to keep your weight under control with green tea as part of your diet', 'caffeine', 'cooler']\n",
      "2\n",
      "winnder: tea  other: coffee\n",
      "acpect winner  better for you, easier, better for the environment, safer\n",
      "acpect other  greater, easier to keep your weight under control with green tea as part of your diet, caffeine, cooler\n",
      "self predicate  better\n",
      "answer begin:  The tea is better than coffee.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:00<00:04, 44.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tea is better than coffee.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 43.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "qu2\n",
      "qu3\n",
      "answer end str:  \n",
      "\n",
      "For me, though, the best tea is not coffee but coffee in the form of a tea. If you want a tea that's truly delicious, then don't rely on a cup of tea as your main source of tea. The best coffee is always coffee.\n",
      "\n",
      "If you're thinking, \"Wow, maybe this is the best tea I've ever had!\" then you're not alone.\n",
      "\n",
      "The best tea is always coffee, especially if you're a tea drinker.\n",
      "\n",
      "This is how I think of my favorite coffee.\n",
      "\n",
      "I like to have a cup of tea with me every day. So how often do I get a cup of coffee?\n",
      "\n",
      "When I first started using the tea method as an alternative to coffee, it was quite simple.\n",
      "\n",
      "You get a cup of coffee daily, and then you get another cup each day.\n",
      "\n",
      "My friend and I used to go to the store to buy coffee.\n",
      "\n",
      "We were always on\n",
      "answer end str:  For me, though, the best tea is not coffee but coffee in the form of a tea. If you want a tea that's truly delicious, then don't rely on a cup of tea as your main source of tea. The best coffee is always coffee.If you're thinking, \"Wow, maybe this is the best tea I've ever had!\" then you're not alone.The best tea is always coffee, especially if you're a tea drinker.\n",
      "full answer  The tea is better than coffee.The reason is better for you, easier, better for the environment, safer.For me, though, the best tea is not coffee but coffee in the form of a tea. If you want a tea that's truly delicious, then don't rely on a cup of tea as your main source of tea. The best coffee is always coffee.If you're thinking, \"Wow, maybe this is the best tea I've ever had!\" then you're not alone.The best tea is always coffee, especially if you're a tea drinker.\n",
      "answer The tea is better than coffee.The reason is better for you, easier, better for the environment, safer.For me, though, the best tea is not coffee but coffee in the form of a tea. If you want a tea that's truly delicious, then don't rely on a cup of tea as your main source of tea. The best coffee is always coffee.If you're thinking, \"Wow, maybe this is the best tea I've ever had!\" then you're not alone.The best tea is always coffee, especially if you're a tea drinker.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The tea is better than coffee.The reason is better for you, easier, better for the environment, safer.For me, though, the best tea is not coffee but coffee in the form of a tea. If you want a tea that\\'s truly delicious, then don\\'t rely on a cup of tea as your main source of tea. The best coffee is always coffee.If you\\'re thinking, \"Wow, maybe this is the best tea I\\'ve ever had!\" then you\\'re not alone.The best tea is always coffee, especially if you\\'re a tea drinker.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from my_functions import do_sum, answerer\n",
    "answerer(\"what is better tea or coffee?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-311a4e67ee93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtext_gen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_generator_for_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext_generator_for_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The pizza is better than bread.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/vika/cqas_flask/generation/gpt-2-Pytorch/text_gen.py\u001b[0m in \u001b[0;36mtext_generator_for_out\u001b[0;34m(text, length, temperature, top_k, path_to_model)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vika/cqas_flask/generation/gpt-2-Pytorch/GPT2/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "from text_gen import text_generator_for_out\n",
    "text_generator_for_out(\"The pizza is better than bread.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:00<00:04, 42.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man is better than woman.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 41.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "qu2\n",
      "qu3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' He\\'s better than the other. He\\'s better than the other man. He\\'s better than the other woman.\\n\\n(7)\\n\\n(A)\\n\\n(B)\\n\\n(C)\\n\\n(D)\\n\\n(E)\\n\\n(F)\\n\\n(G)\\n\\n(H)\\n\\n(I)\\n\\n(J)\\n\\n(K)\\n\\n(L)\\n\\n(M)\\n\\n(N)\\n\\n(O)\\n\\n(P)\\n\\n(Q)\\n\\n(R)\\n\\n(S)\\n\\n(T)\\n\\n(U)\\n\\n(V)\\n\\n(W)\\n\\n(X)\\n\\n(Y)<|endoftext|>The Federal Reserve\\'s policy on quantitative easing—which has been described as a \"market-oriented program\"—has been criticized as a \"market-driven policy,\" according to a New York Times reporter.\\n\\nIn a piece that'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/vika/cqas_flask/generation/gpt-2-Pytorch\")\n",
    "from text_gen import text_generator_for_out\n",
    "text_generator_for_out(\"The man is better than woman.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:00<00:04, 42.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man is better than woman.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 42.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "======================================== SAMPLE 1 ========================================\n",
      "qu2\n",
      "qu3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nIn order to get her out of the house, she must get to the nearest exit. If she does, she is going to be in jail.\\n\\nAnd the most recent of the many possible consequences for this behavior is that the woman's husband will have to pay for her to go, but the woman's husband will do the rest.\\n\\nThe woman is forced to go.\\n\\nThere is no more responsibility for the husband's actions, but there is no more responsibility for the woman's actions.\\n\\nThe man is responsible for her behavior.\\n\\nThe man is responsible for the woman's behavior.\\n\\nThe woman is responsible for the man's actions.\\n\\nAnd the man is responsible for the woman's actions.\\n\\nThe man is responsible for the woman's actions.\\n\\nThe woman is responsible for the man's actions.\\n\\nAnd the man is responsible for the woman's actions.\\n\\nThe woman is responsible for the man's actions\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/vika/cqas_flask/generation/gpt-2-Pytorch\")\n",
    "from text_gen import text_generator_for_out\n",
    "answer_end = text_generator_for_out(\"The man is better than woman.\")\n",
    "answer_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' He is the best. He is better than a woman. He is the man who is better than a man, and the woman who is better than a woman. He is better than a woman. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is better than a woman. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is better than a woman. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is better than a woman. He is the man who is better than a man. He is the man who is']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end.splitlines()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I don\\'t have to be a woman to be successful in my profession,\" he said. \"I don\\'t even have to be a man to be a successful man.\"In the past, he has said he would have preferred women to be in his position. He has also said he would have preferred women to be in his position.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(answer_end.splitlines()[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
